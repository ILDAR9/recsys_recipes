{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте код ниже, чтобы установить все зависимости\n",
    "# !pip install -q \\\n",
    "#     pyarrow==12.0.1 \\\n",
    "#     polars==0.18.6 \\\n",
    "#     pandas==2.0.3 \\\n",
    "#     scipy==1.10.1 \\\n",
    "#     numpy==1.24.3 \\\n",
    "#     torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0e1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import time\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b049d4",
   "metadata": {},
   "source": [
    "Pytorch – фреймворк глубокого обучения, позволяющий использовать autograd (автоматический подсчет градиента с помощью обратного распространения ошибки) для простого и эффективного построения глубоких моделей\n",
    "\n",
    "Работа с данными выполнена в максимально похожем на numpy array стиле, а для ускорения обучения моделей можно легко использовать gpu с минимальными изменениями в коде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5438c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x_numpy = np.array([1, 2, 3])\n",
    "print(x_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3aac91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x_torch = torch.from_numpy(x_numpy)\n",
    "print(x_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e12fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0dbf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch = x_torch.float()\n",
    "x_torch.requires_grad = True\n",
    "x_torch.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d36789",
   "metadata": {},
   "source": [
    "Давайте зададим простую функцию, которую мы хотим приблизить с помощью глубокой модели:\n",
    "\n",
    "$f(x) = 3 \\cdot \\cos(x^2 + \\sqrt{|x|}) + 5 + x^3 + \\epsilon$, где $\\epsilon$ – случайная величина (шум) из стандартного нормального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9186010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * torch.cos(x**2 + torch.sqrt(torch.abs(x))) + 5 + x**3 + torch.randn_like(x)\n",
    "\n",
    "x_all = torch.from_numpy(np.random.uniform(-10, 10, size=1_000)).float()\n",
    "x_all = torch.sort(x_all)[0]\n",
    "\n",
    "x_train = x_all[:900]\n",
    "y_train = f(x_train)\n",
    "\n",
    "x_test = x_all[900:]\n",
    "y_test = f(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c54a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, c='b', label='train')\n",
    "plt.plot(x_test, y_test, c='r', label='test')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0693b09",
   "metadata": {},
   "source": [
    "## Обучим простую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d5565",
   "metadata": {},
   "source": [
    "`nn.Module` – базовый класс для имплементации глубоких моделей\n",
    "\n",
    "`torch.optim.*` – различные варианты оптимизаторов, мы будем использовать Adam как наиболее универсальный\n",
    "\n",
    "`nn.MSELoss` – функция ошибки MSE (можно делать и свои собственные функции, которые состоят из функций pytorch)\n",
    "\n",
    "`nn.Linear` – линейный полносвязный слой  (матрица n x m и параметр глобального смещения)\n",
    "\n",
    "`nn.ReLU` – функция активации `relu(x) = min(0, x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bb1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_blocks: int = 3,\n",
    "        hidden_dim: int = 64,\n",
    "        input_dim: int = 1,\n",
    "        output_dim: int = 1,\n",
    "    ):\n",
    "        # важно сделать, чтобы слои учитывались при обратном распространении ошибок\n",
    "        super().__init__()\n",
    "\n",
    "        # наша сеть будет состоять из скрытых блоков вида [Liner, ReLU], а также входной и выходной слой\n",
    "        layers = []\n",
    "        layers.extend(\n",
    "            [\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "        for _ in range(n_blocks):\n",
    "            layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.ReLU()])\n",
    "        layers.extend([nn.Linear(hidden_dim, output_dim)])\n",
    "        self.ff_layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.ff_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ec9e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000 epoch] Train loss = 108642.52, Test loss = 601753.00\n",
      "[2/1000 epoch] Train loss = 108266.81, Test loss = 600409.06\n",
      "[3/1000 epoch] Train loss = 107459.36, Test loss = 598142.19\n",
      "[4/1000 epoch] Train loss = 105852.34, Test loss = 594116.25\n",
      "[5/1000 epoch] Train loss = 102997.92, Test loss = 587348.88\n",
      "[6/1000 epoch] Train loss = 98417.16, Test loss = 576594.62\n",
      "[7/1000 epoch] Train loss = 91279.86, Test loss = 560314.81\n",
      "[8/1000 epoch] Train loss = 81157.51, Test loss = 536642.19\n",
      "[9/1000 epoch] Train loss = 67725.43, Test loss = 503408.72\n",
      "[10/1000 epoch] Train loss = 51578.71, Test loss = 458806.84\n",
      "[11/1000 epoch] Train loss = 35411.03, Test loss = 400389.69\n",
      "[12/1000 epoch] Train loss = 25585.08, Test loss = 327777.03\n",
      "[13/1000 epoch] Train loss = 32235.96, Test loss = 241843.31\n",
      "[14/1000 epoch] Train loss = 36826.93, Test loss = 148751.20\n",
      "[15/1000 epoch] Train loss = 29401.55, Test loss = 73574.52\n",
      "[16/1000 epoch] Train loss = 23125.53, Test loss = 45532.52\n",
      "[17/1000 epoch] Train loss = 22732.37, Test loss = 49344.99\n",
      "[18/1000 epoch] Train loss = 24550.53, Test loss = 71642.28\n",
      "[19/1000 epoch] Train loss = 25686.22, Test loss = 107785.56\n",
      "[20/1000 epoch] Train loss = 25421.27, Test loss = 151196.02\n",
      "[21/1000 epoch] Train loss = 24015.20, Test loss = 193741.44\n",
      "[22/1000 epoch] Train loss = 22344.01, Test loss = 229252.88\n",
      "[23/1000 epoch] Train loss = 20726.66, Test loss = 254997.86\n",
      "[24/1000 epoch] Train loss = 19541.75, Test loss = 270381.88\n",
      "[25/1000 epoch] Train loss = 19508.52, Test loss = 275873.38\n",
      "[26/1000 epoch] Train loss = 20545.95, Test loss = 272343.81\n",
      "[27/1000 epoch] Train loss = 21559.16, Test loss = 260721.52\n",
      "[28/1000 epoch] Train loss = 21377.08, Test loss = 242018.00\n",
      "[29/1000 epoch] Train loss = 19871.25, Test loss = 217601.62\n",
      "[30/1000 epoch] Train loss = 18026.01, Test loss = 189409.59\n",
      "[31/1000 epoch] Train loss = 16867.88, Test loss = 160129.64\n",
      "[32/1000 epoch] Train loss = 16749.09, Test loss = 133095.69\n",
      "[33/1000 epoch] Train loss = 17278.15, Test loss = 111475.12\n",
      "[34/1000 epoch] Train loss = 17876.50, Test loss = 98219.44\n",
      "[35/1000 epoch] Train loss = 18021.54, Test loss = 94048.66\n",
      "[36/1000 epoch] Train loss = 17543.74, Test loss = 98161.73\n",
      "[37/1000 epoch] Train loss = 16701.74, Test loss = 109125.20\n",
      "[38/1000 epoch] Train loss = 15966.16, Test loss = 124740.32\n",
      "[39/1000 epoch] Train loss = 15665.86, Test loss = 142292.73\n",
      "[40/1000 epoch] Train loss = 15705.74, Test loss = 159060.44\n",
      "[41/1000 epoch] Train loss = 15688.19, Test loss = 172765.95\n",
      "[42/1000 epoch] Train loss = 15399.10, Test loss = 182014.12\n",
      "[43/1000 epoch] Train loss = 14984.29, Test loss = 186196.44\n",
      "[44/1000 epoch] Train loss = 14695.80, Test loss = 185542.05\n",
      "[45/1000 epoch] Train loss = 14586.59, Test loss = 180619.88\n",
      "[46/1000 epoch] Train loss = 14440.28, Test loss = 172296.12\n",
      "[47/1000 epoch] Train loss = 14076.03, Test loss = 161592.45\n",
      "[48/1000 epoch] Train loss = 13488.51, Test loss = 149732.55\n",
      "[49/1000 epoch] Train loss = 12852.81, Test loss = 138105.31\n",
      "[50/1000 epoch] Train loss = 12384.66, Test loss = 128048.29\n",
      "[51/1000 epoch] Train loss = 12181.93, Test loss = 120689.87\n",
      "[52/1000 epoch] Train loss = 11998.78, Test loss = 116745.11\n",
      "[53/1000 epoch] Train loss = 11709.55, Test loss = 116404.01\n",
      "[54/1000 epoch] Train loss = 11318.34, Test loss = 119317.01\n",
      "[55/1000 epoch] Train loss = 10924.68, Test loss = 124683.58\n",
      "[56/1000 epoch] Train loss = 10590.78, Test loss = 131397.81\n",
      "[57/1000 epoch] Train loss = 10282.26, Test loss = 138243.66\n",
      "[58/1000 epoch] Train loss = 9932.66, Test loss = 144096.95\n",
      "[59/1000 epoch] Train loss = 9536.69, Test loss = 148086.95\n",
      "[60/1000 epoch] Train loss = 9152.17, Test loss = 149640.70\n",
      "[61/1000 epoch] Train loss = 8820.43, Test loss = 148632.36\n",
      "[62/1000 epoch] Train loss = 8477.72, Test loss = 145318.23\n",
      "[63/1000 epoch] Train loss = 8085.75, Test loss = 140236.91\n",
      "[64/1000 epoch] Train loss = 7682.43, Test loss = 134174.12\n",
      "[65/1000 epoch] Train loss = 7322.71, Test loss = 128029.12\n",
      "[66/1000 epoch] Train loss = 6978.39, Test loss = 122499.52\n",
      "[67/1000 epoch] Train loss = 6609.63, Test loss = 118370.30\n",
      "[68/1000 epoch] Train loss = 6252.49, Test loss = 116026.97\n",
      "[69/1000 epoch] Train loss = 5943.75, Test loss = 115503.19\n",
      "[70/1000 epoch] Train loss = 5634.31, Test loss = 116557.49\n",
      "[71/1000 epoch] Train loss = 5304.63, Test loss = 118957.88\n",
      "[72/1000 epoch] Train loss = 5004.44, Test loss = 122101.70\n",
      "[73/1000 epoch] Train loss = 4739.37, Test loss = 124943.82\n",
      "[74/1000 epoch] Train loss = 4469.10, Test loss = 126620.72\n",
      "[75/1000 epoch] Train loss = 4252.37, Test loss = 126640.30\n",
      "[76/1000 epoch] Train loss = 4034.98, Test loss = 124959.22\n",
      "[77/1000 epoch] Train loss = 3818.66, Test loss = 121848.68\n",
      "[78/1000 epoch] Train loss = 3634.00, Test loss = 117864.45\n",
      "[79/1000 epoch] Train loss = 3447.79, Test loss = 114347.27\n",
      "[80/1000 epoch] Train loss = 3294.84, Test loss = 111042.84\n",
      "[81/1000 epoch] Train loss = 3143.29, Test loss = 108315.96\n",
      "[82/1000 epoch] Train loss = 2996.10, Test loss = 107126.90\n",
      "[83/1000 epoch] Train loss = 2833.53, Test loss = 108532.76\n",
      "[84/1000 epoch] Train loss = 2699.01, Test loss = 109528.72\n",
      "[85/1000 epoch] Train loss = 2575.76, Test loss = 109149.52\n",
      "[86/1000 epoch] Train loss = 2448.91, Test loss = 106750.76\n",
      "[87/1000 epoch] Train loss = 2325.56, Test loss = 102731.09\n",
      "[88/1000 epoch] Train loss = 2199.27, Test loss = 97679.16\n",
      "[89/1000 epoch] Train loss = 2077.97, Test loss = 92776.50\n",
      "[90/1000 epoch] Train loss = 1968.46, Test loss = 90327.16\n",
      "[91/1000 epoch] Train loss = 1864.06, Test loss = 89507.18\n",
      "[92/1000 epoch] Train loss = 1765.65, Test loss = 89587.99\n",
      "[93/1000 epoch] Train loss = 1677.19, Test loss = 90719.66\n",
      "[94/1000 epoch] Train loss = 1602.43, Test loss = 90406.19\n",
      "[95/1000 epoch] Train loss = 1533.84, Test loss = 87313.34\n",
      "[96/1000 epoch] Train loss = 1461.78, Test loss = 81879.98\n",
      "[97/1000 epoch] Train loss = 1388.12, Test loss = 77847.95\n",
      "[98/1000 epoch] Train loss = 1343.27, Test loss = 75249.23\n",
      "[99/1000 epoch] Train loss = 1257.89, Test loss = 74498.46\n",
      "[100/1000 epoch] Train loss = 1184.47, Test loss = 74905.57\n",
      "[101/1000 epoch] Train loss = 1114.48, Test loss = 74287.61\n",
      "[102/1000 epoch] Train loss = 1051.02, Test loss = 72603.52\n",
      "[103/1000 epoch] Train loss = 984.70, Test loss = 68336.02\n",
      "[104/1000 epoch] Train loss = 918.35, Test loss = 62351.98\n",
      "[105/1000 epoch] Train loss = 853.76, Test loss = 57817.36\n",
      "[106/1000 epoch] Train loss = 803.30, Test loss = 55611.66\n",
      "[107/1000 epoch] Train loss = 750.22, Test loss = 56079.39\n",
      "[108/1000 epoch] Train loss = 696.44, Test loss = 56622.72\n",
      "[109/1000 epoch] Train loss = 653.80, Test loss = 54561.43\n",
      "[110/1000 epoch] Train loss = 611.67, Test loss = 49990.53\n",
      "[111/1000 epoch] Train loss = 567.54, Test loss = 46213.43\n",
      "[112/1000 epoch] Train loss = 532.55, Test loss = 44427.45\n",
      "[113/1000 epoch] Train loss = 493.52, Test loss = 44216.54\n",
      "[114/1000 epoch] Train loss = 455.31, Test loss = 44067.18\n",
      "[115/1000 epoch] Train loss = 425.66, Test loss = 42626.28\n",
      "[116/1000 epoch] Train loss = 393.16, Test loss = 40700.65\n",
      "[117/1000 epoch] Train loss = 362.80, Test loss = 39461.18\n",
      "[118/1000 epoch] Train loss = 336.32, Test loss = 39615.87\n",
      "[119/1000 epoch] Train loss = 308.65, Test loss = 39804.21\n",
      "[120/1000 epoch] Train loss = 287.21, Test loss = 39106.08\n",
      "[121/1000 epoch] Train loss = 264.96, Test loss = 37414.33\n",
      "[122/1000 epoch] Train loss = 246.91, Test loss = 36386.87\n",
      "[123/1000 epoch] Train loss = 229.56, Test loss = 35254.18\n",
      "[124/1000 epoch] Train loss = 215.77, Test loss = 33835.74\n",
      "[125/1000 epoch] Train loss = 205.05, Test loss = 31653.72\n",
      "[126/1000 epoch] Train loss = 200.32, Test loss = 31035.31\n",
      "[127/1000 epoch] Train loss = 205.43, Test loss = 30152.17\n",
      "[128/1000 epoch] Train loss = 222.37, Test loss = 30340.09\n",
      "[129/1000 epoch] Train loss = 235.91, Test loss = 28389.88\n",
      "[130/1000 epoch] Train loss = 223.04, Test loss = 27698.12\n",
      "[131/1000 epoch] Train loss = 172.00, Test loss = 26743.31\n",
      "[132/1000 epoch] Train loss = 135.98, Test loss = 26444.78\n",
      "[133/1000 epoch] Train loss = 145.49, Test loss = 26481.93\n",
      "[134/1000 epoch] Train loss = 171.52, Test loss = 24942.83\n",
      "[135/1000 epoch] Train loss = 170.52, Test loss = 24545.37\n",
      "[136/1000 epoch] Train loss = 136.49, Test loss = 24064.85\n",
      "[137/1000 epoch] Train loss = 115.78, Test loss = 23841.87\n",
      "[138/1000 epoch] Train loss = 127.22, Test loss = 23872.66\n",
      "[139/1000 epoch] Train loss = 139.36, Test loss = 22738.19\n",
      "[140/1000 epoch] Train loss = 127.19, Test loss = 22666.51\n",
      "[141/1000 epoch] Train loss = 103.56, Test loss = 22623.18\n",
      "[142/1000 epoch] Train loss = 98.13, Test loss = 22231.96\n",
      "[143/1000 epoch] Train loss = 108.55, Test loss = 22142.02\n",
      "[144/1000 epoch] Train loss = 109.07, Test loss = 21439.36\n",
      "[145/1000 epoch] Train loss = 95.35, Test loss = 21550.01\n",
      "[146/1000 epoch] Train loss = 82.70, Test loss = 21575.82\n",
      "[147/1000 epoch] Train loss = 83.81, Test loss = 20978.19\n",
      "[148/1000 epoch] Train loss = 89.43, Test loss = 20871.90\n",
      "[149/1000 epoch] Train loss = 86.66, Test loss = 20451.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/1000 epoch] Train loss = 76.68, Test loss = 20452.83\n",
      "[151/1000 epoch] Train loss = 69.50, Test loss = 20181.18\n",
      "[152/1000 epoch] Train loss = 69.78, Test loss = 19596.08\n",
      "[153/1000 epoch] Train loss = 72.68, Test loss = 19662.78\n",
      "[154/1000 epoch] Train loss = 70.95, Test loss = 19355.51\n",
      "[155/1000 epoch] Train loss = 64.64, Test loss = 19229.75\n",
      "[156/1000 epoch] Train loss = 58.13, Test loss = 18891.31\n",
      "[157/1000 epoch] Train loss = 55.93, Test loss = 18599.62\n",
      "[158/1000 epoch] Train loss = 57.01, Test loss = 18673.88\n",
      "[159/1000 epoch] Train loss = 57.86, Test loss = 18215.38\n",
      "[160/1000 epoch] Train loss = 55.97, Test loss = 18105.08\n",
      "[161/1000 epoch] Train loss = 51.98, Test loss = 17837.44\n",
      "[162/1000 epoch] Train loss = 48.26, Test loss = 17752.38\n",
      "[163/1000 epoch] Train loss = 46.54, Test loss = 17601.42\n",
      "[164/1000 epoch] Train loss = 46.53, Test loss = 17253.92\n",
      "[165/1000 epoch] Train loss = 47.04, Test loss = 17300.80\n",
      "[166/1000 epoch] Train loss = 46.75, Test loss = 17025.49\n",
      "[167/1000 epoch] Train loss = 45.43, Test loss = 16992.75\n",
      "[168/1000 epoch] Train loss = 43.20, Test loss = 16694.83\n",
      "[169/1000 epoch] Train loss = 40.88, Test loss = 16699.04\n",
      "[170/1000 epoch] Train loss = 38.92, Test loss = 16563.73\n",
      "[171/1000 epoch] Train loss = 37.63, Test loss = 16371.79\n",
      "[172/1000 epoch] Train loss = 36.95, Test loss = 16303.79\n",
      "[173/1000 epoch] Train loss = 36.71, Test loss = 16145.89\n",
      "[174/1000 epoch] Train loss = 36.70, Test loss = 16131.78\n",
      "[175/1000 epoch] Train loss = 36.69, Test loss = 15831.75\n",
      "[176/1000 epoch] Train loss = 36.69, Test loss = 15895.04\n",
      "[177/1000 epoch] Train loss = 36.64, Test loss = 15632.50\n",
      "[178/1000 epoch] Train loss = 36.70, Test loss = 15688.60\n",
      "[179/1000 epoch] Train loss = 36.82, Test loss = 15358.42\n",
      "[180/1000 epoch] Train loss = 37.33, Test loss = 15519.05\n",
      "[181/1000 epoch] Train loss = 38.17, Test loss = 15140.57\n",
      "[182/1000 epoch] Train loss = 40.05, Test loss = 15313.26\n",
      "[183/1000 epoch] Train loss = 42.98, Test loss = 14870.71\n",
      "[184/1000 epoch] Train loss = 48.32, Test loss = 15228.38\n",
      "[185/1000 epoch] Train loss = 55.56, Test loss = 14588.65\n",
      "[186/1000 epoch] Train loss = 66.20, Test loss = 15099.68\n",
      "[187/1000 epoch] Train loss = 75.97, Test loss = 14356.95\n",
      "[188/1000 epoch] Train loss = 83.45, Test loss = 14989.76\n",
      "[189/1000 epoch] Train loss = 78.94, Test loss = 14240.55\n",
      "[190/1000 epoch] Train loss = 63.70, Test loss = 14708.38\n",
      "[191/1000 epoch] Train loss = 42.82, Test loss = 14388.88\n",
      "[192/1000 epoch] Train loss = 28.31, Test loss = 14351.00\n",
      "[193/1000 epoch] Train loss = 26.81, Test loss = 14513.19\n",
      "[194/1000 epoch] Train loss = 35.54, Test loss = 14068.79\n",
      "[195/1000 epoch] Train loss = 45.85, Test loss = 14502.14\n",
      "[196/1000 epoch] Train loss = 49.80, Test loss = 13942.47\n",
      "[197/1000 epoch] Train loss = 45.24, Test loss = 14335.27\n",
      "[198/1000 epoch] Train loss = 35.39, Test loss = 14009.95\n",
      "[199/1000 epoch] Train loss = 26.55, Test loss = 14065.64\n",
      "[200/1000 epoch] Train loss = 22.79, Test loss = 14095.82\n",
      "[201/1000 epoch] Train loss = 24.27, Test loss = 13845.87\n",
      "[202/1000 epoch] Train loss = 28.96, Test loss = 14114.25\n",
      "[203/1000 epoch] Train loss = 33.91, Test loss = 13648.10\n",
      "[204/1000 epoch] Train loss = 37.53, Test loss = 14066.50\n",
      "[205/1000 epoch] Train loss = 37.64, Test loss = 13577.99\n",
      "[206/1000 epoch] Train loss = 35.45, Test loss = 13891.51\n",
      "[207/1000 epoch] Train loss = 30.79, Test loss = 13543.42\n",
      "[208/1000 epoch] Train loss = 26.02, Test loss = 13709.08\n",
      "[209/1000 epoch] Train loss = 22.11, Test loss = 13536.82\n",
      "[210/1000 epoch] Train loss = 19.96, Test loss = 13519.05\n",
      "[211/1000 epoch] Train loss = 19.58, Test loss = 13581.02\n",
      "[212/1000 epoch] Train loss = 20.55, Test loss = 13373.88\n",
      "[213/1000 epoch] Train loss = 22.32, Test loss = 13584.26\n",
      "[214/1000 epoch] Train loss = 24.36, Test loss = 13266.03\n",
      "[215/1000 epoch] Train loss = 26.56, Test loss = 13560.09\n",
      "[216/1000 epoch] Train loss = 28.48, Test loss = 13148.41\n",
      "[217/1000 epoch] Train loss = 30.46, Test loss = 13537.59\n",
      "[218/1000 epoch] Train loss = 31.83, Test loss = 13070.17\n",
      "[219/1000 epoch] Train loss = 33.27, Test loss = 13492.26\n",
      "[220/1000 epoch] Train loss = 33.83, Test loss = 13006.86\n",
      "[221/1000 epoch] Train loss = 34.60, Test loss = 13444.92\n",
      "[222/1000 epoch] Train loss = 34.37, Test loss = 12937.35\n",
      "[223/1000 epoch] Train loss = 34.38, Test loss = 13380.38\n",
      "[224/1000 epoch] Train loss = 33.24, Test loss = 12898.44\n",
      "[225/1000 epoch] Train loss = 32.27, Test loss = 13306.28\n",
      "[226/1000 epoch] Train loss = 30.26, Test loss = 12875.75\n",
      "[227/1000 epoch] Train loss = 28.41, Test loss = 13241.90\n",
      "[228/1000 epoch] Train loss = 26.03, Test loss = 12864.40\n",
      "[229/1000 epoch] Train loss = 23.95, Test loss = 13158.99\n",
      "[230/1000 epoch] Train loss = 21.88, Test loss = 12867.94\n",
      "[231/1000 epoch] Train loss = 20.18, Test loss = 13078.98\n",
      "[232/1000 epoch] Train loss = 18.76, Test loss = 12861.29\n",
      "[233/1000 epoch] Train loss = 17.71, Test loss = 13022.70\n",
      "[234/1000 epoch] Train loss = 16.94, Test loss = 12836.38\n",
      "[235/1000 epoch] Train loss = 16.41, Test loss = 12960.40\n",
      "[236/1000 epoch] Train loss = 16.07, Test loss = 12794.93\n",
      "[237/1000 epoch] Train loss = 15.89, Test loss = 12907.35\n",
      "[238/1000 epoch] Train loss = 15.87, Test loss = 12722.05\n",
      "[239/1000 epoch] Train loss = 16.05, Test loss = 12870.84\n",
      "[240/1000 epoch] Train loss = 16.53, Test loss = 12627.11\n",
      "[241/1000 epoch] Train loss = 17.54, Test loss = 12848.51\n",
      "[242/1000 epoch] Train loss = 19.47, Test loss = 12490.46\n",
      "[243/1000 epoch] Train loss = 23.18, Test loss = 12872.56\n",
      "[244/1000 epoch] Train loss = 29.71, Test loss = 12283.00\n",
      "[245/1000 epoch] Train loss = 41.93, Test loss = 12994.52\n",
      "[246/1000 epoch] Train loss = 61.46, Test loss = 11997.06\n",
      "[247/1000 epoch] Train loss = 93.32, Test loss = 13209.58\n",
      "[248/1000 epoch] Train loss = 128.87, Test loss = 11739.12\n",
      "[249/1000 epoch] Train loss = 158.93, Test loss = 13292.49\n",
      "[250/1000 epoch] Train loss = 142.21, Test loss = 11858.83\n",
      "[251/1000 epoch] Train loss = 80.10, Test loss = 12734.86\n",
      "[252/1000 epoch] Train loss = 23.00, Test loss = 12655.03\n",
      "[253/1000 epoch] Train loss = 22.14, Test loss = 11993.59\n",
      "[254/1000 epoch] Train loss = 59.84, Test loss = 13225.43\n",
      "[255/1000 epoch] Train loss = 71.52, Test loss = 12065.04\n",
      "[256/1000 epoch] Train loss = 39.12, Test loss = 12556.29\n",
      "[257/1000 epoch] Train loss = 15.47, Test loss = 12888.03\n",
      "[258/1000 epoch] Train loss = 32.07, Test loss = 11967.07\n",
      "[259/1000 epoch] Train loss = 50.63, Test loss = 12982.17\n",
      "[260/1000 epoch] Train loss = 36.79, Test loss = 12400.83\n",
      "[261/1000 epoch] Train loss = 16.44, Test loss = 12252.25\n",
      "[262/1000 epoch] Train loss = 21.71, Test loss = 12965.27\n",
      "[263/1000 epoch] Train loss = 37.25, Test loss = 12080.49\n",
      "[264/1000 epoch] Train loss = 35.02, Test loss = 12624.00\n",
      "[265/1000 epoch] Train loss = 19.69, Test loss = 12527.15\n",
      "[266/1000 epoch] Train loss = 14.61, Test loss = 12160.07\n",
      "[267/1000 epoch] Train loss = 23.55, Test loss = 12744.02\n",
      "[268/1000 epoch] Train loss = 30.03, Test loss = 12178.34\n",
      "[269/1000 epoch] Train loss = 24.87, Test loss = 12524.36\n",
      "[270/1000 epoch] Train loss = 15.58, Test loss = 12463.73\n",
      "[271/1000 epoch] Train loss = 14.66, Test loss = 12205.29\n",
      "[272/1000 epoch] Train loss = 20.76, Test loss = 12669.32\n",
      "[273/1000 epoch] Train loss = 23.55, Test loss = 12147.04\n",
      "[274/1000 epoch] Train loss = 19.56, Test loss = 12485.58\n",
      "[275/1000 epoch] Train loss = 14.24, Test loss = 12442.74\n",
      "[276/1000 epoch] Train loss = 14.00, Test loss = 12169.27\n",
      "[277/1000 epoch] Train loss = 17.63, Test loss = 12608.27\n",
      "[278/1000 epoch] Train loss = 19.46, Test loss = 12174.53\n",
      "[279/1000 epoch] Train loss = 17.37, Test loss = 12403.47\n",
      "[280/1000 epoch] Train loss = 13.97, Test loss = 12373.61\n",
      "[281/1000 epoch] Train loss = 13.02, Test loss = 12198.09\n",
      "[282/1000 epoch] Train loss = 14.75, Test loss = 12460.19\n",
      "[283/1000 epoch] Train loss = 16.44, Test loss = 12158.01\n",
      "[284/1000 epoch] Train loss = 16.09, Test loss = 12408.02\n",
      "[285/1000 epoch] Train loss = 14.13, Test loss = 12236.27\n",
      "[286/1000 epoch] Train loss = 12.59, Test loss = 12245.90\n",
      "[287/1000 epoch] Train loss = 12.59, Test loss = 12371.61\n",
      "[288/1000 epoch] Train loss = 13.60, Test loss = 12109.41\n",
      "[289/1000 epoch] Train loss = 14.36, Test loss = 12395.80\n",
      "[290/1000 epoch] Train loss = 14.06, Test loss = 12135.34\n",
      "[291/1000 epoch] Train loss = 13.09, Test loss = 12280.56\n",
      "[292/1000 epoch] Train loss = 12.06, Test loss = 12221.49\n",
      "[293/1000 epoch] Train loss = 11.48, Test loss = 12190.18\n",
      "[294/1000 epoch] Train loss = 11.41, Test loss = 12254.25\n",
      "[295/1000 epoch] Train loss = 11.74, Test loss = 12142.95\n",
      "[296/1000 epoch] Train loss = 12.19, Test loss = 12279.68\n",
      "[297/1000 epoch] Train loss = 12.53, Test loss = 12090.46\n",
      "[298/1000 epoch] Train loss = 12.66, Test loss = 12294.43\n",
      "[299/1000 epoch] Train loss = 12.53, Test loss = 12081.14\n",
      "[300/1000 epoch] Train loss = 12.23, Test loss = 12249.33\n",
      "[301/1000 epoch] Train loss = 11.84, Test loss = 12117.66\n",
      "[302/1000 epoch] Train loss = 11.46, Test loss = 12188.21\n",
      "[303/1000 epoch] Train loss = 11.16, Test loss = 12139.07\n",
      "[304/1000 epoch] Train loss = 10.95, Test loss = 12157.58\n",
      "[305/1000 epoch] Train loss = 10.83, Test loss = 12145.29\n",
      "[306/1000 epoch] Train loss = 10.80, Test loss = 12127.91\n",
      "[307/1000 epoch] Train loss = 10.82, Test loss = 12173.77\n",
      "[308/1000 epoch] Train loss = 10.88, Test loss = 12089.72\n",
      "[309/1000 epoch] Train loss = 10.98, Test loss = 12207.38\n",
      "[310/1000 epoch] Train loss = 11.12, Test loss = 12063.95\n",
      "[311/1000 epoch] Train loss = 11.31, Test loss = 12218.23\n",
      "[312/1000 epoch] Train loss = 11.58, Test loss = 12042.82\n",
      "[313/1000 epoch] Train loss = 11.98, Test loss = 12238.12\n",
      "[314/1000 epoch] Train loss = 12.57, Test loss = 11990.95\n",
      "[315/1000 epoch] Train loss = 13.50, Test loss = 12298.56\n",
      "[316/1000 epoch] Train loss = 14.95, Test loss = 11900.53\n",
      "[317/1000 epoch] Train loss = 17.40, Test loss = 12391.62\n",
      "[318/1000 epoch] Train loss = 21.30, Test loss = 11763.70\n",
      "[319/1000 epoch] Train loss = 28.10, Test loss = 12537.49\n",
      "[320/1000 epoch] Train loss = 38.61, Test loss = 11561.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321/1000 epoch] Train loss = 56.68, Test loss = 12801.42\n",
      "[322/1000 epoch] Train loss = 80.87, Test loss = 11285.10\n",
      "[323/1000 epoch] Train loss = 119.24, Test loss = 13147.50\n",
      "[324/1000 epoch] Train loss = 150.97, Test loss = 11106.95\n",
      "[325/1000 epoch] Train loss = 179.43, Test loss = 13209.88\n",
      "[326/1000 epoch] Train loss = 153.28, Test loss = 11400.67\n",
      "[327/1000 epoch] Train loss = 98.71, Test loss = 12629.26\n",
      "[328/1000 epoch] Train loss = 34.04, Test loss = 12224.66\n",
      "[329/1000 epoch] Train loss = 10.49, Test loss = 11868.99\n",
      "[330/1000 epoch] Train loss = 33.71, Test loss = 13013.24\n",
      "[331/1000 epoch] Train loss = 69.28, Test loss = 11594.33\n",
      "[332/1000 epoch] Train loss = 81.07, Test loss = 12951.29\n",
      "[333/1000 epoch] Train loss = 52.86, Test loss = 12061.74\n",
      "[334/1000 epoch] Train loss = 19.22, Test loss = 12239.84\n",
      "[335/1000 epoch] Train loss = 12.09, Test loss = 12813.61\n",
      "[336/1000 epoch] Train loss = 31.20, Test loss = 11848.81\n",
      "[337/1000 epoch] Train loss = 47.30, Test loss = 12948.07\n",
      "[338/1000 epoch] Train loss = 39.25, Test loss = 12131.04\n",
      "[339/1000 epoch] Train loss = 18.92, Test loss = 12385.16\n",
      "[340/1000 epoch] Train loss = 10.85, Test loss = 12717.05\n",
      "[341/1000 epoch] Train loss = 20.78, Test loss = 11963.94\n",
      "[342/1000 epoch] Train loss = 31.96, Test loss = 12864.81\n",
      "[343/1000 epoch] Train loss = 29.36, Test loss = 12156.76\n",
      "[344/1000 epoch] Train loss = 17.55, Test loss = 12451.65\n",
      "[345/1000 epoch] Train loss = 10.43, Test loss = 12648.48\n",
      "[346/1000 epoch] Train loss = 14.14, Test loss = 12111.08\n",
      "[347/1000 epoch] Train loss = 21.85, Test loss = 12798.20\n",
      "[348/1000 epoch] Train loss = 23.94, Test loss = 12179.03\n",
      "[349/1000 epoch] Train loss = 18.97, Test loss = 12549.78\n",
      "[350/1000 epoch] Train loss = 12.22, Test loss = 12463.23\n",
      "[351/1000 epoch] Train loss = 10.07, Test loss = 12283.35\n",
      "[352/1000 epoch] Train loss = 13.08, Test loss = 12674.21\n",
      "[353/1000 epoch] Train loss = 17.04, Test loss = 12194.03\n",
      "[354/1000 epoch] Train loss = 18.13, Test loss = 12664.06\n",
      "[355/1000 epoch] Train loss = 15.31, Test loss = 12303.40\n",
      "[356/1000 epoch] Train loss = 11.59, Test loss = 12457.78\n",
      "[357/1000 epoch] Train loss = 9.82, Test loss = 12524.64\n",
      "[358/1000 epoch] Train loss = 10.83, Test loss = 12255.57\n",
      "[359/1000 epoch] Train loss = 13.06, Test loss = 12648.53\n",
      "[360/1000 epoch] Train loss = 14.34, Test loss = 12237.24\n",
      "[361/1000 epoch] Train loss = 13.85, Test loss = 12569.78\n",
      "[362/1000 epoch] Train loss = 12.01, Test loss = 12361.21\n",
      "[363/1000 epoch] Train loss = 10.25, Test loss = 12413.33\n",
      "[364/1000 epoch] Train loss = 9.50, Test loss = 12479.49\n",
      "[365/1000 epoch] Train loss = 9.91, Test loss = 12306.59\n",
      "[366/1000 epoch] Train loss = 10.90, Test loss = 12539.19\n",
      "[367/1000 epoch] Train loss = 11.68, Test loss = 12265.39\n",
      "[368/1000 epoch] Train loss = 11.81, Test loss = 12536.40\n",
      "[369/1000 epoch] Train loss = 11.25, Test loss = 12289.43\n",
      "[370/1000 epoch] Train loss = 10.41, Test loss = 12459.50\n",
      "[371/1000 epoch] Train loss = 9.61, Test loss = 12361.02\n",
      "[372/1000 epoch] Train loss = 9.13, Test loss = 12362.90\n",
      "[373/1000 epoch] Train loss = 9.01, Test loss = 12422.40\n",
      "[374/1000 epoch] Train loss = 9.18, Test loss = 12304.04\n",
      "[375/1000 epoch] Train loss = 9.52, Test loss = 12449.49\n",
      "[376/1000 epoch] Train loss = 9.89, Test loss = 12272.35\n",
      "[377/1000 epoch] Train loss = 10.21, Test loss = 12459.09\n",
      "[378/1000 epoch] Train loss = 10.38, Test loss = 12242.15\n",
      "[379/1000 epoch] Train loss = 10.45, Test loss = 12459.23\n",
      "[380/1000 epoch] Train loss = 10.39, Test loss = 12232.93\n",
      "[381/1000 epoch] Train loss = 10.27, Test loss = 12444.91\n",
      "[382/1000 epoch] Train loss = 10.10, Test loss = 12248.17\n",
      "[383/1000 epoch] Train loss = 9.93, Test loss = 12421.18\n",
      "[384/1000 epoch] Train loss = 9.76, Test loss = 12262.25\n",
      "[385/1000 epoch] Train loss = 9.63, Test loss = 12408.41\n",
      "[386/1000 epoch] Train loss = 9.51, Test loss = 12254.08\n",
      "[387/1000 epoch] Train loss = 9.44, Test loss = 12412.54\n",
      "[388/1000 epoch] Train loss = 9.39, Test loss = 12247.09\n",
      "[389/1000 epoch] Train loss = 9.40, Test loss = 12413.76\n",
      "[390/1000 epoch] Train loss = 9.44, Test loss = 12240.20\n",
      "[391/1000 epoch] Train loss = 9.56, Test loss = 12414.61\n",
      "[392/1000 epoch] Train loss = 9.77, Test loss = 12210.16\n",
      "[393/1000 epoch] Train loss = 10.15, Test loss = 12441.07\n",
      "[394/1000 epoch] Train loss = 10.75, Test loss = 12144.22\n",
      "[395/1000 epoch] Train loss = 11.78, Test loss = 12498.50\n",
      "[396/1000 epoch] Train loss = 13.39, Test loss = 12047.57\n",
      "[397/1000 epoch] Train loss = 16.21, Test loss = 12593.24\n",
      "[398/1000 epoch] Train loss = 20.57, Test loss = 11894.57\n",
      "[399/1000 epoch] Train loss = 28.37, Test loss = 12763.92\n",
      "[400/1000 epoch] Train loss = 40.30, Test loss = 11655.87\n",
      "[401/1000 epoch] Train loss = 62.25, Test loss = 13076.71\n",
      "[402/1000 epoch] Train loss = 92.99, Test loss = 11314.91\n",
      "[403/1000 epoch] Train loss = 146.23, Test loss = 13540.04\n",
      "[404/1000 epoch] Train loss = 194.68, Test loss = 11024.76\n",
      "[405/1000 epoch] Train loss = 255.44, Test loss = 13722.97\n",
      "[406/1000 epoch] Train loss = 227.30, Test loss = 11394.80\n",
      "[407/1000 epoch] Train loss = 162.51, Test loss = 13139.98\n",
      "[408/1000 epoch] Train loss = 56.21, Test loss = 12569.94\n",
      "[409/1000 epoch] Train loss = 9.16, Test loss = 12248.66\n",
      "[410/1000 epoch] Train loss = 39.97, Test loss = 13639.38\n",
      "[411/1000 epoch] Train loss = 95.86, Test loss = 11988.03\n",
      "[412/1000 epoch] Train loss = 117.53, Test loss = 13506.65\n",
      "[413/1000 epoch] Train loss = 69.94, Test loss = 12733.44\n",
      "[414/1000 epoch] Train loss = 18.70, Test loss = 12743.30\n",
      "[415/1000 epoch] Train loss = 14.53, Test loss = 13526.23\n",
      "[416/1000 epoch] Train loss = 48.31, Test loss = 12502.89\n",
      "[417/1000 epoch] Train loss = 66.51, Test loss = 13552.72\n",
      "[418/1000 epoch] Train loss = 38.97, Test loss = 12917.50\n",
      "[419/1000 epoch] Train loss = 11.47, Test loss = 12895.72\n",
      "[420/1000 epoch] Train loss = 16.60, Test loss = 13477.59\n",
      "[421/1000 epoch] Train loss = 37.91, Test loss = 12443.49\n",
      "[422/1000 epoch] Train loss = 42.17, Test loss = 13379.26\n",
      "[423/1000 epoch] Train loss = 22.66, Test loss = 12825.30\n",
      "[424/1000 epoch] Train loss = 9.28, Test loss = 12698.14\n",
      "[425/1000 epoch] Train loss = 16.22, Test loss = 13419.21\n",
      "[426/1000 epoch] Train loss = 28.30, Test loss = 12423.74\n",
      "[427/1000 epoch] Train loss = 27.25, Test loss = 13197.27\n",
      "[428/1000 epoch] Train loss = 14.91, Test loss = 12867.89\n",
      "[429/1000 epoch] Train loss = 8.99, Test loss = 12527.50\n",
      "[430/1000 epoch] Train loss = 14.97, Test loss = 13298.68\n",
      "[431/1000 epoch] Train loss = 21.62, Test loss = 12451.82\n",
      "[432/1000 epoch] Train loss = 19.36, Test loss = 13012.47\n",
      "[433/1000 epoch] Train loss = 11.77, Test loss = 12905.08\n",
      "[434/1000 epoch] Train loss = 8.87, Test loss = 12587.03\n",
      "[435/1000 epoch] Train loss = 12.65, Test loss = 13147.97\n",
      "[436/1000 epoch] Train loss = 16.46, Test loss = 12552.08\n",
      "[437/1000 epoch] Train loss = 15.22, Test loss = 12940.17\n",
      "[438/1000 epoch] Train loss = 10.70, Test loss = 12802.57\n",
      "[439/1000 epoch] Train loss = 8.63, Test loss = 12643.19\n",
      "[440/1000 epoch] Train loss = 10.60, Test loss = 13003.41\n",
      "[441/1000 epoch] Train loss = 13.10, Test loss = 12543.22\n",
      "[442/1000 epoch] Train loss = 12.94, Test loss = 12937.03\n",
      "[443/1000 epoch] Train loss = 10.40, Test loss = 12691.27\n",
      "[444/1000 epoch] Train loss = 8.57, Test loss = 12662.08\n",
      "[445/1000 epoch] Train loss = 9.04, Test loss = 12896.51\n",
      "[446/1000 epoch] Train loss = 10.65, Test loss = 12494.89\n",
      "[447/1000 epoch] Train loss = 11.35, Test loss = 12878.66\n",
      "[448/1000 epoch] Train loss = 10.35, Test loss = 12599.84\n",
      "[449/1000 epoch] Train loss = 8.88, Test loss = 12661.99\n",
      "[450/1000 epoch] Train loss = 8.33, Test loss = 12779.72\n",
      "[451/1000 epoch] Train loss = 8.93, Test loss = 12509.58\n",
      "[452/1000 epoch] Train loss = 9.77, Test loss = 12794.89\n",
      "[453/1000 epoch] Train loss = 9.89, Test loss = 12529.33\n",
      "[454/1000 epoch] Train loss = 9.26, Test loss = 12670.23\n",
      "[455/1000 epoch] Train loss = 8.47, Test loss = 12624.77\n",
      "[456/1000 epoch] Train loss = 8.17, Test loss = 12545.74\n",
      "[457/1000 epoch] Train loss = 8.46, Test loss = 12687.60\n",
      "[458/1000 epoch] Train loss = 8.91, Test loss = 12480.99\n",
      "[459/1000 epoch] Train loss = 9.06, Test loss = 12670.75\n",
      "[460/1000 epoch] Train loss = 8.78, Test loss = 12488.29\n",
      "[461/1000 epoch] Train loss = 8.34, Test loss = 12573.63\n",
      "[462/1000 epoch] Train loss = 8.05, Test loss = 12555.07\n",
      "[463/1000 epoch] Train loss = 8.07, Test loss = 12460.96\n",
      "[464/1000 epoch] Train loss = 8.28, Test loss = 12604.87\n",
      "[465/1000 epoch] Train loss = 8.46, Test loss = 12416.95\n",
      "[466/1000 epoch] Train loss = 8.46, Test loss = 12571.73\n",
      "[467/1000 epoch] Train loss = 8.29, Test loss = 12445.07\n",
      "[468/1000 epoch] Train loss = 8.06, Test loss = 12487.15\n",
      "[469/1000 epoch] Train loss = 7.91, Test loss = 12484.90\n",
      "[470/1000 epoch] Train loss = 7.88, Test loss = 12419.70\n",
      "[471/1000 epoch] Train loss = 7.95, Test loss = 12498.59\n",
      "[472/1000 epoch] Train loss = 8.04, Test loss = 12385.58\n",
      "[473/1000 epoch] Train loss = 8.08, Test loss = 12484.28\n",
      "[474/1000 epoch] Train loss = 8.03, Test loss = 12376.68\n",
      "[475/1000 epoch] Train loss = 7.93, Test loss = 12445.74\n",
      "[476/1000 epoch] Train loss = 7.82, Test loss = 12387.72\n",
      "[477/1000 epoch] Train loss = 7.75, Test loss = 12388.33\n",
      "[478/1000 epoch] Train loss = 7.72, Test loss = 12403.84\n",
      "[479/1000 epoch] Train loss = 7.74, Test loss = 12338.27\n",
      "[480/1000 epoch] Train loss = 7.76, Test loss = 12405.57\n",
      "[481/1000 epoch] Train loss = 7.78, Test loss = 12313.55\n",
      "[482/1000 epoch] Train loss = 7.78, Test loss = 12386.41\n",
      "[483/1000 epoch] Train loss = 7.76, Test loss = 12305.31\n",
      "[484/1000 epoch] Train loss = 7.72, Test loss = 12355.98\n",
      "[485/1000 epoch] Train loss = 7.67, Test loss = 12299.40\n",
      "[486/1000 epoch] Train loss = 7.62, Test loss = 12325.36\n",
      "[487/1000 epoch] Train loss = 7.58, Test loss = 12296.59\n",
      "[488/1000 epoch] Train loss = 7.56, Test loss = 12296.54\n",
      "[489/1000 epoch] Train loss = 7.54, Test loss = 12297.31\n",
      "[490/1000 epoch] Train loss = 7.53, Test loss = 12267.97\n",
      "[491/1000 epoch] Train loss = 7.53, Test loss = 12295.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492/1000 epoch] Train loss = 7.52, Test loss = 12241.68\n",
      "[493/1000 epoch] Train loss = 7.52, Test loss = 12288.30\n",
      "[494/1000 epoch] Train loss = 7.52, Test loss = 12220.46\n",
      "[495/1000 epoch] Train loss = 7.52, Test loss = 12278.97\n",
      "[496/1000 epoch] Train loss = 7.52, Test loss = 12202.70\n",
      "[497/1000 epoch] Train loss = 7.51, Test loss = 12268.40\n",
      "[498/1000 epoch] Train loss = 7.51, Test loss = 12181.54\n",
      "[499/1000 epoch] Train loss = 7.52, Test loss = 12258.70\n",
      "[500/1000 epoch] Train loss = 7.53, Test loss = 12150.39\n",
      "[501/1000 epoch] Train loss = 7.56, Test loss = 12253.43\n",
      "[502/1000 epoch] Train loss = 7.62, Test loss = 12110.74\n",
      "[503/1000 epoch] Train loss = 7.72, Test loss = 12259.30\n",
      "[504/1000 epoch] Train loss = 7.90, Test loss = 12060.39\n",
      "[505/1000 epoch] Train loss = 8.19, Test loss = 12283.48\n",
      "[506/1000 epoch] Train loss = 8.67, Test loss = 11989.18\n",
      "[507/1000 epoch] Train loss = 9.51, Test loss = 12340.23\n",
      "[508/1000 epoch] Train loss = 10.92, Test loss = 11873.51\n",
      "[509/1000 epoch] Train loss = 13.43, Test loss = 12456.46\n",
      "[510/1000 epoch] Train loss = 17.79, Test loss = 11675.59\n",
      "[511/1000 epoch] Train loss = 26.04, Test loss = 12693.50\n",
      "[512/1000 epoch] Train loss = 40.56, Test loss = 11350.49\n",
      "[513/1000 epoch] Train loss = 68.89, Test loss = 13146.62\n",
      "[514/1000 epoch] Train loss = 113.63, Test loss = 10909.42\n",
      "[515/1000 epoch] Train loss = 197.41, Test loss = 13837.34\n",
      "[516/1000 epoch] Train loss = 280.72, Test loss = 10616.42\n",
      "[517/1000 epoch] Train loss = 386.13, Test loss = 14175.71\n",
      "[518/1000 epoch] Train loss = 322.94, Test loss = 11376.45\n",
      "[519/1000 epoch] Train loss = 192.36, Test loss = 13411.39\n",
      "[520/1000 epoch] Train loss = 34.17, Test loss = 13416.16\n",
      "[521/1000 epoch] Train loss = 29.78, Test loss = 12236.73\n",
      "[522/1000 epoch] Train loss = 135.11, Test loss = 14796.94\n",
      "[523/1000 epoch] Train loss = 161.27, Test loss = 12744.03\n",
      "[524/1000 epoch] Train loss = 86.85, Test loss = 13745.00\n",
      "[525/1000 epoch] Train loss = 11.81, Test loss = 14565.25\n",
      "[526/1000 epoch] Train loss = 47.79, Test loss = 12958.85\n",
      "[527/1000 epoch] Train loss = 106.67, Test loss = 14533.19\n",
      "[528/1000 epoch] Train loss = 66.56, Test loss = 14062.69\n",
      "[529/1000 epoch] Train loss = 13.19, Test loss = 13532.32\n",
      "[530/1000 epoch] Train loss = 30.27, Test loss = 14545.19\n",
      "[531/1000 epoch] Train loss = 65.26, Test loss = 13519.64\n",
      "[532/1000 epoch] Train loss = 47.91, Test loss = 13916.65\n",
      "[533/1000 epoch] Train loss = 11.35, Test loss = 13935.42\n",
      "[534/1000 epoch] Train loss = 24.28, Test loss = 13228.24\n",
      "[535/1000 epoch] Train loss = 49.07, Test loss = 14029.67\n",
      "[536/1000 epoch] Train loss = 31.40, Test loss = 13282.36\n",
      "[537/1000 epoch] Train loss = 10.21, Test loss = 13355.87\n",
      "[538/1000 epoch] Train loss = 20.76, Test loss = 13916.00\n",
      "[539/1000 epoch] Train loss = 33.35, Test loss = 12861.66\n",
      "[540/1000 epoch] Train loss = 22.48, Test loss = 13567.41\n",
      "[541/1000 epoch] Train loss = 9.76, Test loss = 13486.50\n",
      "[542/1000 epoch] Train loss = 17.13, Test loss = 12668.90\n",
      "[543/1000 epoch] Train loss = 25.78, Test loss = 13676.17\n",
      "[544/1000 epoch] Train loss = 17.45, Test loss = 13009.37\n",
      "[545/1000 epoch] Train loss = 8.86, Test loss = 12780.11\n",
      "[546/1000 epoch] Train loss = 14.02, Test loss = 13640.25\n",
      "[547/1000 epoch] Train loss = 19.93, Test loss = 12717.34\n",
      "[548/1000 epoch] Train loss = 15.12, Test loss = 13044.46\n",
      "[549/1000 epoch] Train loss = 8.81, Test loss = 13361.70\n",
      "[550/1000 epoch] Train loss = 11.36, Test loss = 12647.07\n",
      "[551/1000 epoch] Train loss = 15.81, Test loss = 13209.86\n",
      "[552/1000 epoch] Train loss = 13.40, Test loss = 13029.62\n",
      "[553/1000 epoch] Train loss = 8.99, Test loss = 12771.22\n",
      "[554/1000 epoch] Train loss = 9.48, Test loss = 13167.92\n",
      "[555/1000 epoch] Train loss = 12.60, Test loss = 12811.57\n",
      "[556/1000 epoch] Train loss = 12.40, Test loss = 12918.01\n",
      "[557/1000 epoch] Train loss = 9.20, Test loss = 12933.65\n",
      "[558/1000 epoch] Train loss = 8.36, Test loss = 12763.76\n",
      "[559/1000 epoch] Train loss = 10.43, Test loss = 12938.95\n",
      "[560/1000 epoch] Train loss = 11.13, Test loss = 12716.41\n",
      "[561/1000 epoch] Train loss = 9.34, Test loss = 12862.60\n",
      "[562/1000 epoch] Train loss = 8.04, Test loss = 12816.15\n",
      "[563/1000 epoch] Train loss = 8.90, Test loss = 12663.22\n",
      "[564/1000 epoch] Train loss = 9.96, Test loss = 12925.74\n",
      "[565/1000 epoch] Train loss = 9.37, Test loss = 12633.44\n",
      "[566/1000 epoch] Train loss = 8.16, Test loss = 12744.05\n",
      "[567/1000 epoch] Train loss = 8.02, Test loss = 12847.31\n",
      "[568/1000 epoch] Train loss = 8.80, Test loss = 12555.48\n",
      "[569/1000 epoch] Train loss = 9.08, Test loss = 12854.42\n",
      "[570/1000 epoch] Train loss = 8.39, Test loss = 12695.00\n",
      "[571/1000 epoch] Train loss = 7.76, Test loss = 12622.40\n",
      "[572/1000 epoch] Train loss = 7.98, Test loss = 12844.57\n",
      "[573/1000 epoch] Train loss = 8.46, Test loss = 12586.18\n",
      "[574/1000 epoch] Train loss = 8.39, Test loss = 12721.44\n",
      "[575/1000 epoch] Train loss = 7.90, Test loss = 12724.80\n",
      "[576/1000 epoch] Train loss = 7.64, Test loss = 12600.73\n",
      "[577/1000 epoch] Train loss = 7.82, Test loss = 12746.71\n",
      "[578/1000 epoch] Train loss = 8.06, Test loss = 12634.04\n",
      "[579/1000 epoch] Train loss = 7.99, Test loss = 12675.26\n",
      "[580/1000 epoch] Train loss = 7.67, Test loss = 12675.67\n",
      "[581/1000 epoch] Train loss = 7.50, Test loss = 12638.77\n",
      "[582/1000 epoch] Train loss = 7.61, Test loss = 12682.62\n",
      "[583/1000 epoch] Train loss = 7.76, Test loss = 12613.56\n",
      "[584/1000 epoch] Train loss = 7.71, Test loss = 12686.01\n",
      "[585/1000 epoch] Train loss = 7.52, Test loss = 12616.40\n",
      "[586/1000 epoch] Train loss = 7.40, Test loss = 12636.12\n",
      "[587/1000 epoch] Train loss = 7.43, Test loss = 12669.16\n",
      "[588/1000 epoch] Train loss = 7.51, Test loss = 12572.19\n",
      "[589/1000 epoch] Train loss = 7.51, Test loss = 12678.48\n",
      "[590/1000 epoch] Train loss = 7.41, Test loss = 12595.57\n",
      "[591/1000 epoch] Train loss = 7.31, Test loss = 12607.97\n",
      "[592/1000 epoch] Train loss = 7.28, Test loss = 12659.67\n",
      "[593/1000 epoch] Train loss = 7.31, Test loss = 12563.64\n",
      "[594/1000 epoch] Train loss = 7.33, Test loss = 12647.57\n",
      "[595/1000 epoch] Train loss = 7.28, Test loss = 12594.81\n",
      "[596/1000 epoch] Train loss = 7.21, Test loss = 12588.64\n",
      "[597/1000 epoch] Train loss = 7.15, Test loss = 12623.30\n",
      "[598/1000 epoch] Train loss = 7.13, Test loss = 12569.12\n",
      "[599/1000 epoch] Train loss = 7.14, Test loss = 12606.70\n",
      "[600/1000 epoch] Train loss = 7.12, Test loss = 12576.54\n",
      "[601/1000 epoch] Train loss = 7.08, Test loss = 12584.91\n",
      "[602/1000 epoch] Train loss = 7.02, Test loss = 12569.98\n",
      "[603/1000 epoch] Train loss = 6.97, Test loss = 12567.86\n",
      "[604/1000 epoch] Train loss = 6.95, Test loss = 12567.42\n",
      "[605/1000 epoch] Train loss = 6.93, Test loss = 12539.03\n",
      "[606/1000 epoch] Train loss = 6.89, Test loss = 12571.07\n",
      "[607/1000 epoch] Train loss = 6.85, Test loss = 12520.82\n",
      "[608/1000 epoch] Train loss = 6.80, Test loss = 12548.53\n",
      "[609/1000 epoch] Train loss = 6.75, Test loss = 12529.06\n",
      "[610/1000 epoch] Train loss = 6.72, Test loss = 12509.92\n",
      "[611/1000 epoch] Train loss = 6.71, Test loss = 12532.20\n",
      "[612/1000 epoch] Train loss = 6.70, Test loss = 12489.34\n",
      "[613/1000 epoch] Train loss = 6.69, Test loss = 12512.92\n",
      "[614/1000 epoch] Train loss = 6.67, Test loss = 12486.35\n",
      "[615/1000 epoch] Train loss = 6.66, Test loss = 12489.86\n",
      "[616/1000 epoch] Train loss = 6.63, Test loss = 12478.31\n",
      "[617/1000 epoch] Train loss = 6.61, Test loss = 12474.52\n",
      "[618/1000 epoch] Train loss = 6.60, Test loss = 12464.87\n",
      "[619/1000 epoch] Train loss = 6.59, Test loss = 12458.34\n",
      "[620/1000 epoch] Train loss = 6.57, Test loss = 12459.63\n",
      "[621/1000 epoch] Train loss = 6.56, Test loss = 12436.72\n",
      "[622/1000 epoch] Train loss = 6.54, Test loss = 12454.10\n",
      "[623/1000 epoch] Train loss = 6.53, Test loss = 12424.44\n",
      "[624/1000 epoch] Train loss = 6.51, Test loss = 12432.81\n",
      "[625/1000 epoch] Train loss = 6.49, Test loss = 12420.57\n",
      "[626/1000 epoch] Train loss = 6.48, Test loss = 12408.46\n",
      "[627/1000 epoch] Train loss = 6.46, Test loss = 12406.62\n",
      "[628/1000 epoch] Train loss = 6.45, Test loss = 12393.93\n",
      "[629/1000 epoch] Train loss = 6.44, Test loss = 12387.63\n",
      "[630/1000 epoch] Train loss = 6.43, Test loss = 12376.83\n",
      "[631/1000 epoch] Train loss = 6.42, Test loss = 12373.48\n",
      "[632/1000 epoch] Train loss = 6.41, Test loss = 12354.05\n",
      "[633/1000 epoch] Train loss = 6.40, Test loss = 12357.16\n",
      "[634/1000 epoch] Train loss = 6.39, Test loss = 12333.68\n",
      "[635/1000 epoch] Train loss = 6.38, Test loss = 12334.03\n",
      "[636/1000 epoch] Train loss = 6.36, Test loss = 12318.43\n",
      "[637/1000 epoch] Train loss = 6.35, Test loss = 12310.48\n",
      "[638/1000 epoch] Train loss = 6.34, Test loss = 12299.48\n",
      "[639/1000 epoch] Train loss = 6.33, Test loss = 12290.53\n",
      "[640/1000 epoch] Train loss = 6.32, Test loss = 12277.22\n",
      "[641/1000 epoch] Train loss = 6.31, Test loss = 12268.92\n",
      "[642/1000 epoch] Train loss = 6.30, Test loss = 12258.94\n",
      "[643/1000 epoch] Train loss = 6.29, Test loss = 12247.76\n",
      "[644/1000 epoch] Train loss = 6.29, Test loss = 12243.83\n",
      "[645/1000 epoch] Train loss = 6.28, Test loss = 12229.88\n",
      "[646/1000 epoch] Train loss = 6.27, Test loss = 12228.45\n",
      "[647/1000 epoch] Train loss = 6.26, Test loss = 12213.96\n",
      "[648/1000 epoch] Train loss = 6.25, Test loss = 12211.76\n",
      "[649/1000 epoch] Train loss = 6.24, Test loss = 12197.38\n",
      "[650/1000 epoch] Train loss = 6.24, Test loss = 12197.10\n",
      "[651/1000 epoch] Train loss = 6.23, Test loss = 12180.83\n",
      "[652/1000 epoch] Train loss = 6.22, Test loss = 12184.98\n",
      "[653/1000 epoch] Train loss = 6.21, Test loss = 12165.04\n",
      "[654/1000 epoch] Train loss = 6.21, Test loss = 12173.83\n",
      "[655/1000 epoch] Train loss = 6.20, Test loss = 12149.18\n",
      "[656/1000 epoch] Train loss = 6.20, Test loss = 12162.70\n",
      "[657/1000 epoch] Train loss = 6.19, Test loss = 12132.15\n",
      "[658/1000 epoch] Train loss = 6.19, Test loss = 12153.72\n",
      "[659/1000 epoch] Train loss = 6.20, Test loss = 12112.08\n",
      "[660/1000 epoch] Train loss = 6.21, Test loss = 12150.15\n",
      "[661/1000 epoch] Train loss = 6.23, Test loss = 12088.32\n",
      "[662/1000 epoch] Train loss = 6.26, Test loss = 12151.69\n",
      "[663/1000 epoch] Train loss = 6.33, Test loss = 12059.32\n",
      "[664/1000 epoch] Train loss = 6.45, Test loss = 12161.60\n",
      "[665/1000 epoch] Train loss = 6.65, Test loss = 12018.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[666/1000 epoch] Train loss = 7.01, Test loss = 12190.62\n",
      "[667/1000 epoch] Train loss = 7.63, Test loss = 11951.11\n",
      "[668/1000 epoch] Train loss = 8.77, Test loss = 12259.91\n",
      "[669/1000 epoch] Train loss = 10.71, Test loss = 11838.09\n",
      "[670/1000 epoch] Train loss = 14.38, Test loss = 12399.19\n",
      "[671/1000 epoch] Train loss = 20.52, Test loss = 11647.32\n",
      "[672/1000 epoch] Train loss = 32.53, Test loss = 12661.78\n",
      "[673/1000 epoch] Train loss = 51.87, Test loss = 11325.82\n",
      "[674/1000 epoch] Train loss = 91.81, Test loss = 13160.61\n",
      "[675/1000 epoch] Train loss = 147.43, Test loss = 10810.04\n",
      "[676/1000 epoch] Train loss = 260.92, Test loss = 13942.01\n",
      "[677/1000 epoch] Train loss = 349.80, Test loss = 10368.34\n",
      "[678/1000 epoch] Train loss = 494.97, Test loss = 14441.25\n",
      "[679/1000 epoch] Train loss = 379.36, Test loss = 10906.36\n",
      "[680/1000 epoch] Train loss = 230.85, Test loss = 13377.09\n",
      "[681/1000 epoch] Train loss = 41.30, Test loss = 13026.42\n",
      "[682/1000 epoch] Train loss = 31.79, Test loss = 11731.83\n",
      "[683/1000 epoch] Train loss = 160.47, Test loss = 14884.17\n",
      "[684/1000 epoch] Train loss = 214.05, Test loss = 11742.17\n",
      "[685/1000 epoch] Train loss = 168.64, Test loss = 13836.17\n",
      "[686/1000 epoch] Train loss = 39.95, Test loss = 13824.08\n",
      "[687/1000 epoch] Train loss = 18.13, Test loss = 12395.31\n",
      "[688/1000 epoch] Train loss = 93.50, Test loss = 14803.46\n",
      "[689/1000 epoch] Train loss = 119.05, Test loss = 12978.66\n",
      "[690/1000 epoch] Train loss = 72.10, Test loss = 13767.35\n",
      "[691/1000 epoch] Train loss = 12.36, Test loss = 14309.15\n",
      "[692/1000 epoch] Train loss = 31.35, Test loss = 12918.48\n",
      "[693/1000 epoch] Train loss = 80.45, Test loss = 14383.23\n",
      "[694/1000 epoch] Train loss = 65.26, Test loss = 13317.25\n",
      "[695/1000 epoch] Train loss = 21.72, Test loss = 13479.03\n",
      "[696/1000 epoch] Train loss = 11.01, Test loss = 14100.21\n",
      "[697/1000 epoch] Train loss = 39.48, Test loss = 12941.64\n",
      "[698/1000 epoch] Train loss = 55.87, Test loss = 14107.04\n",
      "[699/1000 epoch] Train loss = 30.55, Test loss = 13314.56\n",
      "[700/1000 epoch] Train loss = 8.97, Test loss = 13262.16\n",
      "[701/1000 epoch] Train loss = 17.88, Test loss = 13964.61\n",
      "[702/1000 epoch] Train loss = 34.62, Test loss = 12695.94\n",
      "[703/1000 epoch] Train loss = 31.87, Test loss = 13746.35\n",
      "[704/1000 epoch] Train loss = 13.61, Test loss = 13216.23\n",
      "[705/1000 epoch] Train loss = 8.63, Test loss = 12831.99\n",
      "[706/1000 epoch] Train loss = 19.52, Test loss = 13815.64\n",
      "[707/1000 epoch] Train loss = 25.53, Test loss = 12615.53\n",
      "[708/1000 epoch] Train loss = 18.26, Test loss = 13329.52\n",
      "[709/1000 epoch] Train loss = 8.53, Test loss = 13301.46\n",
      "[710/1000 epoch] Train loss = 9.89, Test loss = 12579.87\n",
      "[711/1000 epoch] Train loss = 17.35, Test loss = 13571.83\n",
      "[712/1000 epoch] Train loss = 17.95, Test loss = 12735.81\n",
      "[713/1000 epoch] Train loss = 11.58, Test loss = 12967.54\n",
      "[714/1000 epoch] Train loss = 7.55, Test loss = 13291.94\n",
      "[715/1000 epoch] Train loss = 10.39, Test loss = 12566.51\n",
      "[716/1000 epoch] Train loss = 14.30, Test loss = 13227.53\n",
      "[717/1000 epoch] Train loss = 13.07, Test loss = 12779.92\n",
      "[718/1000 epoch] Train loss = 8.98, Test loss = 12760.23\n",
      "[719/1000 epoch] Train loss = 7.40, Test loss = 13056.81\n",
      "[720/1000 epoch] Train loss = 9.55, Test loss = 12572.34\n",
      "[721/1000 epoch] Train loss = 11.59, Test loss = 13000.42\n",
      "[722/1000 epoch] Train loss = 10.47, Test loss = 12717.80\n",
      "[723/1000 epoch] Train loss = 7.97, Test loss = 12761.28\n",
      "[724/1000 epoch] Train loss = 7.21, Test loss = 12906.27\n",
      "[725/1000 epoch] Train loss = 8.56, Test loss = 12593.58\n",
      "[726/1000 epoch] Train loss = 9.72, Test loss = 12932.17\n",
      "[727/1000 epoch] Train loss = 9.04, Test loss = 12637.93\n",
      "[728/1000 epoch] Train loss = 7.55, Test loss = 12763.13\n",
      "[729/1000 epoch] Train loss = 7.00, Test loss = 12836.48\n",
      "[730/1000 epoch] Train loss = 7.70, Test loss = 12586.62\n",
      "[731/1000 epoch] Train loss = 8.46, Test loss = 12913.73\n",
      "[732/1000 epoch] Train loss = 8.24, Test loss = 12615.38\n",
      "[733/1000 epoch] Train loss = 7.38, Test loss = 12749.93\n",
      "[734/1000 epoch] Train loss = 6.86, Test loss = 12785.76\n",
      "[735/1000 epoch] Train loss = 7.12, Test loss = 12571.86\n",
      "[736/1000 epoch] Train loss = 7.63, Test loss = 12848.33\n",
      "[737/1000 epoch] Train loss = 7.71, Test loss = 12592.12\n",
      "[738/1000 epoch] Train loss = 7.28, Test loss = 12721.80\n",
      "[739/1000 epoch] Train loss = 6.84, Test loss = 12728.60\n",
      "[740/1000 epoch] Train loss = 6.80, Test loss = 12586.76\n",
      "[741/1000 epoch] Train loss = 7.06, Test loss = 12776.03\n",
      "[742/1000 epoch] Train loss = 7.25, Test loss = 12581.45\n",
      "[743/1000 epoch] Train loss = 7.14, Test loss = 12695.11\n",
      "[744/1000 epoch] Train loss = 6.85, Test loss = 12656.92\n",
      "[745/1000 epoch] Train loss = 6.67, Test loss = 12604.75\n",
      "[746/1000 epoch] Train loss = 6.71, Test loss = 12698.28\n",
      "[747/1000 epoch] Train loss = 6.86, Test loss = 12576.82\n",
      "[748/1000 epoch] Train loss = 6.93, Test loss = 12679.79\n",
      "[749/1000 epoch] Train loss = 6.84, Test loss = 12592.74\n",
      "[750/1000 epoch] Train loss = 6.67, Test loss = 12633.85\n",
      "[751/1000 epoch] Train loss = 6.57, Test loss = 12631.82\n",
      "[752/1000 epoch] Train loss = 6.58, Test loss = 12585.97\n",
      "[753/1000 epoch] Train loss = 6.66, Test loss = 12667.43\n",
      "[754/1000 epoch] Train loss = 6.70, Test loss = 12563.82\n",
      "[755/1000 epoch] Train loss = 6.66, Test loss = 12662.27\n",
      "[756/1000 epoch] Train loss = 6.58, Test loss = 12586.36\n",
      "[757/1000 epoch] Train loss = 6.50, Test loss = 12608.12\n",
      "[758/1000 epoch] Train loss = 6.47, Test loss = 12633.48\n",
      "[759/1000 epoch] Train loss = 6.49, Test loss = 12559.67\n",
      "[760/1000 epoch] Train loss = 6.52, Test loss = 12652.62\n",
      "[761/1000 epoch] Train loss = 6.53, Test loss = 12560.10\n",
      "[762/1000 epoch] Train loss = 6.50, Test loss = 12625.98\n",
      "[763/1000 epoch] Train loss = 6.44, Test loss = 12594.60\n",
      "[764/1000 epoch] Train loss = 6.40, Test loss = 12585.95\n",
      "[765/1000 epoch] Train loss = 6.38, Test loss = 12619.82\n",
      "[766/1000 epoch] Train loss = 6.38, Test loss = 12568.22\n",
      "[767/1000 epoch] Train loss = 6.39, Test loss = 12617.83\n",
      "[768/1000 epoch] Train loss = 6.39, Test loss = 12571.67\n",
      "[769/1000 epoch] Train loss = 6.38, Test loss = 12606.96\n",
      "[770/1000 epoch] Train loss = 6.35, Test loss = 12576.26\n",
      "[771/1000 epoch] Train loss = 6.32, Test loss = 12596.71\n",
      "[772/1000 epoch] Train loss = 6.30, Test loss = 12580.08\n",
      "[773/1000 epoch] Train loss = 6.28, Test loss = 12581.27\n",
      "[774/1000 epoch] Train loss = 6.28, Test loss = 12588.00\n",
      "[775/1000 epoch] Train loss = 6.27, Test loss = 12561.97\n",
      "[776/1000 epoch] Train loss = 6.27, Test loss = 12599.99\n",
      "[777/1000 epoch] Train loss = 6.25, Test loss = 12549.95\n",
      "[778/1000 epoch] Train loss = 6.24, Test loss = 12597.72\n",
      "[779/1000 epoch] Train loss = 6.22, Test loss = 12558.13\n",
      "[780/1000 epoch] Train loss = 6.20, Test loss = 12573.93\n",
      "[781/1000 epoch] Train loss = 6.18, Test loss = 12576.22\n",
      "[782/1000 epoch] Train loss = 6.17, Test loss = 12552.35\n",
      "[783/1000 epoch] Train loss = 6.16, Test loss = 12579.80\n",
      "[784/1000 epoch] Train loss = 6.15, Test loss = 12552.12\n",
      "[785/1000 epoch] Train loss = 6.14, Test loss = 12568.62\n",
      "[786/1000 epoch] Train loss = 6.13, Test loss = 12557.52\n",
      "[787/1000 epoch] Train loss = 6.11, Test loss = 12560.21\n",
      "[788/1000 epoch] Train loss = 6.10, Test loss = 12553.75\n",
      "[789/1000 epoch] Train loss = 6.09, Test loss = 12561.33\n",
      "[790/1000 epoch] Train loss = 6.07, Test loss = 12543.43\n",
      "[791/1000 epoch] Train loss = 6.06, Test loss = 12563.14\n",
      "[792/1000 epoch] Train loss = 6.04, Test loss = 12543.46\n",
      "[793/1000 epoch] Train loss = 6.03, Test loss = 12551.46\n",
      "[794/1000 epoch] Train loss = 6.02, Test loss = 12552.71\n",
      "[795/1000 epoch] Train loss = 6.01, Test loss = 12538.09\n",
      "[796/1000 epoch] Train loss = 6.00, Test loss = 12556.82\n",
      "[797/1000 epoch] Train loss = 5.99, Test loss = 12535.32\n",
      "[798/1000 epoch] Train loss = 5.98, Test loss = 12552.72\n",
      "[799/1000 epoch] Train loss = 5.97, Test loss = 12535.79\n",
      "[800/1000 epoch] Train loss = 5.96, Test loss = 12547.15\n",
      "[801/1000 epoch] Train loss = 5.95, Test loss = 12532.80\n",
      "[802/1000 epoch] Train loss = 5.94, Test loss = 12543.14\n",
      "[803/1000 epoch] Train loss = 5.94, Test loss = 12528.26\n",
      "[804/1000 epoch] Train loss = 5.93, Test loss = 12542.49\n",
      "[805/1000 epoch] Train loss = 5.92, Test loss = 12520.40\n",
      "[806/1000 epoch] Train loss = 5.91, Test loss = 12542.71\n",
      "[807/1000 epoch] Train loss = 5.90, Test loss = 12513.89\n",
      "[808/1000 epoch] Train loss = 5.90, Test loss = 12538.43\n",
      "[809/1000 epoch] Train loss = 5.89, Test loss = 12511.64\n",
      "[810/1000 epoch] Train loss = 5.88, Test loss = 12531.70\n",
      "[811/1000 epoch] Train loss = 5.88, Test loss = 12508.66\n",
      "[812/1000 epoch] Train loss = 5.87, Test loss = 12528.92\n",
      "[813/1000 epoch] Train loss = 5.87, Test loss = 12498.55\n",
      "[814/1000 epoch] Train loss = 5.87, Test loss = 12534.70\n",
      "[815/1000 epoch] Train loss = 5.87, Test loss = 12479.80\n",
      "[816/1000 epoch] Train loss = 5.88, Test loss = 12544.88\n",
      "[817/1000 epoch] Train loss = 5.90, Test loss = 12458.50\n",
      "[818/1000 epoch] Train loss = 5.93, Test loss = 12554.80\n",
      "[819/1000 epoch] Train loss = 5.98, Test loss = 12438.65\n",
      "[820/1000 epoch] Train loss = 6.06, Test loss = 12567.48\n",
      "[821/1000 epoch] Train loss = 6.19, Test loss = 12409.68\n",
      "[822/1000 epoch] Train loss = 6.42, Test loss = 12595.96\n",
      "[823/1000 epoch] Train loss = 6.77, Test loss = 12355.73\n",
      "[824/1000 epoch] Train loss = 7.38, Test loss = 12655.09\n",
      "[825/1000 epoch] Train loss = 8.34, Test loss = 12266.72\n",
      "[826/1000 epoch] Train loss = 9.98, Test loss = 12763.76\n",
      "[827/1000 epoch] Train loss = 12.61, Test loss = 12123.34\n",
      "[828/1000 epoch] Train loss = 17.32, Test loss = 12956.83\n",
      "[829/1000 epoch] Train loss = 24.72, Test loss = 11889.49\n",
      "[830/1000 epoch] Train loss = 38.40, Test loss = 13290.41\n",
      "[831/1000 epoch] Train loss = 59.35, Test loss = 11525.67\n",
      "[832/1000 epoch] Train loss = 99.22, Test loss = 13818.84\n",
      "[833/1000 epoch] Train loss = 149.24, Test loss = 11084.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[834/1000 epoch] Train loss = 242.57, Test loss = 14542.36\n",
      "[835/1000 epoch] Train loss = 307.34, Test loss = 10843.45\n",
      "[836/1000 epoch] Train loss = 400.56, Test loss = 14902.25\n",
      "[837/1000 epoch] Train loss = 312.13, Test loss = 11599.53\n",
      "[838/1000 epoch] Train loss = 197.12, Test loss = 14161.06\n",
      "[839/1000 epoch] Train loss = 46.69, Test loss = 13532.50\n",
      "[840/1000 epoch] Train loss = 15.22, Test loss = 12848.87\n",
      "[841/1000 epoch] Train loss = 93.35, Test loss = 15400.32\n",
      "[842/1000 epoch] Train loss = 155.49, Test loss = 12442.92\n",
      "[843/1000 epoch] Train loss = 144.30, Test loss = 15075.26\n",
      "[844/1000 epoch] Train loss = 50.40, Test loss = 14290.12\n",
      "[845/1000 epoch] Train loss = 8.88, Test loss = 13408.28\n",
      "[846/1000 epoch] Train loss = 47.82, Test loss = 15734.53\n",
      "[847/1000 epoch] Train loss = 89.71, Test loss = 13413.08\n",
      "[848/1000 epoch] Train loss = 81.46, Test loss = 14987.35\n",
      "[849/1000 epoch] Train loss = 27.28, Test loss = 14866.11\n",
      "[850/1000 epoch] Train loss = 8.89, Test loss = 13724.64\n",
      "[851/1000 epoch] Train loss = 37.19, Test loss = 15325.81\n",
      "[852/1000 epoch] Train loss = 58.58, Test loss = 13839.39\n",
      "[853/1000 epoch] Train loss = 45.90, Test loss = 14506.24\n",
      "[854/1000 epoch] Train loss = 14.90, Test loss = 14542.98\n",
      "[855/1000 epoch] Train loss = 9.69, Test loss = 13774.62\n",
      "[856/1000 epoch] Train loss = 29.19, Test loss = 14735.81\n",
      "[857/1000 epoch] Train loss = 39.01, Test loss = 13640.16\n",
      "[858/1000 epoch] Train loss = 27.43, Test loss = 14238.99\n",
      "[859/1000 epoch] Train loss = 9.85, Test loss = 13929.55\n",
      "[860/1000 epoch] Train loss = 9.72, Test loss = 13457.50\n",
      "[861/1000 epoch] Train loss = 21.88, Test loss = 14211.64\n",
      "[862/1000 epoch] Train loss = 25.63, Test loss = 13052.27\n",
      "[863/1000 epoch] Train loss = 17.49, Test loss = 13908.70\n",
      "[864/1000 epoch] Train loss = 8.30, Test loss = 13436.31\n",
      "[865/1000 epoch] Train loss = 9.06, Test loss = 13066.69\n",
      "[866/1000 epoch] Train loss = 15.85, Test loss = 13965.22\n",
      "[867/1000 epoch] Train loss = 18.09, Test loss = 12705.27\n",
      "[868/1000 epoch] Train loss = 13.50, Test loss = 13617.85\n",
      "[869/1000 epoch] Train loss = 7.92, Test loss = 13265.03\n",
      "[870/1000 epoch] Train loss = 7.79, Test loss = 12781.99\n",
      "[871/1000 epoch] Train loss = 11.81, Test loss = 13781.01\n",
      "[872/1000 epoch] Train loss = 13.85, Test loss = 12618.87\n",
      "[873/1000 epoch] Train loss = 11.26, Test loss = 13346.56\n",
      "[874/1000 epoch] Train loss = 7.45, Test loss = 13204.03\n",
      "[875/1000 epoch] Train loss = 6.86, Test loss = 12656.90\n",
      "[876/1000 epoch] Train loss = 9.24, Test loss = 13519.56\n",
      "[877/1000 epoch] Train loss = 10.85, Test loss = 12640.59\n",
      "[878/1000 epoch] Train loss = 9.71, Test loss = 13128.41\n",
      "[879/1000 epoch] Train loss = 7.41, Test loss = 13099.22\n",
      "[880/1000 epoch] Train loss = 6.57, Test loss = 12696.48\n",
      "[881/1000 epoch] Train loss = 7.58, Test loss = 13285.63\n",
      "[882/1000 epoch] Train loss = 8.78, Test loss = 12705.96\n",
      "[883/1000 epoch] Train loss = 8.70, Test loss = 13042.67\n",
      "[884/1000 epoch] Train loss = 7.51, Test loss = 12946.41\n",
      "[885/1000 epoch] Train loss = 6.52, Test loss = 12783.17\n",
      "[886/1000 epoch] Train loss = 6.58, Test loss = 13066.74\n",
      "[887/1000 epoch] Train loss = 7.33, Test loss = 12729.93\n",
      "[888/1000 epoch] Train loss = 7.79, Test loss = 12997.93\n",
      "[889/1000 epoch] Train loss = 7.41, Test loss = 12799.27\n",
      "[890/1000 epoch] Train loss = 6.65, Test loss = 12856.65\n",
      "[891/1000 epoch] Train loss = 6.25, Test loss = 12882.25\n",
      "[892/1000 epoch] Train loss = 6.48, Test loss = 12730.94\n",
      "[893/1000 epoch] Train loss = 6.92, Test loss = 12933.35\n",
      "[894/1000 epoch] Train loss = 7.04, Test loss = 12680.82\n",
      "[895/1000 epoch] Train loss = 6.75, Test loss = 12898.67\n",
      "[896/1000 epoch] Train loss = 6.36, Test loss = 12738.65\n",
      "[897/1000 epoch] Train loss = 6.17, Test loss = 12761.16\n",
      "[898/1000 epoch] Train loss = 6.27, Test loss = 12855.25\n",
      "[899/1000 epoch] Train loss = 6.47, Test loss = 12633.68\n",
      "[900/1000 epoch] Train loss = 6.55, Test loss = 12890.60\n",
      "[901/1000 epoch] Train loss = 6.44, Test loss = 12644.55\n",
      "[902/1000 epoch] Train loss = 6.23, Test loss = 12784.26\n",
      "[903/1000 epoch] Train loss = 6.07, Test loss = 12761.63\n",
      "[904/1000 epoch] Train loss = 6.07, Test loss = 12644.68\n",
      "[905/1000 epoch] Train loss = 6.17, Test loss = 12839.40\n",
      "[906/1000 epoch] Train loss = 6.25, Test loss = 12605.85\n",
      "[907/1000 epoch] Train loss = 6.24, Test loss = 12794.50\n",
      "[908/1000 epoch] Train loss = 6.13, Test loss = 12679.57\n",
      "[909/1000 epoch] Train loss = 6.02, Test loss = 12691.23\n",
      "[910/1000 epoch] Train loss = 5.97, Test loss = 12759.45\n",
      "[911/1000 epoch] Train loss = 5.98, Test loss = 12635.30\n",
      "[912/1000 epoch] Train loss = 6.02, Test loss = 12766.80\n",
      "[913/1000 epoch] Train loss = 6.05, Test loss = 12653.68\n",
      "[914/1000 epoch] Train loss = 6.03, Test loss = 12722.27\n",
      "[915/1000 epoch] Train loss = 5.98, Test loss = 12693.21\n",
      "[916/1000 epoch] Train loss = 5.92, Test loss = 12686.90\n",
      "[917/1000 epoch] Train loss = 5.88, Test loss = 12709.26\n",
      "[918/1000 epoch] Train loss = 5.87, Test loss = 12678.54\n",
      "[919/1000 epoch] Train loss = 5.88, Test loss = 12715.16\n",
      "[920/1000 epoch] Train loss = 5.90, Test loss = 12672.05\n",
      "[921/1000 epoch] Train loss = 5.90, Test loss = 12726.64\n",
      "[922/1000 epoch] Train loss = 5.88, Test loss = 12663.59\n",
      "[923/1000 epoch] Train loss = 5.84, Test loss = 12727.71\n",
      "[924/1000 epoch] Train loss = 5.81, Test loss = 12674.60\n",
      "[925/1000 epoch] Train loss = 5.79, Test loss = 12704.01\n",
      "[926/1000 epoch] Train loss = 5.78, Test loss = 12708.21\n",
      "[927/1000 epoch] Train loss = 5.77, Test loss = 12670.91\n",
      "[928/1000 epoch] Train loss = 5.77, Test loss = 12734.02\n",
      "[929/1000 epoch] Train loss = 5.77, Test loss = 12656.26\n",
      "[930/1000 epoch] Train loss = 5.76, Test loss = 12732.17\n",
      "[931/1000 epoch] Train loss = 5.75, Test loss = 12667.12\n",
      "[932/1000 epoch] Train loss = 5.73, Test loss = 12708.03\n",
      "[933/1000 epoch] Train loss = 5.71, Test loss = 12689.48\n",
      "[934/1000 epoch] Train loss = 5.70, Test loss = 12682.23\n",
      "[935/1000 epoch] Train loss = 5.68, Test loss = 12703.41\n",
      "[936/1000 epoch] Train loss = 5.67, Test loss = 12673.31\n",
      "[937/1000 epoch] Train loss = 5.67, Test loss = 12702.29\n",
      "[938/1000 epoch] Train loss = 5.66, Test loss = 12673.31\n",
      "[939/1000 epoch] Train loss = 5.66, Test loss = 12696.60\n",
      "[940/1000 epoch] Train loss = 5.65, Test loss = 12668.34\n",
      "[941/1000 epoch] Train loss = 5.64, Test loss = 12695.80\n",
      "[942/1000 epoch] Train loss = 5.63, Test loss = 12659.24\n",
      "[943/1000 epoch] Train loss = 5.62, Test loss = 12693.85\n",
      "[944/1000 epoch] Train loss = 5.61, Test loss = 12655.96\n",
      "[945/1000 epoch] Train loss = 5.60, Test loss = 12684.30\n",
      "[946/1000 epoch] Train loss = 5.59, Test loss = 12659.99\n",
      "[947/1000 epoch] Train loss = 5.58, Test loss = 12667.23\n",
      "[948/1000 epoch] Train loss = 5.57, Test loss = 12667.44\n",
      "[949/1000 epoch] Train loss = 5.56, Test loss = 12652.74\n",
      "[950/1000 epoch] Train loss = 5.55, Test loss = 12671.25\n",
      "[951/1000 epoch] Train loss = 5.55, Test loss = 12643.70\n",
      "[952/1000 epoch] Train loss = 5.54, Test loss = 12668.64\n",
      "[953/1000 epoch] Train loss = 5.54, Test loss = 12639.31\n",
      "[954/1000 epoch] Train loss = 5.53, Test loss = 12663.23\n",
      "[955/1000 epoch] Train loss = 5.52, Test loss = 12635.49\n",
      "[956/1000 epoch] Train loss = 5.52, Test loss = 12659.90\n",
      "[957/1000 epoch] Train loss = 5.51, Test loss = 12630.52\n",
      "[958/1000 epoch] Train loss = 5.51, Test loss = 12658.79\n",
      "[959/1000 epoch] Train loss = 5.50, Test loss = 12625.29\n",
      "[960/1000 epoch] Train loss = 5.50, Test loss = 12660.37\n",
      "[961/1000 epoch] Train loss = 5.50, Test loss = 12615.69\n",
      "[962/1000 epoch] Train loss = 5.49, Test loss = 12665.31\n",
      "[963/1000 epoch] Train loss = 5.49, Test loss = 12604.55\n",
      "[964/1000 epoch] Train loss = 5.49, Test loss = 12669.49\n",
      "[965/1000 epoch] Train loss = 5.49, Test loss = 12594.75\n",
      "[966/1000 epoch] Train loss = 5.50, Test loss = 12672.32\n",
      "[967/1000 epoch] Train loss = 5.51, Test loss = 12584.37\n",
      "[968/1000 epoch] Train loss = 5.53, Test loss = 12678.56\n",
      "[969/1000 epoch] Train loss = 5.56, Test loss = 12566.36\n",
      "[970/1000 epoch] Train loss = 5.60, Test loss = 12694.79\n",
      "[971/1000 epoch] Train loss = 5.67, Test loss = 12536.65\n",
      "[972/1000 epoch] Train loss = 5.78, Test loss = 12723.80\n",
      "[973/1000 epoch] Train loss = 5.94, Test loss = 12493.02\n",
      "[974/1000 epoch] Train loss = 6.20, Test loss = 12769.69\n",
      "[975/1000 epoch] Train loss = 6.59, Test loss = 12430.00\n",
      "[976/1000 epoch] Train loss = 7.22, Test loss = 12843.47\n",
      "[977/1000 epoch] Train loss = 8.20, Test loss = 12333.64\n",
      "[978/1000 epoch] Train loss = 9.82, Test loss = 12968.24\n",
      "[979/1000 epoch] Train loss = 12.32, Test loss = 12177.95\n",
      "[980/1000 epoch] Train loss = 16.58, Test loss = 13186.83\n",
      "[981/1000 epoch] Train loss = 23.00, Test loss = 11929.76\n",
      "[982/1000 epoch] Train loss = 34.19, Test loss = 13534.76\n",
      "[983/1000 epoch] Train loss = 50.08, Test loss = 11598.09\n",
      "[984/1000 epoch] Train loss = 78.83, Test loss = 14055.92\n",
      "[985/1000 epoch] Train loss = 115.47, Test loss = 11216.00\n",
      "[986/1000 epoch] Train loss = 182.14, Test loss = 14681.49\n",
      "[987/1000 epoch] Train loss = 233.45, Test loss = 11094.56\n",
      "[988/1000 epoch] Train loss = 324.42, Test loss = 15069.38\n",
      "[989/1000 epoch] Train loss = 308.20, Test loss = 11630.95\n",
      "[990/1000 epoch] Train loss = 290.79, Test loss = 14876.60\n",
      "[991/1000 epoch] Train loss = 147.62, Test loss = 12946.62\n",
      "[992/1000 epoch] Train loss = 40.82, Test loss = 14080.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993/1000 epoch] Train loss = 8.61, Test loss = 14760.70\n",
      "[994/1000 epoch] Train loss = 57.35, Test loss = 13074.71\n",
      "[995/1000 epoch] Train loss = 129.99, Test loss = 15789.43\n",
      "[996/1000 epoch] Train loss = 128.53, Test loss = 13295.61\n",
      "[997/1000 epoch] Train loss = 84.63, Test loss = 14963.71\n",
      "[998/1000 epoch] Train loss = 21.00, Test loss = 14837.99\n",
      "[999/1000 epoch] Train loss = 11.05, Test loss = 13711.88\n",
      "[1000/1000 epoch] Train loss = 47.98, Test loss = 15691.92\n",
      "CPU times: user 1.03 s, sys: 663 ms, total: 1.7 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = PredictionModel()\n",
    "# в качестве параметров оптимизатору передаем параметры нашей модели\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "# в качестве функции ошибки используем MSE, так как решаем задачу регрессии\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # включим режим обучения\n",
    "    model.train()\n",
    "    \n",
    "    # обнулим все градиенты, чтобы делать градиентный спуск только по текущим данным\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_preds = model(x_train.unsqueeze(-1))\n",
    "    train_loss = criterion(y_preds, y_train.unsqueeze(-1))\n",
    "    \n",
    "    # сделаем обратное распространение ошибки\n",
    "    train_loss.backward()\n",
    "    # и шаг градиентного спуска с помощью оптимизатора\n",
    "    optimizer.step()\n",
    "    \n",
    "    # включим режим инференса\n",
    "    model.eval()\n",
    "    \n",
    "    # режим no_grad отключает подсчет градиентов\n",
    "    with torch.no_grad():\n",
    "        y_preds = model(x_test.unsqueeze(-1)).squeeze(-1)\n",
    "    \n",
    "    test_loss = criterion(y_preds, y_test)\n",
    "    \n",
    "    print(f'[{epoch + 1}/{n_epochs} epoch] Train loss = {train_loss:.2f}, Test loss = {test_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bdc3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_ordered_inds = torch.argsort(x_test)\n",
    "with torch.no_grad():\n",
    "    y_preds = model(x_test.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "plt.plot(x_train, y_train, c='black', label='train')\n",
    "plt.plot(x_test, y_test, c='b', label='test')\n",
    "plt.plot(x_test, y_preds, c='r', label='predictions')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ae6fa",
   "metadata": {},
   "source": [
    "Как теперь использовать gpu (и не только) для ускорения обучения?\n",
    "\n",
    "Для этого нужно две вещи:\n",
    "- перенести модель на девайс `model.to(device)`\n",
    "- перенести данные на девайс `data.to(device)`\n",
    "\n",
    "попробуем это применить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d34a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    # если есть gpu с поддержкой cuda\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    # если у вас mac на apple silicon чипе, то тоже можно ускорить\n",
    "    device = torch.device('mps')\n",
    "print(f'using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def73f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000 epoch] Train loss = 108655.42, Test loss = 601252.69\n",
      "[2/1000 epoch] Train loss = 108430.91, Test loss = 598418.50\n",
      "[3/1000 epoch] Train loss = 107952.32, Test loss = 592693.50\n",
      "[4/1000 epoch] Train loss = 107019.78, Test loss = 582315.62\n",
      "[5/1000 epoch] Train loss = 105377.23, Test loss = 564409.38\n",
      "[6/1000 epoch] Train loss = 102668.73, Test loss = 535655.38\n",
      "[7/1000 epoch] Train loss = 98501.35, Test loss = 492204.59\n",
      "[8/1000 epoch] Train loss = 92311.41, Test loss = 430423.62\n",
      "[9/1000 epoch] Train loss = 83832.25, Test loss = 347260.28\n",
      "[10/1000 epoch] Train loss = 73067.98, Test loss = 243929.16\n",
      "[11/1000 epoch] Train loss = 60498.81, Test loss = 129808.48\n",
      "[12/1000 epoch] Train loss = 48704.29, Test loss = 53712.52\n",
      "[13/1000 epoch] Train loss = 39863.91, Test loss = 46965.36\n",
      "[14/1000 epoch] Train loss = 29037.39, Test loss = 76163.04\n",
      "[15/1000 epoch] Train loss = 19917.18, Test loss = 141662.95\n",
      "[16/1000 epoch] Train loss = 22505.50, Test loss = 224815.41\n",
      "[17/1000 epoch] Train loss = 33934.91, Test loss = 251176.34\n",
      "[18/1000 epoch] Train loss = 35379.56, Test loss = 243265.30\n",
      "[19/1000 epoch] Train loss = 28818.88, Test loss = 221094.22\n",
      "[20/1000 epoch] Train loss = 21786.63, Test loss = 192527.92\n",
      "[21/1000 epoch] Train loss = 18087.97, Test loss = 165045.58\n",
      "[22/1000 epoch] Train loss = 17984.74, Test loss = 143480.30\n",
      "[23/1000 epoch] Train loss = 19865.71, Test loss = 126494.18\n",
      "[24/1000 epoch] Train loss = 22059.59, Test loss = 116997.78\n",
      "[25/1000 epoch] Train loss = 23494.47, Test loss = 115583.41\n",
      "[26/1000 epoch] Train loss = 23856.79, Test loss = 121623.41\n",
      "[27/1000 epoch] Train loss = 23120.76, Test loss = 132679.20\n",
      "[28/1000 epoch] Train loss = 21594.95, Test loss = 145975.86\n",
      "[29/1000 epoch] Train loss = 19756.00, Test loss = 158493.88\n",
      "[30/1000 epoch] Train loss = 18059.82, Test loss = 167708.41\n",
      "[31/1000 epoch] Train loss = 16943.85, Test loss = 172108.09\n",
      "[32/1000 epoch] Train loss = 16665.10, Test loss = 171126.86\n",
      "[33/1000 epoch] Train loss = 17123.88, Test loss = 165143.06\n",
      "[34/1000 epoch] Train loss = 17815.97, Test loss = 155455.03\n",
      "[35/1000 epoch] Train loss = 18079.03, Test loss = 144014.97\n",
      "[36/1000 epoch] Train loss = 17630.25, Test loss = 132916.55\n",
      "[37/1000 epoch] Train loss = 16659.61, Test loss = 124283.98\n",
      "[38/1000 epoch] Train loss = 15816.85, Test loss = 119689.82\n",
      "[39/1000 epoch] Train loss = 15507.85, Test loss = 119737.84\n",
      "[40/1000 epoch] Train loss = 15729.85, Test loss = 123950.27\n",
      "[41/1000 epoch] Train loss = 16033.93, Test loss = 130903.05\n",
      "[42/1000 epoch] Train loss = 16019.22, Test loss = 138797.06\n",
      "[43/1000 epoch] Train loss = 15651.98, Test loss = 145535.20\n",
      "[44/1000 epoch] Train loss = 15055.08, Test loss = 149171.20\n",
      "[45/1000 epoch] Train loss = 14569.77, Test loss = 149071.61\n",
      "[46/1000 epoch] Train loss = 14345.03, Test loss = 145071.58\n",
      "[47/1000 epoch] Train loss = 14261.78, Test loss = 138017.06\n",
      "[48/1000 epoch] Train loss = 14160.96, Test loss = 129476.77\n",
      "[49/1000 epoch] Train loss = 13899.19, Test loss = 121579.11\n",
      "[50/1000 epoch] Train loss = 13509.68, Test loss = 116343.36\n",
      "[51/1000 epoch] Train loss = 13160.34, Test loss = 114905.78\n",
      "[52/1000 epoch] Train loss = 12905.09, Test loss = 116804.65\n",
      "[53/1000 epoch] Train loss = 12751.75, Test loss = 121329.07\n",
      "[54/1000 epoch] Train loss = 12585.73, Test loss = 127120.48\n",
      "[55/1000 epoch] Train loss = 12206.29, Test loss = 129695.64\n",
      "[56/1000 epoch] Train loss = 11701.36, Test loss = 129279.89\n",
      "[57/1000 epoch] Train loss = 11410.86, Test loss = 125624.42\n",
      "[58/1000 epoch] Train loss = 11179.75, Test loss = 119401.58\n",
      "[59/1000 epoch] Train loss = 10868.46, Test loss = 112180.60\n",
      "[60/1000 epoch] Train loss = 10387.60, Test loss = 105905.00\n",
      "[61/1000 epoch] Train loss = 9883.75, Test loss = 102288.00\n",
      "[62/1000 epoch] Train loss = 9565.62, Test loss = 102069.76\n",
      "[63/1000 epoch] Train loss = 9150.98, Test loss = 104977.38\n",
      "[64/1000 epoch] Train loss = 8516.00, Test loss = 108313.96\n",
      "[65/1000 epoch] Train loss = 8015.72, Test loss = 109074.49\n",
      "[66/1000 epoch] Train loss = 7612.44, Test loss = 105882.14\n",
      "[67/1000 epoch] Train loss = 7048.33, Test loss = 100385.46\n",
      "[68/1000 epoch] Train loss = 6792.64, Test loss = 95921.98\n",
      "[69/1000 epoch] Train loss = 6231.52, Test loss = 92674.66\n",
      "[70/1000 epoch] Train loss = 5950.42, Test loss = 89409.78\n",
      "[71/1000 epoch] Train loss = 5518.91, Test loss = 87705.94\n",
      "[72/1000 epoch] Train loss = 5285.47, Test loss = 89324.84\n",
      "[73/1000 epoch] Train loss = 4908.98, Test loss = 90916.90\n",
      "[74/1000 epoch] Train loss = 4765.11, Test loss = 88828.56\n",
      "[75/1000 epoch] Train loss = 4399.84, Test loss = 84962.38\n",
      "[76/1000 epoch] Train loss = 4290.69, Test loss = 81940.52\n",
      "[77/1000 epoch] Train loss = 4158.60, Test loss = 76069.50\n",
      "[78/1000 epoch] Train loss = 3889.49, Test loss = 73221.71\n",
      "[79/1000 epoch] Train loss = 3814.12, Test loss = 74651.30\n",
      "[80/1000 epoch] Train loss = 3720.98, Test loss = 73688.28\n",
      "[81/1000 epoch] Train loss = 3458.48, Test loss = 72766.85\n",
      "[82/1000 epoch] Train loss = 3283.88, Test loss = 70344.48\n",
      "[83/1000 epoch] Train loss = 3189.70, Test loss = 64189.06\n",
      "[84/1000 epoch] Train loss = 3048.09, Test loss = 62832.18\n",
      "[85/1000 epoch] Train loss = 2785.10, Test loss = 61539.80\n",
      "[86/1000 epoch] Train loss = 2513.40, Test loss = 61639.82\n",
      "[87/1000 epoch] Train loss = 2357.21, Test loss = 63475.49\n",
      "[88/1000 epoch] Train loss = 2255.61, Test loss = 59904.36\n",
      "[89/1000 epoch] Train loss = 2045.64, Test loss = 57287.11\n",
      "[90/1000 epoch] Train loss = 1796.09, Test loss = 54294.27\n",
      "[91/1000 epoch] Train loss = 1651.09, Test loss = 51168.19\n",
      "[92/1000 epoch] Train loss = 1570.45, Test loss = 52006.41\n",
      "[93/1000 epoch] Train loss = 1435.16, Test loss = 48976.75\n",
      "[94/1000 epoch] Train loss = 1265.81, Test loss = 45988.20\n",
      "[95/1000 epoch] Train loss = 1161.43, Test loss = 43254.48\n",
      "[96/1000 epoch] Train loss = 1132.22, Test loss = 39009.70\n",
      "[97/1000 epoch] Train loss = 1107.86, Test loss = 41758.12\n",
      "[98/1000 epoch] Train loss = 1040.03, Test loss = 34735.89\n",
      "[99/1000 epoch] Train loss = 925.91, Test loss = 32924.94\n",
      "[100/1000 epoch] Train loss = 814.12, Test loss = 32374.40\n",
      "[101/1000 epoch] Train loss = 742.84, Test loss = 28507.31\n",
      "[102/1000 epoch] Train loss = 716.00, Test loss = 27475.46\n",
      "[103/1000 epoch] Train loss = 748.45, Test loss = 23109.73\n",
      "[104/1000 epoch] Train loss = 915.36, Test loss = 27606.71\n",
      "[105/1000 epoch] Train loss = 1161.64, Test loss = 20976.71\n",
      "[106/1000 epoch] Train loss = 990.15, Test loss = 23269.31\n",
      "[107/1000 epoch] Train loss = 502.64, Test loss = 23174.04\n",
      "[108/1000 epoch] Train loss = 406.98, Test loss = 20259.84\n",
      "[109/1000 epoch] Train loss = 646.43, Test loss = 21361.93\n",
      "[110/1000 epoch] Train loss = 505.02, Test loss = 19171.83\n",
      "[111/1000 epoch] Train loss = 255.16, Test loss = 20022.94\n",
      "[112/1000 epoch] Train loss = 395.70, Test loss = 23180.47\n",
      "[113/1000 epoch] Train loss = 453.71, Test loss = 19874.13\n",
      "[114/1000 epoch] Train loss = 236.83, Test loss = 18855.05\n",
      "[115/1000 epoch] Train loss = 249.04, Test loss = 21164.80\n",
      "[116/1000 epoch] Train loss = 394.55, Test loss = 18545.91\n",
      "[117/1000 epoch] Train loss = 305.42, Test loss = 17545.14\n",
      "[118/1000 epoch] Train loss = 157.08, Test loss = 17110.66\n",
      "[119/1000 epoch] Train loss = 200.78, Test loss = 15365.58\n",
      "[120/1000 epoch] Train loss = 291.00, Test loss = 16354.11\n",
      "[121/1000 epoch] Train loss = 229.40, Test loss = 13272.78\n",
      "[122/1000 epoch] Train loss = 125.98, Test loss = 13576.93\n",
      "[123/1000 epoch] Train loss = 135.52, Test loss = 15153.02\n",
      "[124/1000 epoch] Train loss = 208.48, Test loss = 11581.08\n",
      "[125/1000 epoch] Train loss = 210.20, Test loss = 13116.20\n",
      "[126/1000 epoch] Train loss = 132.13, Test loss = 12996.70\n",
      "[127/1000 epoch] Train loss = 89.32, Test loss = 11471.96\n",
      "[128/1000 epoch] Train loss = 119.98, Test loss = 12359.58\n",
      "[129/1000 epoch] Train loss = 159.05, Test loss = 11147.04\n",
      "[130/1000 epoch] Train loss = 144.35, Test loss = 12239.24\n",
      "[131/1000 epoch] Train loss = 94.61, Test loss = 10940.71\n",
      "[132/1000 epoch] Train loss = 72.80, Test loss = 10632.79\n",
      "[133/1000 epoch] Train loss = 93.48, Test loss = 12171.92\n",
      "[134/1000 epoch] Train loss = 117.10, Test loss = 9911.56\n",
      "[135/1000 epoch] Train loss = 108.52, Test loss = 10953.81\n",
      "[136/1000 epoch] Train loss = 76.96, Test loss = 10791.94\n",
      "[137/1000 epoch] Train loss = 56.08, Test loss = 10159.47\n",
      "[138/1000 epoch] Train loss = 58.22, Test loss = 10493.05\n",
      "[139/1000 epoch] Train loss = 74.44, Test loss = 9723.37\n",
      "[140/1000 epoch] Train loss = 88.07, Test loss = 10671.76\n",
      "[141/1000 epoch] Train loss = 85.98, Test loss = 9161.58\n",
      "[142/1000 epoch] Train loss = 74.09, Test loss = 10078.50\n",
      "[143/1000 epoch] Train loss = 57.15, Test loss = 9571.50\n",
      "[144/1000 epoch] Train loss = 45.26, Test loss = 9253.45\n",
      "[145/1000 epoch] Train loss = 41.73, Test loss = 9522.68\n",
      "[146/1000 epoch] Train loss = 45.40, Test loss = 9047.80\n",
      "[147/1000 epoch] Train loss = 52.86, Test loss = 9486.13\n",
      "[148/1000 epoch] Train loss = 59.69, Test loss = 8528.80\n",
      "[149/1000 epoch] Train loss = 65.18, Test loss = 9623.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/1000 epoch] Train loss = 66.02, Test loss = 8362.79\n",
      "[151/1000 epoch] Train loss = 64.96, Test loss = 9152.94\n",
      "[152/1000 epoch] Train loss = 60.21, Test loss = 8382.54\n",
      "[153/1000 epoch] Train loss = 55.67, Test loss = 8967.84\n",
      "[154/1000 epoch] Train loss = 50.18, Test loss = 8100.34\n",
      "[155/1000 epoch] Train loss = 46.21, Test loss = 8809.38\n",
      "[156/1000 epoch] Train loss = 42.83, Test loss = 8107.41\n",
      "[157/1000 epoch] Train loss = 41.25, Test loss = 8517.28\n",
      "[158/1000 epoch] Train loss = 40.66, Test loss = 7996.53\n",
      "[159/1000 epoch] Train loss = 42.27, Test loss = 8587.13\n",
      "[160/1000 epoch] Train loss = 46.01, Test loss = 7652.83\n",
      "[161/1000 epoch] Train loss = 55.25, Test loss = 8706.44\n",
      "[162/1000 epoch] Train loss = 71.95, Test loss = 7317.13\n",
      "[163/1000 epoch] Train loss = 107.04, Test loss = 8981.49\n",
      "[164/1000 epoch] Train loss = 160.10, Test loss = 6732.28\n",
      "[165/1000 epoch] Train loss = 252.58, Test loss = 9657.24\n",
      "[166/1000 epoch] Train loss = 329.45, Test loss = 6315.02\n",
      "[167/1000 epoch] Train loss = 355.60, Test loss = 9351.13\n",
      "[168/1000 epoch] Train loss = 238.18, Test loss = 7077.03\n",
      "[169/1000 epoch] Train loss = 78.96, Test loss = 7560.27\n",
      "[170/1000 epoch] Train loss = 36.11, Test loss = 8831.97\n",
      "[171/1000 epoch] Train loss = 121.15, Test loss = 6772.88\n",
      "[172/1000 epoch] Train loss = 169.44, Test loss = 8847.29\n",
      "[173/1000 epoch] Train loss = 99.38, Test loss = 7736.15\n",
      "[174/1000 epoch] Train loss = 31.88, Test loss = 7234.46\n",
      "[175/1000 epoch] Train loss = 64.29, Test loss = 8855.06\n",
      "[176/1000 epoch] Train loss = 113.29, Test loss = 7057.62\n",
      "[177/1000 epoch] Train loss = 88.21, Test loss = 7869.80\n",
      "[178/1000 epoch] Train loss = 34.68, Test loss = 8075.41\n",
      "[179/1000 epoch] Train loss = 43.71, Test loss = 7031.12\n",
      "[180/1000 epoch] Train loss = 83.20, Test loss = 8393.32\n",
      "[181/1000 epoch] Train loss = 76.00, Test loss = 7358.63\n",
      "[182/1000 epoch] Train loss = 38.04, Test loss = 7586.69\n",
      "[183/1000 epoch] Train loss = 27.67, Test loss = 8204.96\n",
      "[184/1000 epoch] Train loss = 51.42, Test loss = 7051.01\n",
      "[185/1000 epoch] Train loss = 69.17, Test loss = 8153.67\n",
      "[186/1000 epoch] Train loss = 60.05, Test loss = 7226.73\n",
      "[187/1000 epoch] Train loss = 36.45, Test loss = 7462.21\n",
      "[188/1000 epoch] Train loss = 22.21, Test loss = 7536.86\n",
      "[189/1000 epoch] Train loss = 24.93, Test loss = 7029.98\n",
      "[190/1000 epoch] Train loss = 38.58, Test loss = 7764.69\n",
      "[191/1000 epoch] Train loss = 51.79, Test loss = 6828.60\n",
      "[192/1000 epoch] Train loss = 60.84, Test loss = 7853.60\n",
      "[193/1000 epoch] Train loss = 57.78, Test loss = 6872.89\n",
      "[194/1000 epoch] Train loss = 50.41, Test loss = 7637.32\n",
      "[195/1000 epoch] Train loss = 38.16, Test loss = 7075.50\n",
      "[196/1000 epoch] Train loss = 28.16, Test loss = 7359.42\n",
      "[197/1000 epoch] Train loss = 21.52, Test loss = 7231.56\n",
      "[198/1000 epoch] Train loss = 19.46, Test loss = 7147.79\n",
      "[199/1000 epoch] Train loss = 21.16, Test loss = 7424.18\n",
      "[200/1000 epoch] Train loss = 25.24, Test loss = 6947.26\n",
      "[201/1000 epoch] Train loss = 30.66, Test loss = 7569.46\n",
      "[202/1000 epoch] Train loss = 35.87, Test loss = 6831.88\n",
      "[203/1000 epoch] Train loss = 41.95, Test loss = 7594.30\n",
      "[204/1000 epoch] Train loss = 46.80, Test loss = 6711.46\n",
      "[205/1000 epoch] Train loss = 53.89, Test loss = 7654.72\n",
      "[206/1000 epoch] Train loss = 59.16, Test loss = 6552.15\n",
      "[207/1000 epoch] Train loss = 68.09, Test loss = 7742.31\n",
      "[208/1000 epoch] Train loss = 74.32, Test loss = 6463.04\n",
      "[209/1000 epoch] Train loss = 86.07, Test loss = 7807.78\n",
      "[210/1000 epoch] Train loss = 92.74, Test loss = 6375.42\n",
      "[211/1000 epoch] Train loss = 105.89, Test loss = 7909.11\n",
      "[212/1000 epoch] Train loss = 108.14, Test loss = 6285.63\n",
      "[213/1000 epoch] Train loss = 113.99, Test loss = 7890.43\n",
      "[214/1000 epoch] Train loss = 103.07, Test loss = 6364.97\n",
      "[215/1000 epoch] Train loss = 92.35, Test loss = 7658.27\n",
      "[216/1000 epoch] Train loss = 69.79, Test loss = 6596.93\n",
      "[217/1000 epoch] Train loss = 50.11, Test loss = 7371.12\n",
      "[218/1000 epoch] Train loss = 31.96, Test loss = 6884.71\n",
      "[219/1000 epoch] Train loss = 21.06, Test loss = 7062.85\n",
      "[220/1000 epoch] Train loss = 17.21, Test loss = 7180.41\n",
      "[221/1000 epoch] Train loss = 19.38, Test loss = 6791.08\n",
      "[222/1000 epoch] Train loss = 25.74, Test loss = 7358.46\n",
      "[223/1000 epoch] Train loss = 34.33, Test loss = 6601.06\n",
      "[224/1000 epoch] Train loss = 45.11, Test loss = 7506.36\n",
      "[225/1000 epoch] Train loss = 55.04, Test loss = 6425.19\n",
      "[226/1000 epoch] Train loss = 67.68, Test loss = 7674.14\n",
      "[227/1000 epoch] Train loss = 76.43, Test loss = 6318.39\n",
      "[228/1000 epoch] Train loss = 88.69, Test loss = 7777.91\n",
      "[229/1000 epoch] Train loss = 91.94, Test loss = 6282.71\n",
      "[230/1000 epoch] Train loss = 97.20, Test loss = 7778.09\n",
      "[231/1000 epoch] Train loss = 89.57, Test loss = 6329.90\n",
      "[232/1000 epoch] Train loss = 81.39, Test loss = 7625.86\n",
      "[233/1000 epoch] Train loss = 63.92, Test loss = 6517.30\n",
      "[234/1000 epoch] Train loss = 47.70, Test loss = 7329.34\n",
      "[235/1000 epoch] Train loss = 31.98, Test loss = 6800.98\n",
      "[236/1000 epoch] Train loss = 21.43, Test loss = 7032.12\n",
      "[237/1000 epoch] Train loss = 16.44, Test loss = 7053.92\n",
      "[238/1000 epoch] Train loss = 16.58, Test loss = 6801.88\n",
      "[239/1000 epoch] Train loss = 20.48, Test loss = 7226.10\n",
      "[240/1000 epoch] Train loss = 26.73, Test loss = 6600.08\n",
      "[241/1000 epoch] Train loss = 34.97, Test loss = 7401.32\n",
      "[242/1000 epoch] Train loss = 44.35, Test loss = 6406.43\n",
      "[243/1000 epoch] Train loss = 56.90, Test loss = 7595.49\n",
      "[244/1000 epoch] Train loss = 69.85, Test loss = 6253.80\n",
      "[245/1000 epoch] Train loss = 87.78, Test loss = 7809.77\n",
      "[246/1000 epoch] Train loss = 99.87, Test loss = 6128.15\n",
      "[247/1000 epoch] Train loss = 112.93, Test loss = 7923.40\n",
      "[248/1000 epoch] Train loss = 110.39, Test loss = 6158.05\n",
      "[249/1000 epoch] Train loss = 99.80, Test loss = 7721.30\n",
      "[250/1000 epoch] Train loss = 73.87, Test loss = 6464.47\n",
      "[251/1000 epoch] Train loss = 45.31, Test loss = 7228.50\n",
      "[252/1000 epoch] Train loss = 23.63, Test loss = 6972.11\n",
      "[253/1000 epoch] Train loss = 15.75, Test loss = 6748.13\n",
      "[254/1000 epoch] Train loss = 21.37, Test loss = 7369.79\n",
      "[255/1000 epoch] Train loss = 34.49, Test loss = 6477.92\n",
      "[256/1000 epoch] Train loss = 46.72, Test loss = 7512.49\n",
      "[257/1000 epoch] Train loss = 52.81, Test loss = 6400.37\n",
      "[258/1000 epoch] Train loss = 50.26, Test loss = 7406.31\n",
      "[259/1000 epoch] Train loss = 41.18, Test loss = 6555.66\n",
      "[260/1000 epoch] Train loss = 29.17, Test loss = 7117.83\n",
      "[261/1000 epoch] Train loss = 19.72, Test loss = 6893.73\n",
      "[262/1000 epoch] Train loss = 15.33, Test loss = 6826.44\n",
      "[263/1000 epoch] Train loss = 16.28, Test loss = 7182.89\n",
      "[264/1000 epoch] Train loss = 20.93, Test loss = 6611.63\n",
      "[265/1000 epoch] Train loss = 27.70, Test loss = 7337.51\n",
      "[266/1000 epoch] Train loss = 36.19, Test loss = 6401.08\n",
      "[267/1000 epoch] Train loss = 46.90, Test loss = 7481.71\n",
      "[268/1000 epoch] Train loss = 58.58, Test loss = 6170.00\n",
      "[269/1000 epoch] Train loss = 75.24, Test loss = 7692.05\n",
      "[270/1000 epoch] Train loss = 92.44, Test loss = 5970.37\n",
      "[271/1000 epoch] Train loss = 116.09, Test loss = 7932.83\n",
      "[272/1000 epoch] Train loss = 132.79, Test loss = 5846.92\n",
      "[273/1000 epoch] Train loss = 149.88, Test loss = 8041.75\n",
      "[274/1000 epoch] Train loss = 142.17, Test loss = 5930.03\n",
      "[275/1000 epoch] Train loss = 114.38, Test loss = 7700.66\n",
      "[276/1000 epoch] Train loss = 71.01, Test loss = 6462.60\n",
      "[277/1000 epoch] Train loss = 30.57, Test loss = 6908.19\n",
      "[278/1000 epoch] Train loss = 16.15, Test loss = 7347.80\n",
      "[279/1000 epoch] Train loss = 31.61, Test loss = 6290.46\n",
      "[280/1000 epoch] Train loss = 54.42, Test loss = 7759.07\n",
      "[281/1000 epoch] Train loss = 59.67, Test loss = 6368.42\n",
      "[282/1000 epoch] Train loss = 43.89, Test loss = 7194.08\n",
      "[283/1000 epoch] Train loss = 23.24, Test loss = 6978.67\n",
      "[284/1000 epoch] Train loss = 16.17, Test loss = 6540.85\n",
      "[285/1000 epoch] Train loss = 25.03, Test loss = 7402.74\n",
      "[286/1000 epoch] Train loss = 37.68, Test loss = 6386.06\n",
      "[287/1000 epoch] Train loss = 42.27, Test loss = 7348.74\n",
      "[288/1000 epoch] Train loss = 36.33, Test loss = 6561.42\n",
      "[289/1000 epoch] Train loss = 25.21, Test loss = 7045.42\n",
      "[290/1000 epoch] Train loss = 16.68, Test loss = 6874.47\n",
      "[291/1000 epoch] Train loss = 14.09, Test loss = 6670.58\n",
      "[292/1000 epoch] Train loss = 17.00, Test loss = 7153.63\n",
      "[293/1000 epoch] Train loss = 23.57, Test loss = 6399.63\n",
      "[294/1000 epoch] Train loss = 32.75, Test loss = 7311.46\n",
      "[295/1000 epoch] Train loss = 43.38, Test loss = 6212.03\n",
      "[296/1000 epoch] Train loss = 58.08, Test loss = 7509.83\n",
      "[297/1000 epoch] Train loss = 73.68, Test loss = 5975.09\n",
      "[298/1000 epoch] Train loss = 100.37, Test loss = 7836.42\n",
      "[299/1000 epoch] Train loss = 124.52, Test loss = 5716.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300/1000 epoch] Train loss = 165.90, Test loss = 8174.59\n",
      "[301/1000 epoch] Train loss = 181.75, Test loss = 5578.24\n",
      "[302/1000 epoch] Train loss = 200.54, Test loss = 8182.85\n",
      "[303/1000 epoch] Train loss = 165.15, Test loss = 5821.57\n",
      "[304/1000 epoch] Train loss = 116.62, Test loss = 7515.50\n",
      "[305/1000 epoch] Train loss = 51.50, Test loss = 6645.35\n",
      "[306/1000 epoch] Train loss = 16.89, Test loss = 6561.08\n",
      "[307/1000 epoch] Train loss = 21.87, Test loss = 7592.57\n",
      "[308/1000 epoch] Train loss = 51.97, Test loss = 6104.35\n",
      "[309/1000 epoch] Train loss = 81.90, Test loss = 7753.22\n",
      "[310/1000 epoch] Train loss = 83.22, Test loss = 6239.78\n",
      "[311/1000 epoch] Train loss = 63.86, Test loss = 7253.87\n",
      "[312/1000 epoch] Train loss = 32.62, Test loss = 6724.61\n",
      "[313/1000 epoch] Train loss = 15.10, Test loss = 6665.00\n",
      "[314/1000 epoch] Train loss = 19.38, Test loss = 7336.54\n",
      "[315/1000 epoch] Train loss = 35.60, Test loss = 6333.64\n",
      "[316/1000 epoch] Train loss = 47.10, Test loss = 7544.00\n",
      "[317/1000 epoch] Train loss = 42.28, Test loss = 6515.41\n",
      "[318/1000 epoch] Train loss = 28.03, Test loss = 7073.76\n",
      "[319/1000 epoch] Train loss = 15.80, Test loss = 7029.66\n",
      "[320/1000 epoch] Train loss = 14.93, Test loss = 6539.33\n",
      "[321/1000 epoch] Train loss = 22.91, Test loss = 7315.31\n",
      "[322/1000 epoch] Train loss = 30.32, Test loss = 6432.88\n",
      "[323/1000 epoch] Train loss = 31.34, Test loss = 7187.77\n",
      "[324/1000 epoch] Train loss = 25.39, Test loss = 6643.04\n",
      "[325/1000 epoch] Train loss = 18.14, Test loss = 6926.28\n",
      "[326/1000 epoch] Train loss = 13.54, Test loss = 6910.01\n",
      "[327/1000 epoch] Train loss = 13.34, Test loss = 6681.67\n",
      "[328/1000 epoch] Train loss = 16.46, Test loss = 7118.75\n",
      "[329/1000 epoch] Train loss = 20.71, Test loss = 6504.55\n",
      "[330/1000 epoch] Train loss = 24.70, Test loss = 7188.62\n",
      "[331/1000 epoch] Train loss = 26.09, Test loss = 6463.11\n",
      "[332/1000 epoch] Train loss = 25.95, Test loss = 7122.77\n",
      "[333/1000 epoch] Train loss = 23.19, Test loss = 6542.52\n",
      "[334/1000 epoch] Train loss = 20.13, Test loss = 6999.58\n",
      "[335/1000 epoch] Train loss = 16.72, Test loss = 6665.56\n",
      "[336/1000 epoch] Train loss = 14.24, Test loss = 6855.68\n",
      "[337/1000 epoch] Train loss = 12.76, Test loss = 6782.87\n",
      "[338/1000 epoch] Train loss = 12.32, Test loss = 6699.90\n",
      "[339/1000 epoch] Train loss = 12.73, Test loss = 6874.17\n",
      "[340/1000 epoch] Train loss = 13.70, Test loss = 6576.19\n",
      "[341/1000 epoch] Train loss = 15.06, Test loss = 6934.32\n",
      "[342/1000 epoch] Train loss = 16.49, Test loss = 6502.26\n",
      "[343/1000 epoch] Train loss = 18.15, Test loss = 6992.77\n",
      "[344/1000 epoch] Train loss = 19.64, Test loss = 6442.14\n",
      "[345/1000 epoch] Train loss = 21.61, Test loss = 7064.11\n",
      "[346/1000 epoch] Train loss = 23.49, Test loss = 6369.29\n",
      "[347/1000 epoch] Train loss = 26.59, Test loss = 7138.58\n",
      "[348/1000 epoch] Train loss = 29.87, Test loss = 6267.51\n",
      "[349/1000 epoch] Train loss = 35.65, Test loss = 7249.11\n",
      "[350/1000 epoch] Train loss = 41.76, Test loss = 6117.09\n",
      "[351/1000 epoch] Train loss = 52.66, Test loss = 7438.88\n",
      "[352/1000 epoch] Train loss = 63.31, Test loss = 5924.97\n",
      "[353/1000 epoch] Train loss = 82.66, Test loss = 7685.46\n",
      "[354/1000 epoch] Train loss = 97.62, Test loss = 5755.01\n",
      "[355/1000 epoch] Train loss = 125.53, Test loss = 7913.41\n",
      "[356/1000 epoch] Train loss = 138.10, Test loss = 5630.84\n",
      "[357/1000 epoch] Train loss = 160.71, Test loss = 8045.21\n",
      "[358/1000 epoch] Train loss = 151.08, Test loss = 5679.50\n",
      "[359/1000 epoch] Train loss = 135.99, Test loss = 7787.96\n",
      "[360/1000 epoch] Train loss = 91.60, Test loss = 6132.44\n",
      "[361/1000 epoch] Train loss = 48.48, Test loss = 7059.98\n",
      "[362/1000 epoch] Train loss = 17.82, Test loss = 6958.81\n",
      "[363/1000 epoch] Train loss = 15.20, Test loss = 6333.06\n",
      "[364/1000 epoch] Train loss = 34.18, Test loss = 7612.29\n",
      "[365/1000 epoch] Train loss = 55.30, Test loss = 6061.94\n",
      "[366/1000 epoch] Train loss = 65.24, Test loss = 7541.56\n",
      "[367/1000 epoch] Train loss = 53.14, Test loss = 6342.04\n",
      "[368/1000 epoch] Train loss = 33.09, Test loss = 6987.54\n",
      "[369/1000 epoch] Train loss = 16.39, Test loss = 6917.65\n",
      "[370/1000 epoch] Train loss = 14.02, Test loss = 6506.44\n",
      "[371/1000 epoch] Train loss = 23.56, Test loss = 7397.50\n",
      "[372/1000 epoch] Train loss = 34.07, Test loss = 6340.23\n",
      "[373/1000 epoch] Train loss = 37.79, Test loss = 7414.67\n",
      "[374/1000 epoch] Train loss = 31.12, Test loss = 6542.51\n",
      "[375/1000 epoch] Train loss = 21.01, Test loss = 6977.80\n",
      "[376/1000 epoch] Train loss = 13.76, Test loss = 6943.69\n",
      "[377/1000 epoch] Train loss = 13.41, Test loss = 6545.21\n",
      "[378/1000 epoch] Train loss = 18.27, Test loss = 7218.35\n",
      "[379/1000 epoch] Train loss = 23.65, Test loss = 6411.95\n",
      "[380/1000 epoch] Train loss = 26.48, Test loss = 7208.91\n",
      "[381/1000 epoch] Train loss = 25.06, Test loss = 6519.51\n",
      "[382/1000 epoch] Train loss = 21.49, Test loss = 7037.08\n",
      "[383/1000 epoch] Train loss = 16.92, Test loss = 6688.27\n",
      "[384/1000 epoch] Train loss = 13.58, Test loss = 6837.42\n",
      "[385/1000 epoch] Train loss = 12.14, Test loss = 6865.08\n",
      "[386/1000 epoch] Train loss = 12.66, Test loss = 6641.42\n",
      "[387/1000 epoch] Train loss = 14.42, Test loss = 7032.30\n",
      "[388/1000 epoch] Train loss = 16.37, Test loss = 6520.26\n",
      "[389/1000 epoch] Train loss = 17.96, Test loss = 7087.90\n",
      "[390/1000 epoch] Train loss = 18.47, Test loss = 6522.12\n",
      "[391/1000 epoch] Train loss = 18.31, Test loss = 7024.99\n",
      "[392/1000 epoch] Train loss = 17.27, Test loss = 6570.85\n",
      "[393/1000 epoch] Train loss = 16.04, Test loss = 6940.93\n",
      "[394/1000 epoch] Train loss = 14.64, Test loss = 6611.19\n",
      "[395/1000 epoch] Train loss = 13.45, Test loss = 6860.85\n",
      "[396/1000 epoch] Train loss = 12.53, Test loss = 6676.38\n",
      "[397/1000 epoch] Train loss = 11.94, Test loss = 6765.78\n",
      "[398/1000 epoch] Train loss = 11.63, Test loss = 6762.51\n",
      "[399/1000 epoch] Train loss = 11.57, Test loss = 6684.21\n",
      "[400/1000 epoch] Train loss = 11.69, Test loss = 6815.43\n",
      "[401/1000 epoch] Train loss = 11.94, Test loss = 6631.99\n",
      "[402/1000 epoch] Train loss = 12.30, Test loss = 6841.61\n",
      "[403/1000 epoch] Train loss = 12.79, Test loss = 6571.93\n",
      "[404/1000 epoch] Train loss = 13.51, Test loss = 6893.87\n",
      "[405/1000 epoch] Train loss = 14.56, Test loss = 6476.45\n",
      "[406/1000 epoch] Train loss = 16.21, Test loss = 6993.31\n",
      "[407/1000 epoch] Train loss = 18.74, Test loss = 6343.46\n",
      "[408/1000 epoch] Train loss = 23.17, Test loss = 7154.17\n",
      "[409/1000 epoch] Train loss = 30.25, Test loss = 6133.37\n",
      "[410/1000 epoch] Train loss = 44.15, Test loss = 7470.00\n",
      "[411/1000 epoch] Train loss = 67.10, Test loss = 5767.04\n",
      "[412/1000 epoch] Train loss = 114.41, Test loss = 8118.72\n",
      "[413/1000 epoch] Train loss = 184.14, Test loss = 5210.05\n",
      "[414/1000 epoch] Train loss = 319.80, Test loss = 9254.27\n",
      "[415/1000 epoch] Train loss = 433.45, Test loss = 4691.86\n",
      "[416/1000 epoch] Train loss = 570.38, Test loss = 9819.35\n",
      "[417/1000 epoch] Train loss = 425.17, Test loss = 5226.12\n",
      "[418/1000 epoch] Train loss = 190.53, Test loss = 7376.60\n",
      "[419/1000 epoch] Train loss = 24.06, Test loss = 8127.17\n",
      "[420/1000 epoch] Train loss = 130.92, Test loss = 5318.24\n",
      "[421/1000 epoch] Train loss = 287.50, Test loss = 9726.56\n",
      "[422/1000 epoch] Train loss = 179.35, Test loss = 6417.13\n",
      "[423/1000 epoch] Train loss = 31.97, Test loss = 6332.40\n",
      "[424/1000 epoch] Train loss = 46.66, Test loss = 9427.78\n",
      "[425/1000 epoch] Train loss = 149.52, Test loss = 5917.62\n",
      "[426/1000 epoch] Train loss = 157.26, Test loss = 7583.54\n",
      "[427/1000 epoch] Train loss = 45.18, Test loss = 8186.25\n",
      "[428/1000 epoch] Train loss = 26.89, Test loss = 6388.67\n",
      "[429/1000 epoch] Train loss = 99.32, Test loss = 8431.87\n",
      "[430/1000 epoch] Train loss = 98.82, Test loss = 7489.13\n",
      "[431/1000 epoch] Train loss = 39.61, Test loss = 7337.01\n",
      "[432/1000 epoch] Train loss = 17.44, Test loss = 8285.99\n",
      "[433/1000 epoch] Train loss = 59.73, Test loss = 7245.12\n",
      "[434/1000 epoch] Train loss = 77.17, Test loss = 7937.29\n",
      "[435/1000 epoch] Train loss = 31.12, Test loss = 7484.25\n",
      "[436/1000 epoch] Train loss = 17.23, Test loss = 7204.17\n",
      "[437/1000 epoch] Train loss = 47.77, Test loss = 8064.11\n",
      "[438/1000 epoch] Train loss = 49.89, Test loss = 6830.45\n",
      "[439/1000 epoch] Train loss = 23.77, Test loss = 7582.83\n",
      "[440/1000 epoch] Train loss = 16.10, Test loss = 7873.71\n",
      "[441/1000 epoch] Train loss = 34.17, Test loss = 6720.76\n",
      "[442/1000 epoch] Train loss = 39.96, Test loss = 8162.86\n",
      "[443/1000 epoch] Train loss = 21.68, Test loss = 7541.41\n",
      "[444/1000 epoch] Train loss = 14.16, Test loss = 7023.14\n",
      "[445/1000 epoch] Train loss = 26.33, Test loss = 8407.54\n",
      "[446/1000 epoch] Train loss = 31.30, Test loss = 7249.55\n",
      "[447/1000 epoch] Train loss = 20.84, Test loss = 7432.22\n",
      "[448/1000 epoch] Train loss = 13.51, Test loss = 8145.46\n",
      "[449/1000 epoch] Train loss = 19.67, Test loss = 7150.19\n",
      "[450/1000 epoch] Train loss = 25.13, Test loss = 7693.60\n",
      "[451/1000 epoch] Train loss = 19.53, Test loss = 7675.19\n",
      "[452/1000 epoch] Train loss = 13.30, Test loss = 7251.44\n",
      "[453/1000 epoch] Train loss = 15.49, Test loss = 7650.35\n",
      "[454/1000 epoch] Train loss = 20.17, Test loss = 7330.33\n",
      "[455/1000 epoch] Train loss = 18.72, Test loss = 7452.37\n",
      "[456/1000 epoch] Train loss = 13.61, Test loss = 7392.42\n",
      "[457/1000 epoch] Train loss = 13.31, Test loss = 7319.73\n",
      "[458/1000 epoch] Train loss = 16.73, Test loss = 7589.53\n",
      "[459/1000 epoch] Train loss = 17.03, Test loss = 7212.81\n",
      "[460/1000 epoch] Train loss = 14.01, Test loss = 7572.99\n",
      "[461/1000 epoch] Train loss = 12.35, Test loss = 7539.33\n",
      "[462/1000 epoch] Train loss = 13.88, Test loss = 7234.05\n",
      "[463/1000 epoch] Train loss = 15.44, Test loss = 7768.41\n",
      "[464/1000 epoch] Train loss = 14.33, Test loss = 7346.75\n",
      "[465/1000 epoch] Train loss = 12.35, Test loss = 7367.54\n",
      "[466/1000 epoch] Train loss = 12.26, Test loss = 7684.69\n",
      "[467/1000 epoch] Train loss = 13.58, Test loss = 7204.12\n",
      "[468/1000 epoch] Train loss = 13.86, Test loss = 7490.27\n",
      "[469/1000 epoch] Train loss = 12.68, Test loss = 7447.00\n",
      "[470/1000 epoch] Train loss = 11.78, Test loss = 7243.21\n",
      "[471/1000 epoch] Train loss = 12.13, Test loss = 7494.52\n",
      "[472/1000 epoch] Train loss = 12.85, Test loss = 7302.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[473/1000 epoch] Train loss = 12.77, Test loss = 7382.58\n",
      "[474/1000 epoch] Train loss = 11.97, Test loss = 7381.80\n",
      "[475/1000 epoch] Train loss = 11.47, Test loss = 7352.10\n",
      "[476/1000 epoch] Train loss = 11.75, Test loss = 7426.15\n",
      "[477/1000 epoch] Train loss = 12.16, Test loss = 7313.61\n",
      "[478/1000 epoch] Train loss = 12.06, Test loss = 7473.06\n",
      "[479/1000 epoch] Train loss = 11.57, Test loss = 7338.33\n",
      "[480/1000 epoch] Train loss = 11.26, Test loss = 7374.77\n",
      "[481/1000 epoch] Train loss = 11.36, Test loss = 7468.66\n",
      "[482/1000 epoch] Train loss = 11.59, Test loss = 7265.75\n",
      "[483/1000 epoch] Train loss = 11.60, Test loss = 7459.21\n",
      "[484/1000 epoch] Train loss = 11.32, Test loss = 7340.53\n",
      "[485/1000 epoch] Train loss = 11.05, Test loss = 7309.91\n",
      "[486/1000 epoch] Train loss = 11.03, Test loss = 7433.93\n",
      "[487/1000 epoch] Train loss = 11.15, Test loss = 7273.98\n",
      "[488/1000 epoch] Train loss = 11.22, Test loss = 7389.70\n",
      "[489/1000 epoch] Train loss = 11.11, Test loss = 7346.83\n",
      "[490/1000 epoch] Train loss = 10.92, Test loss = 7335.62\n",
      "[491/1000 epoch] Train loss = 10.81, Test loss = 7378.77\n",
      "[492/1000 epoch] Train loss = 10.81, Test loss = 7337.23\n",
      "[493/1000 epoch] Train loss = 10.87, Test loss = 7382.58\n",
      "[494/1000 epoch] Train loss = 10.88, Test loss = 7328.41\n",
      "[495/1000 epoch] Train loss = 10.79, Test loss = 7388.47\n",
      "[496/1000 epoch] Train loss = 10.68, Test loss = 7330.38\n",
      "[497/1000 epoch] Train loss = 10.61, Test loss = 7345.64\n",
      "[498/1000 epoch] Train loss = 10.60, Test loss = 7372.69\n",
      "[499/1000 epoch] Train loss = 10.61, Test loss = 7290.70\n",
      "[500/1000 epoch] Train loss = 10.62, Test loss = 7380.87\n",
      "[501/1000 epoch] Train loss = 10.58, Test loss = 7300.44\n",
      "[502/1000 epoch] Train loss = 10.51, Test loss = 7332.20\n",
      "[503/1000 epoch] Train loss = 10.44, Test loss = 7339.86\n",
      "[504/1000 epoch] Train loss = 10.40, Test loss = 7300.93\n",
      "[505/1000 epoch] Train loss = 10.39, Test loss = 7344.54\n",
      "[506/1000 epoch] Train loss = 10.39, Test loss = 7306.97\n",
      "[507/1000 epoch] Train loss = 10.38, Test loss = 7335.03\n",
      "[508/1000 epoch] Train loss = 10.35, Test loss = 7308.67\n",
      "[509/1000 epoch] Train loss = 10.30, Test loss = 7334.71\n",
      "[510/1000 epoch] Train loss = 10.26, Test loss = 7307.26\n",
      "[511/1000 epoch] Train loss = 10.22, Test loss = 7320.17\n",
      "[512/1000 epoch] Train loss = 10.20, Test loss = 7323.02\n",
      "[513/1000 epoch] Train loss = 10.18, Test loss = 7290.04\n",
      "[514/1000 epoch] Train loss = 10.17, Test loss = 7332.95\n",
      "[515/1000 epoch] Train loss = 10.15, Test loss = 7279.90\n",
      "[516/1000 epoch] Train loss = 10.12, Test loss = 7317.15\n",
      "[517/1000 epoch] Train loss = 10.09, Test loss = 7281.35\n",
      "[518/1000 epoch] Train loss = 10.06, Test loss = 7290.40\n",
      "[519/1000 epoch] Train loss = 10.03, Test loss = 7283.93\n",
      "[520/1000 epoch] Train loss = 10.00, Test loss = 7270.09\n",
      "[521/1000 epoch] Train loss = 9.98, Test loss = 7280.75\n",
      "[522/1000 epoch] Train loss = 9.96, Test loss = 7257.31\n",
      "[523/1000 epoch] Train loss = 9.94, Test loss = 7272.76\n",
      "[524/1000 epoch] Train loss = 9.92, Test loss = 7246.97\n",
      "[525/1000 epoch] Train loss = 9.90, Test loss = 7263.55\n",
      "[526/1000 epoch] Train loss = 9.88, Test loss = 7237.12\n",
      "[527/1000 epoch] Train loss = 9.85, Test loss = 7252.28\n",
      "[528/1000 epoch] Train loss = 9.83, Test loss = 7230.52\n",
      "[529/1000 epoch] Train loss = 9.80, Test loss = 7238.12\n",
      "[530/1000 epoch] Train loss = 9.78, Test loss = 7227.52\n",
      "[531/1000 epoch] Train loss = 9.75, Test loss = 7223.10\n",
      "[532/1000 epoch] Train loss = 9.73, Test loss = 7224.07\n",
      "[533/1000 epoch] Train loss = 9.71, Test loss = 7213.11\n",
      "[534/1000 epoch] Train loss = 9.69, Test loss = 7212.78\n",
      "[535/1000 epoch] Train loss = 9.67, Test loss = 7196.64\n",
      "[536/1000 epoch] Train loss = 9.65, Test loss = 7204.69\n",
      "[537/1000 epoch] Train loss = 9.63, Test loss = 7181.96\n",
      "[538/1000 epoch] Train loss = 9.61, Test loss = 7194.88\n",
      "[539/1000 epoch] Train loss = 9.60, Test loss = 7169.36\n",
      "[540/1000 epoch] Train loss = 9.58, Test loss = 7184.03\n",
      "[541/1000 epoch] Train loss = 9.56, Test loss = 7156.36\n",
      "[542/1000 epoch] Train loss = 9.54, Test loss = 7174.60\n",
      "[543/1000 epoch] Train loss = 9.52, Test loss = 7142.09\n",
      "[544/1000 epoch] Train loss = 9.51, Test loss = 7168.35\n",
      "[545/1000 epoch] Train loss = 9.49, Test loss = 7121.69\n",
      "[546/1000 epoch] Train loss = 9.48, Test loss = 7162.79\n",
      "[547/1000 epoch] Train loss = 9.47, Test loss = 7100.22\n",
      "[548/1000 epoch] Train loss = 9.47, Test loss = 7154.80\n",
      "[549/1000 epoch] Train loss = 9.48, Test loss = 7082.26\n",
      "[550/1000 epoch] Train loss = 9.50, Test loss = 7151.83\n",
      "[551/1000 epoch] Train loss = 9.54, Test loss = 7054.34\n",
      "[552/1000 epoch] Train loss = 9.61, Test loss = 7165.52\n",
      "[553/1000 epoch] Train loss = 9.74, Test loss = 7010.74\n",
      "[554/1000 epoch] Train loss = 9.97, Test loss = 7198.25\n",
      "[555/1000 epoch] Train loss = 10.35, Test loss = 6944.48\n",
      "[556/1000 epoch] Train loss = 11.04, Test loss = 7256.61\n",
      "[557/1000 epoch] Train loss = 12.18, Test loss = 6839.65\n",
      "[558/1000 epoch] Train loss = 14.31, Test loss = 7363.63\n",
      "[559/1000 epoch] Train loss = 17.86, Test loss = 6666.76\n",
      "[560/1000 epoch] Train loss = 24.69, Test loss = 7579.71\n",
      "[561/1000 epoch] Train loss = 35.97, Test loss = 6372.80\n",
      "[562/1000 epoch] Train loss = 59.24, Test loss = 8001.13\n",
      "[563/1000 epoch] Train loss = 95.00, Test loss = 5874.14\n",
      "[564/1000 epoch] Train loss = 175.52, Test loss = 8849.14\n",
      "[565/1000 epoch] Train loss = 272.04, Test loss = 5182.89\n",
      "[566/1000 epoch] Train loss = 488.35, Test loss = 10094.69\n",
      "[567/1000 epoch] Train loss = 559.88, Test loss = 4634.24\n",
      "[568/1000 epoch] Train loss = 700.75, Test loss = 10262.47\n",
      "[569/1000 epoch] Train loss = 368.59, Test loss = 5530.95\n",
      "[570/1000 epoch] Train loss = 103.26, Test loss = 7228.72\n",
      "[571/1000 epoch] Train loss = 30.76, Test loss = 9248.45\n",
      "[572/1000 epoch] Train loss = 176.35, Test loss = 5235.27\n",
      "[573/1000 epoch] Train loss = 317.28, Test loss = 9698.19\n",
      "[574/1000 epoch] Train loss = 186.54, Test loss = 7003.42\n",
      "[575/1000 epoch] Train loss = 37.81, Test loss = 6222.91\n",
      "[576/1000 epoch] Train loss = 39.49, Test loss = 9349.30\n",
      "[577/1000 epoch] Train loss = 143.45, Test loss = 6298.61\n",
      "[578/1000 epoch] Train loss = 181.94, Test loss = 7672.17\n",
      "[579/1000 epoch] Train loss = 67.95, Test loss = 8106.23\n",
      "[580/1000 epoch] Train loss = 18.68, Test loss = 6955.36\n",
      "[581/1000 epoch] Train loss = 77.37, Test loss = 8443.12\n",
      "[582/1000 epoch] Train loss = 112.50, Test loss = 7484.85\n",
      "[583/1000 epoch] Train loss = 76.40, Test loss = 8056.48\n",
      "[584/1000 epoch] Train loss = 18.00, Test loss = 7979.33\n",
      "[585/1000 epoch] Train loss = 34.63, Test loss = 7375.07\n",
      "[586/1000 epoch] Train loss = 79.55, Test loss = 8493.68\n",
      "[587/1000 epoch] Train loss = 60.18, Test loss = 7124.58\n",
      "[588/1000 epoch] Train loss = 20.61, Test loss = 7684.62\n",
      "[589/1000 epoch] Train loss = 20.07, Test loss = 8246.25\n",
      "[590/1000 epoch] Train loss = 47.05, Test loss = 6820.95\n",
      "[591/1000 epoch] Train loss = 51.05, Test loss = 8398.62\n",
      "[592/1000 epoch] Train loss = 23.11, Test loss = 7817.49\n",
      "[593/1000 epoch] Train loss = 12.96, Test loss = 7247.46\n",
      "[594/1000 epoch] Train loss = 30.11, Test loss = 8826.38\n",
      "[595/1000 epoch] Train loss = 39.51, Test loss = 7565.04\n",
      "[596/1000 epoch] Train loss = 27.46, Test loss = 7925.49\n",
      "[597/1000 epoch] Train loss = 13.15, Test loss = 8573.75\n",
      "[598/1000 epoch] Train loss = 17.08, Test loss = 7628.72\n",
      "[599/1000 epoch] Train loss = 28.17, Test loss = 8272.41\n",
      "[600/1000 epoch] Train loss = 26.43, Test loss = 8061.75\n",
      "[601/1000 epoch] Train loss = 15.95, Test loss = 7875.78\n",
      "[602/1000 epoch] Train loss = 11.85, Test loss = 8068.48\n",
      "[603/1000 epoch] Train loss = 18.18, Test loss = 7770.29\n",
      "[604/1000 epoch] Train loss = 22.71, Test loss = 8040.23\n",
      "[605/1000 epoch] Train loss = 17.47, Test loss = 7626.89\n",
      "[606/1000 epoch] Train loss = 11.79, Test loss = 7844.41\n",
      "[607/1000 epoch] Train loss = 13.02, Test loss = 7942.39\n",
      "[608/1000 epoch] Train loss = 17.15, Test loss = 7437.69\n",
      "[609/1000 epoch] Train loss = 17.26, Test loss = 8125.51\n",
      "[610/1000 epoch] Train loss = 13.15, Test loss = 7710.68\n",
      "[611/1000 epoch] Train loss = 11.00, Test loss = 7627.05\n",
      "[612/1000 epoch] Train loss = 13.04, Test loss = 8207.70\n",
      "[613/1000 epoch] Train loss = 15.23, Test loss = 7542.49\n",
      "[614/1000 epoch] Train loss = 14.15, Test loss = 7867.83\n",
      "[615/1000 epoch] Train loss = 11.52, Test loss = 7944.28\n",
      "[616/1000 epoch] Train loss = 10.98, Test loss = 7509.43\n",
      "[617/1000 epoch] Train loss = 12.46, Test loss = 7875.18\n",
      "[618/1000 epoch] Train loss = 13.29, Test loss = 7639.12\n",
      "[619/1000 epoch] Train loss = 12.33, Test loss = 7601.82\n",
      "[620/1000 epoch] Train loss = 10.87, Test loss = 7694.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[621/1000 epoch] Train loss = 10.75, Test loss = 7577.32\n",
      "[622/1000 epoch] Train loss = 11.73, Test loss = 7660.50\n",
      "[623/1000 epoch] Train loss = 12.13, Test loss = 7538.10\n",
      "[624/1000 epoch] Train loss = 11.42, Test loss = 7694.87\n",
      "[625/1000 epoch] Train loss = 10.55, Test loss = 7556.81\n",
      "[626/1000 epoch] Train loss = 10.47, Test loss = 7561.45\n",
      "[627/1000 epoch] Train loss = 10.99, Test loss = 7727.90\n",
      "[628/1000 epoch] Train loss = 11.29, Test loss = 7438.21\n",
      "[629/1000 epoch] Train loss = 10.98, Test loss = 7684.18\n",
      "[630/1000 epoch] Train loss = 10.41, Test loss = 7580.92\n",
      "[631/1000 epoch] Train loss = 10.19, Test loss = 7457.00\n",
      "[632/1000 epoch] Train loss = 10.43, Test loss = 7675.61\n",
      "[633/1000 epoch] Train loss = 10.69, Test loss = 7425.91\n",
      "[634/1000 epoch] Train loss = 10.63, Test loss = 7529.16\n",
      "[635/1000 epoch] Train loss = 10.31, Test loss = 7517.26\n",
      "[636/1000 epoch] Train loss = 10.05, Test loss = 7420.27\n",
      "[637/1000 epoch] Train loss = 10.03, Test loss = 7506.67\n",
      "[638/1000 epoch] Train loss = 10.17, Test loss = 7429.20\n",
      "[639/1000 epoch] Train loss = 10.26, Test loss = 7472.30\n",
      "[640/1000 epoch] Train loss = 10.16, Test loss = 7420.78\n",
      "[641/1000 epoch] Train loss = 9.96, Test loss = 7468.36\n",
      "[642/1000 epoch] Train loss = 9.83, Test loss = 7420.75\n",
      "[643/1000 epoch] Train loss = 9.83, Test loss = 7403.70\n",
      "[644/1000 epoch] Train loss = 9.89, Test loss = 7465.75\n",
      "[645/1000 epoch] Train loss = 9.91, Test loss = 7335.47\n",
      "[646/1000 epoch] Train loss = 9.85, Test loss = 7441.97\n",
      "[647/1000 epoch] Train loss = 9.74, Test loss = 7368.05\n",
      "[648/1000 epoch] Train loss = 9.65, Test loss = 7348.39\n",
      "[649/1000 epoch] Train loss = 9.62, Test loss = 7410.93\n",
      "[650/1000 epoch] Train loss = 9.63, Test loss = 7313.05\n",
      "[651/1000 epoch] Train loss = 9.64, Test loss = 7376.00\n",
      "[652/1000 epoch] Train loss = 9.61, Test loss = 7332.41\n",
      "[653/1000 epoch] Train loss = 9.55, Test loss = 7330.54\n",
      "[654/1000 epoch] Train loss = 9.48, Test loss = 7327.06\n",
      "[655/1000 epoch] Train loss = 9.43, Test loss = 7313.80\n",
      "[656/1000 epoch] Train loss = 9.41, Test loss = 7314.11\n",
      "[657/1000 epoch] Train loss = 9.41, Test loss = 7284.87\n",
      "[658/1000 epoch] Train loss = 9.40, Test loss = 7319.55\n",
      "[659/1000 epoch] Train loss = 9.37, Test loss = 7255.56\n",
      "[660/1000 epoch] Train loss = 9.32, Test loss = 7301.29\n",
      "[661/1000 epoch] Train loss = 9.28, Test loss = 7263.03\n",
      "[662/1000 epoch] Train loss = 9.24, Test loss = 7253.50\n",
      "[663/1000 epoch] Train loss = 9.21, Test loss = 7276.52\n",
      "[664/1000 epoch] Train loss = 9.19, Test loss = 7224.60\n",
      "[665/1000 epoch] Train loss = 9.18, Test loss = 7258.40\n",
      "[666/1000 epoch] Train loss = 9.15, Test loss = 7222.45\n",
      "[667/1000 epoch] Train loss = 9.11, Test loss = 7230.80\n",
      "[668/1000 epoch] Train loss = 9.06, Test loss = 7213.38\n",
      "[669/1000 epoch] Train loss = 9.00, Test loss = 7214.28\n",
      "[670/1000 epoch] Train loss = 8.93, Test loss = 7196.42\n",
      "[671/1000 epoch] Train loss = 8.86, Test loss = 7192.58\n",
      "[672/1000 epoch] Train loss = 8.79, Test loss = 7189.15\n",
      "[673/1000 epoch] Train loss = 8.71, Test loss = 7161.88\n",
      "[674/1000 epoch] Train loss = 8.64, Test loss = 7183.04\n",
      "[675/1000 epoch] Train loss = 8.56, Test loss = 7141.29\n",
      "[676/1000 epoch] Train loss = 8.47, Test loss = 7164.71\n",
      "[677/1000 epoch] Train loss = 8.35, Test loss = 7134.56\n",
      "[678/1000 epoch] Train loss = 8.22, Test loss = 7142.05\n",
      "[679/1000 epoch] Train loss = 8.11, Test loss = 7123.92\n",
      "[680/1000 epoch] Train loss = 8.02, Test loss = 7130.65\n",
      "[681/1000 epoch] Train loss = 7.96, Test loss = 7103.83\n",
      "[682/1000 epoch] Train loss = 7.92, Test loss = 7125.58\n",
      "[683/1000 epoch] Train loss = 7.91, Test loss = 7084.43\n",
      "[684/1000 epoch] Train loss = 7.91, Test loss = 7118.27\n",
      "[685/1000 epoch] Train loss = 7.92, Test loss = 7067.95\n",
      "[686/1000 epoch] Train loss = 7.95, Test loss = 7114.71\n",
      "[687/1000 epoch] Train loss = 8.01, Test loss = 7039.53\n",
      "[688/1000 epoch] Train loss = 8.14, Test loss = 7130.99\n",
      "[689/1000 epoch] Train loss = 8.38, Test loss = 6985.90\n",
      "[690/1000 epoch] Train loss = 8.85, Test loss = 7177.62\n",
      "[691/1000 epoch] Train loss = 9.76, Test loss = 6899.00\n",
      "[692/1000 epoch] Train loss = 11.56, Test loss = 7271.09\n",
      "[693/1000 epoch] Train loss = 14.83, Test loss = 6747.24\n",
      "[694/1000 epoch] Train loss = 21.56, Test loss = 7467.78\n",
      "[695/1000 epoch] Train loss = 33.08, Test loss = 6466.48\n",
      "[696/1000 epoch] Train loss = 58.45, Test loss = 7879.08\n",
      "[697/1000 epoch] Train loss = 101.83, Test loss = 5979.92\n",
      "[698/1000 epoch] Train loss = 204.72, Test loss = 8732.86\n",
      "[699/1000 epoch] Train loss = 335.58, Test loss = 5197.89\n",
      "[700/1000 epoch] Train loss = 641.80, Test loss = 10244.20\n",
      "[701/1000 epoch] Train loss = 671.85, Test loss = 4461.44\n",
      "[702/1000 epoch] Train loss = 738.02, Test loss = 10454.17\n",
      "[703/1000 epoch] Train loss = 230.91, Test loss = 5657.38\n",
      "[704/1000 epoch] Train loss = 53.47, Test loss = 6097.03\n",
      "[705/1000 epoch] Train loss = 255.69, Test loss = 11522.30\n",
      "[706/1000 epoch] Train loss = 304.84, Test loss = 4488.59\n",
      "[707/1000 epoch] Train loss = 140.59, Test loss = 8422.52\n",
      "[708/1000 epoch] Train loss = 40.60, Test loss = 9554.14\n",
      "[709/1000 epoch] Train loss = 158.88, Test loss = 4349.76\n",
      "[710/1000 epoch] Train loss = 220.03, Test loss = 10467.04\n",
      "[711/1000 epoch] Train loss = 72.30, Test loss = 7947.09\n",
      "[712/1000 epoch] Train loss = 48.73, Test loss = 4942.38\n",
      "[713/1000 epoch] Train loss = 165.14, Test loss = 11535.40\n",
      "[714/1000 epoch] Train loss = 123.42, Test loss = 8035.58\n",
      "[715/1000 epoch] Train loss = 27.67, Test loss = 5688.64\n",
      "[716/1000 epoch] Train loss = 74.88, Test loss = 11283.68\n",
      "[717/1000 epoch] Train loss = 111.65, Test loss = 8758.34\n",
      "[718/1000 epoch] Train loss = 66.29, Test loss = 6255.05\n",
      "[719/1000 epoch] Train loss = 35.70, Test loss = 9754.63\n",
      "[720/1000 epoch] Train loss = 55.83, Test loss = 8890.40\n",
      "[721/1000 epoch] Train loss = 83.58, Test loss = 6768.61\n",
      "[722/1000 epoch] Train loss = 41.02, Test loss = 8144.02\n",
      "[723/1000 epoch] Train loss = 18.63, Test loss = 8806.93\n",
      "[724/1000 epoch] Train loss = 59.36, Test loss = 7279.82\n",
      "[725/1000 epoch] Train loss = 57.60, Test loss = 7174.17\n",
      "[726/1000 epoch] Train loss = 24.09, Test loss = 9140.58\n",
      "[727/1000 epoch] Train loss = 20.38, Test loss = 7431.43\n",
      "[728/1000 epoch] Train loss = 34.62, Test loss = 6937.25\n",
      "[729/1000 epoch] Train loss = 44.25, Test loss = 9565.65\n",
      "[730/1000 epoch] Train loss = 32.94, Test loss = 7293.00\n",
      "[731/1000 epoch] Train loss = 12.68, Test loss = 7134.08\n",
      "[732/1000 epoch] Train loss = 16.64, Test loss = 9342.40\n",
      "[733/1000 epoch] Train loss = 32.12, Test loss = 7201.54\n",
      "[734/1000 epoch] Train loss = 30.52, Test loss = 7358.02\n",
      "[735/1000 epoch] Train loss = 20.46, Test loss = 8553.74\n",
      "[736/1000 epoch] Train loss = 13.26, Test loss = 7359.45\n",
      "[737/1000 epoch] Train loss = 13.50, Test loss = 7164.90\n",
      "[738/1000 epoch] Train loss = 21.95, Test loss = 7891.43\n",
      "[739/1000 epoch] Train loss = 23.24, Test loss = 7535.54\n",
      "[740/1000 epoch] Train loss = 14.80, Test loss = 6675.86\n",
      "[741/1000 epoch] Train loss = 11.09, Test loss = 7711.94\n",
      "[742/1000 epoch] Train loss = 12.40, Test loss = 7416.06\n",
      "[743/1000 epoch] Train loss = 15.37, Test loss = 6444.89\n",
      "[744/1000 epoch] Train loss = 17.42, Test loss = 7816.70\n",
      "[745/1000 epoch] Train loss = 13.42, Test loss = 7167.99\n",
      "[746/1000 epoch] Train loss = 9.35, Test loss = 6624.67\n",
      "[747/1000 epoch] Train loss = 10.97, Test loss = 7768.41\n",
      "[748/1000 epoch] Train loss = 13.25, Test loss = 7067.49\n",
      "[749/1000 epoch] Train loss = 13.34, Test loss = 6871.35\n",
      "[750/1000 epoch] Train loss = 11.99, Test loss = 7465.49\n",
      "[751/1000 epoch] Train loss = 9.75, Test loss = 7157.19\n",
      "[752/1000 epoch] Train loss = 9.31, Test loss = 6851.43\n",
      "[753/1000 epoch] Train loss = 11.28, Test loss = 7255.75\n",
      "[754/1000 epoch] Train loss = 11.88, Test loss = 7251.30\n",
      "[755/1000 epoch] Train loss = 10.57, Test loss = 6693.40\n",
      "[756/1000 epoch] Train loss = 9.61, Test loss = 7284.37\n",
      "[757/1000 epoch] Train loss = 9.08, Test loss = 7178.73\n",
      "[758/1000 epoch] Train loss = 9.57, Test loss = 6657.10\n",
      "[759/1000 epoch] Train loss = 10.51, Test loss = 7333.82\n",
      "[760/1000 epoch] Train loss = 10.10, Test loss = 7007.74\n",
      "[761/1000 epoch] Train loss = 9.13, Test loss = 6764.44\n",
      "[762/1000 epoch] Train loss = 8.92, Test loss = 7223.91\n",
      "[763/1000 epoch] Train loss = 9.06, Test loss = 6953.06\n",
      "[764/1000 epoch] Train loss = 9.37, Test loss = 6852.50\n",
      "[765/1000 epoch] Train loss = 9.61, Test loss = 7085.16\n",
      "[766/1000 epoch] Train loss = 9.16, Test loss = 7031.04\n",
      "[767/1000 epoch] Train loss = 8.63, Test loss = 6810.89\n",
      "[768/1000 epoch] Train loss = 8.65, Test loss = 7073.74\n",
      "[769/1000 epoch] Train loss = 8.82, Test loss = 7028.62\n",
      "[770/1000 epoch] Train loss = 8.96, Test loss = 6747.93\n",
      "[771/1000 epoch] Train loss = 9.04, Test loss = 7112.26\n",
      "[772/1000 epoch] Train loss = 8.80, Test loss = 6901.54\n",
      "[773/1000 epoch] Train loss = 8.48, Test loss = 6792.83\n",
      "[774/1000 epoch] Train loss = 8.44, Test loss = 7047.38\n",
      "[775/1000 epoch] Train loss = 8.51, Test loss = 6844.20\n",
      "[776/1000 epoch] Train loss = 8.57, Test loss = 6835.79\n",
      "[777/1000 epoch] Train loss = 8.64, Test loss = 6947.76\n",
      "[778/1000 epoch] Train loss = 8.58, Test loss = 6871.76\n",
      "[779/1000 epoch] Train loss = 8.39, Test loss = 6781.08\n",
      "[780/1000 epoch] Train loss = 8.30, Test loss = 6941.02\n",
      "[781/1000 epoch] Train loss = 8.30, Test loss = 6836.42\n",
      "[782/1000 epoch] Train loss = 8.31, Test loss = 6761.07\n",
      "[783/1000 epoch] Train loss = 8.36, Test loss = 6953.17\n",
      "[784/1000 epoch] Train loss = 8.38, Test loss = 6773.88\n",
      "[785/1000 epoch] Train loss = 8.30, Test loss = 6818.22\n",
      "[786/1000 epoch] Train loss = 8.23, Test loss = 6896.87\n",
      "[787/1000 epoch] Train loss = 8.18, Test loss = 6786.96\n",
      "[788/1000 epoch] Train loss = 8.15, Test loss = 6815.45\n",
      "[789/1000 epoch] Train loss = 8.15, Test loss = 6859.10\n",
      "[790/1000 epoch] Train loss = 8.17, Test loss = 6789.27\n",
      "[791/1000 epoch] Train loss = 8.16, Test loss = 6773.58\n",
      "[792/1000 epoch] Train loss = 8.12, Test loss = 6854.88\n",
      "[793/1000 epoch] Train loss = 8.09, Test loss = 6739.63\n",
      "[794/1000 epoch] Train loss = 8.05, Test loss = 6778.80\n",
      "[795/1000 epoch] Train loss = 8.02, Test loss = 6819.44\n",
      "[796/1000 epoch] Train loss = 8.02, Test loss = 6719.80\n",
      "[797/1000 epoch] Train loss = 8.02, Test loss = 6789.98\n",
      "[798/1000 epoch] Train loss = 8.00, Test loss = 6776.46\n",
      "[799/1000 epoch] Train loss = 7.99, Test loss = 6739.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800/1000 epoch] Train loss = 7.98, Test loss = 6764.31\n",
      "[801/1000 epoch] Train loss = 7.95, Test loss = 6782.10\n",
      "[802/1000 epoch] Train loss = 7.92, Test loss = 6720.71\n",
      "[803/1000 epoch] Train loss = 7.90, Test loss = 6775.35\n",
      "[804/1000 epoch] Train loss = 7.88, Test loss = 6761.42\n",
      "[805/1000 epoch] Train loss = 7.87, Test loss = 6719.56\n",
      "[806/1000 epoch] Train loss = 7.86, Test loss = 6775.65\n",
      "[807/1000 epoch] Train loss = 7.84, Test loss = 6732.14\n",
      "[808/1000 epoch] Train loss = 7.83, Test loss = 6728.89\n",
      "[809/1000 epoch] Train loss = 7.82, Test loss = 6744.49\n",
      "[810/1000 epoch] Train loss = 7.81, Test loss = 6729.12\n",
      "[811/1000 epoch] Train loss = 7.79, Test loss = 6703.69\n",
      "[812/1000 epoch] Train loss = 7.77, Test loss = 6745.85\n",
      "[813/1000 epoch] Train loss = 7.76, Test loss = 6697.87\n",
      "[814/1000 epoch] Train loss = 7.74, Test loss = 6713.96\n",
      "[815/1000 epoch] Train loss = 7.72, Test loss = 6721.17\n",
      "[816/1000 epoch] Train loss = 7.71, Test loss = 6697.37\n",
      "[817/1000 epoch] Train loss = 7.69, Test loss = 6704.05\n",
      "[818/1000 epoch] Train loss = 7.68, Test loss = 6712.79\n",
      "[819/1000 epoch] Train loss = 7.66, Test loss = 6683.90\n",
      "[820/1000 epoch] Train loss = 7.65, Test loss = 6699.65\n",
      "[821/1000 epoch] Train loss = 7.64, Test loss = 6695.45\n",
      "[822/1000 epoch] Train loss = 7.62, Test loss = 6673.03\n",
      "[823/1000 epoch] Train loss = 7.61, Test loss = 6691.81\n",
      "[824/1000 epoch] Train loss = 7.60, Test loss = 6674.58\n",
      "[825/1000 epoch] Train loss = 7.59, Test loss = 6667.84\n",
      "[826/1000 epoch] Train loss = 7.57, Test loss = 6673.60\n",
      "[827/1000 epoch] Train loss = 7.56, Test loss = 6664.57\n",
      "[828/1000 epoch] Train loss = 7.55, Test loss = 6649.94\n",
      "[829/1000 epoch] Train loss = 7.54, Test loss = 6668.34\n",
      "[830/1000 epoch] Train loss = 7.53, Test loss = 6637.48\n",
      "[831/1000 epoch] Train loss = 7.52, Test loss = 6653.92\n",
      "[832/1000 epoch] Train loss = 7.51, Test loss = 6635.30\n",
      "[833/1000 epoch] Train loss = 7.51, Test loss = 6643.66\n",
      "[834/1000 epoch] Train loss = 7.51, Test loss = 6615.72\n",
      "[835/1000 epoch] Train loss = 7.52, Test loss = 6651.05\n",
      "[836/1000 epoch] Train loss = 7.54, Test loss = 6586.75\n",
      "[837/1000 epoch] Train loss = 7.59, Test loss = 6655.15\n",
      "[838/1000 epoch] Train loss = 7.66, Test loss = 6563.77\n",
      "[839/1000 epoch] Train loss = 7.79, Test loss = 6658.50\n",
      "[840/1000 epoch] Train loss = 8.02, Test loss = 6528.02\n",
      "[841/1000 epoch] Train loss = 8.43, Test loss = 6688.11\n",
      "[842/1000 epoch] Train loss = 9.11, Test loss = 6459.38\n",
      "[843/1000 epoch] Train loss = 10.36, Test loss = 6754.50\n",
      "[844/1000 epoch] Train loss = 12.48, Test loss = 6354.29\n",
      "[845/1000 epoch] Train loss = 16.53, Test loss = 6871.70\n",
      "[846/1000 epoch] Train loss = 23.34, Test loss = 6180.57\n",
      "[847/1000 epoch] Train loss = 36.79, Test loss = 7105.66\n",
      "[848/1000 epoch] Train loss = 58.99, Test loss = 5871.29\n",
      "[849/1000 epoch] Train loss = 105.49, Test loss = 7587.82\n",
      "[850/1000 epoch] Train loss = 172.42, Test loss = 5340.37\n",
      "[851/1000 epoch] Train loss = 324.70, Test loss = 8481.88\n",
      "[852/1000 epoch] Train loss = 439.43, Test loss = 4660.76\n",
      "[853/1000 epoch] Train loss = 688.70, Test loss = 9371.18\n",
      "[854/1000 epoch] Train loss = 478.61, Test loss = 4583.82\n",
      "[855/1000 epoch] Train loss = 301.27, Test loss = 7765.73\n",
      "[856/1000 epoch] Train loss = 60.84, Test loss = 6652.85\n",
      "[857/1000 epoch] Train loss = 43.04, Test loss = 5107.87\n",
      "[858/1000 epoch] Train loss = 200.86, Test loss = 9467.84\n",
      "[859/1000 epoch] Train loss = 286.21, Test loss = 4810.27\n",
      "[860/1000 epoch] Train loss = 264.42, Test loss = 7480.32\n",
      "[861/1000 epoch] Train loss = 91.25, Test loss = 6800.50\n",
      "[862/1000 epoch] Train loss = 11.49, Test loss = 5425.71\n",
      "[863/1000 epoch] Train loss = 69.81, Test loss = 8071.81\n",
      "[864/1000 epoch] Train loss = 139.67, Test loss = 5592.78\n",
      "[865/1000 epoch] Train loss = 126.75, Test loss = 7182.81\n",
      "[866/1000 epoch] Train loss = 34.70, Test loss = 6992.59\n",
      "[867/1000 epoch] Train loss = 20.13, Test loss = 6075.58\n",
      "[868/1000 epoch] Train loss = 78.58, Test loss = 8082.04\n",
      "[869/1000 epoch] Train loss = 91.11, Test loss = 6014.65\n",
      "[870/1000 epoch] Train loss = 46.86, Test loss = 7065.86\n",
      "[871/1000 epoch] Train loss = 12.08, Test loss = 7233.33\n",
      "[872/1000 epoch] Train loss = 37.33, Test loss = 5680.88\n",
      "[873/1000 epoch] Train loss = 65.77, Test loss = 7753.87\n",
      "[874/1000 epoch] Train loss = 40.23, Test loss = 6061.66\n",
      "[875/1000 epoch] Train loss = 12.98, Test loss = 6248.95\n",
      "[876/1000 epoch] Train loss = 23.74, Test loss = 7745.00\n",
      "[877/1000 epoch] Train loss = 42.67, Test loss = 5659.12\n",
      "[878/1000 epoch] Train loss = 35.44, Test loss = 7356.43\n",
      "[879/1000 epoch] Train loss = 14.06, Test loss = 7126.99\n",
      "[880/1000 epoch] Train loss = 12.64, Test loss = 6002.81\n",
      "[881/1000 epoch] Train loss = 27.69, Test loss = 7943.43\n",
      "[882/1000 epoch] Train loss = 31.34, Test loss = 6474.67\n",
      "[883/1000 epoch] Train loss = 19.37, Test loss = 6694.28\n",
      "[884/1000 epoch] Train loss = 9.85, Test loss = 7553.04\n",
      "[885/1000 epoch] Train loss = 13.91, Test loss = 6317.29\n",
      "[886/1000 epoch] Train loss = 22.10, Test loss = 7142.64\n",
      "[887/1000 epoch] Train loss = 21.81, Test loss = 6862.75\n",
      "[888/1000 epoch] Train loss = 14.79, Test loss = 6638.59\n",
      "[889/1000 epoch] Train loss = 8.66, Test loss = 6881.60\n",
      "[890/1000 epoch] Train loss = 10.16, Test loss = 6668.39\n",
      "[891/1000 epoch] Train loss = 15.73, Test loss = 6815.77\n",
      "[892/1000 epoch] Train loss = 17.12, Test loss = 6487.07\n",
      "[893/1000 epoch] Train loss = 13.48, Test loss = 6974.97\n",
      "[894/1000 epoch] Train loss = 9.08, Test loss = 6550.30\n",
      "[895/1000 epoch] Train loss = 8.38, Test loss = 6658.58\n",
      "[896/1000 epoch] Train loss = 10.83, Test loss = 7089.68\n",
      "[897/1000 epoch] Train loss = 13.01, Test loss = 6360.46\n",
      "[898/1000 epoch] Train loss = 12.55, Test loss = 7093.02\n",
      "[899/1000 epoch] Train loss = 9.89, Test loss = 6732.89\n",
      "[900/1000 epoch] Train loss = 7.94, Test loss = 6556.65\n",
      "[901/1000 epoch] Train loss = 8.37, Test loss = 7068.46\n",
      "[902/1000 epoch] Train loss = 10.01, Test loss = 6472.12\n",
      "[903/1000 epoch] Train loss = 10.83, Test loss = 6804.95\n",
      "[904/1000 epoch] Train loss = 10.03, Test loss = 6727.92\n",
      "[905/1000 epoch] Train loss = 8.58, Test loss = 6603.02\n",
      "[906/1000 epoch] Train loss = 7.71, Test loss = 6742.01\n",
      "[907/1000 epoch] Train loss = 8.08, Test loss = 6657.85\n",
      "[908/1000 epoch] Train loss = 9.05, Test loss = 6727.00\n",
      "[909/1000 epoch] Train loss = 9.41, Test loss = 6591.63\n",
      "[910/1000 epoch] Train loss = 8.89, Test loss = 6811.73\n",
      "[911/1000 epoch] Train loss = 8.04, Test loss = 6572.71\n",
      "[912/1000 epoch] Train loss = 7.59, Test loss = 6682.70\n",
      "[913/1000 epoch] Train loss = 7.74, Test loss = 6773.46\n",
      "[914/1000 epoch] Train loss = 8.22, Test loss = 6483.74\n",
      "[915/1000 epoch] Train loss = 8.51, Test loss = 6833.67\n",
      "[916/1000 epoch] Train loss = 8.33, Test loss = 6560.60\n",
      "[917/1000 epoch] Train loss = 7.86, Test loss = 6635.26\n",
      "[918/1000 epoch] Train loss = 7.51, Test loss = 6725.28\n",
      "[919/1000 epoch] Train loss = 7.47, Test loss = 6525.12\n",
      "[920/1000 epoch] Train loss = 7.65, Test loss = 6686.65\n",
      "[921/1000 epoch] Train loss = 7.86, Test loss = 6574.22\n",
      "[922/1000 epoch] Train loss = 7.94, Test loss = 6608.48\n",
      "[923/1000 epoch] Train loss = 7.81, Test loss = 6560.99\n",
      "[924/1000 epoch] Train loss = 7.56, Test loss = 6623.43\n",
      "[925/1000 epoch] Train loss = 7.37, Test loss = 6529.78\n",
      "[926/1000 epoch] Train loss = 7.32, Test loss = 6581.48\n",
      "[927/1000 epoch] Train loss = 7.38, Test loss = 6600.39\n",
      "[928/1000 epoch] Train loss = 7.48, Test loss = 6472.15\n",
      "[929/1000 epoch] Train loss = 7.54, Test loss = 6648.24\n",
      "[930/1000 epoch] Train loss = 7.52, Test loss = 6463.72\n",
      "[931/1000 epoch] Train loss = 7.42, Test loss = 6565.26\n",
      "[932/1000 epoch] Train loss = 7.30, Test loss = 6542.58\n",
      "[933/1000 epoch] Train loss = 7.22, Test loss = 6484.41\n",
      "[934/1000 epoch] Train loss = 7.20, Test loss = 6557.68\n",
      "[935/1000 epoch] Train loss = 7.21, Test loss = 6491.03\n",
      "[936/1000 epoch] Train loss = 7.25, Test loss = 6520.83\n",
      "[937/1000 epoch] Train loss = 7.27, Test loss = 6491.35\n",
      "[938/1000 epoch] Train loss = 7.27, Test loss = 6520.92\n",
      "[939/1000 epoch] Train loss = 7.24, Test loss = 6447.91\n",
      "[940/1000 epoch] Train loss = 7.19, Test loss = 6523.59\n",
      "[941/1000 epoch] Train loss = 7.14, Test loss = 6439.15\n",
      "[942/1000 epoch] Train loss = 7.10, Test loss = 6472.87\n",
      "[943/1000 epoch] Train loss = 7.07, Test loss = 6477.38\n",
      "[944/1000 epoch] Train loss = 7.07, Test loss = 6419.63\n",
      "[945/1000 epoch] Train loss = 7.07, Test loss = 6488.92\n",
      "[946/1000 epoch] Train loss = 7.08, Test loss = 6417.59\n",
      "[947/1000 epoch] Train loss = 7.08, Test loss = 6460.25\n",
      "[948/1000 epoch] Train loss = 7.07, Test loss = 6428.16\n",
      "[949/1000 epoch] Train loss = 7.06, Test loss = 6444.06\n",
      "[950/1000 epoch] Train loss = 7.04, Test loss = 6409.22\n",
      "[951/1000 epoch] Train loss = 7.02, Test loss = 6447.92\n",
      "[952/1000 epoch] Train loss = 6.99, Test loss = 6387.91\n",
      "[953/1000 epoch] Train loss = 6.97, Test loss = 6431.03\n",
      "[954/1000 epoch] Train loss = 6.95, Test loss = 6394.04\n",
      "[955/1000 epoch] Train loss = 6.94, Test loss = 6393.04\n",
      "[956/1000 epoch] Train loss = 6.92, Test loss = 6401.62\n",
      "[957/1000 epoch] Train loss = 6.91, Test loss = 6369.00\n",
      "[958/1000 epoch] Train loss = 6.90, Test loss = 6387.96\n",
      "[959/1000 epoch] Train loss = 6.89, Test loss = 6362.48\n",
      "[960/1000 epoch] Train loss = 6.89, Test loss = 6370.03\n",
      "[961/1000 epoch] Train loss = 6.88, Test loss = 6350.68\n",
      "[962/1000 epoch] Train loss = 6.88, Test loss = 6367.23\n",
      "[963/1000 epoch] Train loss = 6.87, Test loss = 6326.46\n",
      "[964/1000 epoch] Train loss = 6.87, Test loss = 6369.28\n",
      "[965/1000 epoch] Train loss = 6.87, Test loss = 6306.22\n",
      "[966/1000 epoch] Train loss = 6.86, Test loss = 6359.45\n",
      "[967/1000 epoch] Train loss = 6.86, Test loss = 6296.67\n",
      "[968/1000 epoch] Train loss = 6.86, Test loss = 6343.30\n",
      "[969/1000 epoch] Train loss = 6.86, Test loss = 6284.29\n",
      "[970/1000 epoch] Train loss = 6.86, Test loss = 6332.10\n",
      "[971/1000 epoch] Train loss = 6.86, Test loss = 6267.81\n",
      "[972/1000 epoch] Train loss = 6.87, Test loss = 6329.10\n",
      "[973/1000 epoch] Train loss = 6.88, Test loss = 6247.07\n",
      "[974/1000 epoch] Train loss = 6.89, Test loss = 6330.06\n",
      "[975/1000 epoch] Train loss = 6.92, Test loss = 6227.73\n",
      "[976/1000 epoch] Train loss = 6.97, Test loss = 6330.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[977/1000 epoch] Train loss = 7.05, Test loss = 6200.31\n",
      "[978/1000 epoch] Train loss = 7.18, Test loss = 6348.44\n",
      "[979/1000 epoch] Train loss = 7.39, Test loss = 6153.57\n",
      "[980/1000 epoch] Train loss = 7.72, Test loss = 6388.15\n",
      "[981/1000 epoch] Train loss = 8.22, Test loss = 6088.55\n",
      "[982/1000 epoch] Train loss = 9.05, Test loss = 6451.18\n",
      "[983/1000 epoch] Train loss = 10.35, Test loss = 6004.03\n",
      "[984/1000 epoch] Train loss = 12.56, Test loss = 6550.48\n",
      "[985/1000 epoch] Train loss = 15.98, Test loss = 5862.42\n",
      "[986/1000 epoch] Train loss = 22.15, Test loss = 6747.00\n",
      "[987/1000 epoch] Train loss = 31.50, Test loss = 5609.88\n",
      "[988/1000 epoch] Train loss = 49.27, Test loss = 7118.19\n",
      "[989/1000 epoch] Train loss = 74.46, Test loss = 5205.50\n",
      "[990/1000 epoch] Train loss = 125.25, Test loss = 7773.97\n",
      "[991/1000 epoch] Train loss = 183.43, Test loss = 4628.98\n",
      "[992/1000 epoch] Train loss = 306.20, Test loss = 8790.74\n",
      "[993/1000 epoch] Train loss = 356.74, Test loss = 4094.54\n",
      "[994/1000 epoch] Train loss = 477.41, Test loss = 9418.25\n",
      "[995/1000 epoch] Train loss = 339.27, Test loss = 4290.13\n",
      "[996/1000 epoch] Train loss = 222.83, Test loss = 7794.01\n",
      "[997/1000 epoch] Train loss = 62.81, Test loss = 6182.46\n",
      "[998/1000 epoch] Train loss = 14.53, Test loss = 5247.99\n",
      "[999/1000 epoch] Train loss = 75.65, Test loss = 8708.28\n",
      "[1000/1000 epoch] Train loss = 159.41, Test loss = 4451.33\n",
      "CPU times: user 5.14 s, sys: 681 ms, total: 5.82 s\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = PredictionModel().to(device)\n",
    "\n",
    "# в качестве параметров оптимизатору передаем параметры нашей модели\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "# в качестве функции ошибки используем MSE, так как решаем задачу регрессии\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "x_train_device = x_train.unsqueeze(-1).to(device)\n",
    "x_test_device = x_test.unsqueeze(-1).to(device)\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # включим режим обучения\n",
    "    model.train()\n",
    "    \n",
    "    # обнулим все градиенты, чтобы делать градиентный спуск только по текущим данным\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_preds = model(x_train_device).cpu()\n",
    "    train_loss = criterion(y_preds, y_train.unsqueeze(-1))\n",
    "    \n",
    "    # сделаем обратное распространение ошибки\n",
    "    train_loss.backward()\n",
    "    # и шаг градиентного спуска с помощью оптимизатора\n",
    "    optimizer.step()\n",
    "    \n",
    "    # включим режим инференса\n",
    "    model.eval()\n",
    "    \n",
    "    # режим no_grad отключает подсчет градиентов\n",
    "    with torch.no_grad():\n",
    "        y_preds = model(x_test_device).squeeze(-1).cpu()\n",
    "    \n",
    "    test_loss = criterion(y_preds, y_test)\n",
    "    \n",
    "    print(f'[{epoch + 1}/{n_epochs} epoch] Train loss = {train_loss:.2f}, Test loss = {test_loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288ce8b6",
   "metadata": {},
   "source": [
    "Используя mps получилось еще дольше, как думаете, почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0265b",
   "metadata": {},
   "source": [
    "## Попробуем реализовать модель SLIM\n",
    "\n",
    "**Важно**: это не является оригинальным алгоритмом, так как не требуется положительная определнность матрицы весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте следующие строчки, чтобы загрузить датасет\n",
    "# !wget -q https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "# !unzip -q ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d146b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (575_281, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>1193</td><td>5</td><td>978300760</td></tr><tr><td>1</td><td>3408</td><td>4</td><td>978300275</td></tr><tr><td>1</td><td>2355</td><td>5</td><td>978824291</td></tr><tr><td>1</td><td>1287</td><td>5</td><td>978302039</td></tr><tr><td>1</td><td>2804</td><td>5</td><td>978300719</td></tr><tr><td>1</td><td>594</td><td>4</td><td>978302268</td></tr><tr><td>1</td><td>919</td><td>4</td><td>978301368</td></tr><tr><td>1</td><td>595</td><td>5</td><td>978824268</td></tr><tr><td>1</td><td>938</td><td>4</td><td>978301752</td></tr><tr><td>1</td><td>2398</td><td>4</td><td>978302281</td></tr><tr><td>1</td><td>2918</td><td>4</td><td>978302124</td></tr><tr><td>1</td><td>1035</td><td>5</td><td>978301753</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6040</td><td>2019</td><td>5</td><td>956703977</td></tr><tr><td>6040</td><td>541</td><td>4</td><td>956715288</td></tr><tr><td>6040</td><td>1077</td><td>5</td><td>964828799</td></tr><tr><td>6040</td><td>549</td><td>4</td><td>956704746</td></tr><tr><td>6040</td><td>2022</td><td>5</td><td>956716207</td></tr><tr><td>6040</td><td>2028</td><td>5</td><td>956704519</td></tr><tr><td>6040</td><td>1080</td><td>4</td><td>957717322</td></tr><tr><td>6040</td><td>1089</td><td>4</td><td>956704996</td></tr><tr><td>6040</td><td>1094</td><td>5</td><td>956704887</td></tr><tr><td>6040</td><td>562</td><td>5</td><td>956704746</td></tr><tr><td>6040</td><td>1096</td><td>4</td><td>956715648</td></tr><tr><td>6040</td><td>1097</td><td>4</td><td>956715569</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (575_281, 4)\n",
       "┌─────────┬─────────┬────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ rating ┆ timestamp │\n",
       "│ ---     ┆ ---     ┆ ---    ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64    ┆ i64       │\n",
       "╞═════════╪═════════╪════════╪═══════════╡\n",
       "│ 1       ┆ 1193    ┆ 5      ┆ 978300760 │\n",
       "│ 1       ┆ 3408    ┆ 4      ┆ 978300275 │\n",
       "│ 1       ┆ 2355    ┆ 5      ┆ 978824291 │\n",
       "│ 1       ┆ 1287    ┆ 5      ┆ 978302039 │\n",
       "│ …       ┆ …       ┆ …      ┆ …         │\n",
       "│ 6040    ┆ 1094    ┆ 5      ┆ 956704887 │\n",
       "│ 6040    ┆ 562     ┆ 5      ┆ 956704746 │\n",
       "│ 6040    ┆ 1096    ┆ 4      ┆ 956715648 │\n",
       "│ 6040    ┆ 1097    ┆ 4      ┆ 956715569 │\n",
       "└─────────┴─────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "    'ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "    engine='python'\n",
    ")\n",
    "ratings = pl.from_pandas(ratings).filter(pl.col('rating') >= 4)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2f8083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6_038, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>train_item_ids</th><th>train_ratings</th><th>test_item_ids</th><th>test_ratings</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>2144</td><td>[1258, 1407, … 1986]</td><td>[4, 5, … 4]</td><td>[70, 2959, 1222]</td><td>[4, 4, 4]</td></tr><tr><td>1248</td><td>[1256, 1259, … 3911]</td><td>[5, 5, … 5]</td><td>[1238, 3925, 1242]</td><td>[5, 4, 4]</td></tr><tr><td>1408</td><td>[1258, 589, … 555]</td><td>[5, 4, … 4]</td><td>[556, 99, 1233]</td><td>[5, 5, 4]</td></tr><tr><td>1376</td><td>[2987, 2997, … 1213]</td><td>[4, 4, … 4]</td><td>[2975, 1093, 1094]</td><td>[4, 4, 4]</td></tr><tr><td>784</td><td>[2987, 1617, … 507]</td><td>[5, 5, … 4]</td><td>[3753, 2959, 2979]</td><td>[5, 5, 4]</td></tr><tr><td>560</td><td>[2993, 2058, … 95]</td><td>[5, 5, … 4]</td><td>[1233, 1240, 2985]</td><td>[5, 4, 4]</td></tr><tr><td>2776</td><td>[719, 3791, … 1095]</td><td>[4, 5, … 4]</td><td>[1097, 1242, 1246]</td><td>[5, 4, 5]</td></tr><tr><td>4544</td><td>[3789, 908, … 2731]</td><td>[4, 5, … 4]</td><td>[3742, 1095, 3788]</td><td>[4, 5, 5]</td></tr><tr><td>4552</td><td>[2058, 589, … 527]</td><td>[4, 5, … 5]</td><td>[3744, 534, 2028]</td><td>[4, 4, 5]</td></tr><tr><td>3720</td><td>[1249, 1250, … 2966]</td><td>[4, 5, … 5]</td><td>[1089, 1233, 1247]</td><td>[4, 4, 5]</td></tr><tr><td>4768</td><td>[580, 589, … 199]</td><td>[5, 4, … 4]</td><td>[527, 2028, 1092]</td><td>[5, 4, 5]</td></tr><tr><td>3104</td><td>[1249, 589, … 1214]</td><td>[5, 4, … 4]</td><td>[1219, 1089, 1240]</td><td>[5, 5, 5]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3431</td><td>[1408, 2067, … 2013]</td><td>[4, 5, … 4]</td><td>[2028, 1230, 1247]</td><td>[5, 4, 4]</td></tr><tr><td>3719</td><td>[2987, 2997, … 2761]</td><td>[5, 4, … 5]</td><td>[2762, 1961, 2770]</td><td>[5, 5, 5]</td></tr><tr><td>471</td><td>[1250, 1252, … 1223]</td><td>[5, 5, … 5]</td><td>[2028, 2968, 1240]</td><td>[5, 4, 4]</td></tr><tr><td>1911</td><td>[1, 1270, … 2762]</td><td>[4, 4, … 5]</td><td>[3723, 1207, 1247]</td><td>[4, 5, 4]</td></tr><tr><td>2455</td><td>[2987, 3932, … 1215]</td><td>[4, 5, … 5]</td><td>[541, 1240, 2985]</td><td>[5, 5, 4]</td></tr><tr><td>191</td><td>[1517, 2329, … 409]</td><td>[4, 5, … 4]</td><td>[19, 344, 2858]</td><td>[4, 5, 5]</td></tr><tr><td>2463</td><td>[3930, 3932, … 1097]</td><td>[4, 4, … 4]</td><td>[1240, 3928, 3785]</td><td>[4, 4, 4]</td></tr><tr><td>4935</td><td>[912, 246, … 110]</td><td>[4, 4, … 4]</td><td>[159, 2761, 2028]</td><td>[4, 5, 4]</td></tr><tr><td>1359</td><td>[720, 588, … 3752]</td><td>[5, 5, … 4]</td><td>[2013, 3753, 2018]</td><td>[4, 5, 5]</td></tr><tr><td>4071</td><td>[2054, 1257, … 1220]</td><td>[4, 4, … 5]</td><td>[553, 1090, 2976]</td><td>[5, 5, 4]</td></tr><tr><td>5375</td><td>[1, 3005, … 1747]</td><td>[5, 5, … 4]</td><td>[2762, 1028, 551]</td><td>[5, 4, 4]</td></tr><tr><td>2823</td><td>[3948, 1266, … 1060]</td><td>[4, 4, … 4]</td><td>[1213, 1089, 3916]</td><td>[4, 4, 4]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6_038, 5)\n",
       "┌─────────┬──────────────────────┬───────────────┬────────────────────┬──────────────┐\n",
       "│ user_id ┆ train_item_ids       ┆ train_ratings ┆ test_item_ids      ┆ test_ratings │\n",
       "│ ---     ┆ ---                  ┆ ---           ┆ ---                ┆ ---          │\n",
       "│ i64     ┆ list[i64]            ┆ list[i64]     ┆ list[i64]          ┆ list[i64]    │\n",
       "╞═════════╪══════════════════════╪═══════════════╪════════════════════╪══════════════╡\n",
       "│ 2144    ┆ [1258, 1407, … 1986] ┆ [4, 5, … 4]   ┆ [70, 2959, 1222]   ┆ [4, 4, 4]    │\n",
       "│ 1248    ┆ [1256, 1259, … 3911] ┆ [5, 5, … 5]   ┆ [1238, 3925, 1242] ┆ [5, 4, 4]    │\n",
       "│ 1408    ┆ [1258, 589, … 555]   ┆ [5, 4, … 4]   ┆ [556, 99, 1233]    ┆ [5, 5, 4]    │\n",
       "│ 1376    ┆ [2987, 2997, … 1213] ┆ [4, 4, … 4]   ┆ [2975, 1093, 1094] ┆ [4, 4, 4]    │\n",
       "│ …       ┆ …                    ┆ …             ┆ …                  ┆ …            │\n",
       "│ 1359    ┆ [720, 588, … 3752]   ┆ [5, 5, … 4]   ┆ [2013, 3753, 2018] ┆ [4, 5, 5]    │\n",
       "│ 4071    ┆ [2054, 1257, … 1220] ┆ [4, 4, … 5]   ┆ [553, 1090, 2976]  ┆ [5, 5, 4]    │\n",
       "│ 5375    ┆ [1, 3005, … 1747]    ┆ [5, 5, … 4]   ┆ [2762, 1028, 551]  ┆ [5, 4, 4]    │\n",
       "│ 2823    ┆ [3948, 1266, … 1060] ┆ [4, 4, … 4]   ┆ [1213, 1089, 3916] ┆ [4, 4, 4]    │\n",
       "└─────────┴──────────────────────┴───────────────┴────────────────────┴──────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = (\n",
    "    ratings\n",
    "    .groupby('user_id')\n",
    "    .agg([\n",
    "        pl.col('item_id').apply(lambda x: x[:-3]).alias('train_item_ids'),\n",
    "        pl.col('rating').apply(lambda x: x[:-3]).alias('train_ratings'),\n",
    "        pl.col('item_id').apply(lambda x: x[-3:]).alias('test_item_ids'),\n",
    "        pl.col('rating').apply(lambda x: x[-3:]).alias('test_ratings'),\n",
    "    ])\n",
    ")\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c146c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "средняя длина сессии 55\n"
     ]
    }
   ],
   "source": [
    "median_seq_len = int(grouped_df['train_item_ids'].apply(len).median())\n",
    "print(f\"средняя длина сессии {median_seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7f5704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def user_intersection(y_relevant: List[str], y_recs: List[str], k: int = TOP_K) -> int:\n",
    "    return len(set(y_relevant).intersection(y_recs[:k]))\n",
    "\n",
    "\n",
    "def user_hitrate(y_relevant: List[str], y_recs: List[str], k: int = TOP_K) -> int:\n",
    "    return int(user_intersection(y_relevant, y_recs, k) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa30e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6041x3953 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 557171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соберем строчки для разреженной матрицы\n",
    "rows = []\n",
    "cols = []\n",
    "values = []\n",
    "\n",
    "for user_id, train_item_ids, train_ratings in grouped_df.select(\n",
    "    'user_id', 'train_item_ids', 'train_ratings'\n",
    ").rows():\n",
    "    rows.extend([user_id] * len(train_item_ids))\n",
    "    cols.extend(train_item_ids)\n",
    "    values.extend(train_ratings)\n",
    "\n",
    "user_item_data = sp.csr_matrix((values, (rows, cols)), dtype=np.float32)\n",
    "user_item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514167e",
   "metadata": {},
   "source": [
    "преобразуем scipy разреженную матрицу в pytorch разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6584579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   1,    1,    1,  ..., 6040, 6040, 6040],\n",
       "                       [   1,   48,  150,  ..., 3735, 3751, 3819]]),\n",
       "       values=tensor([5., 5., 5.,  ..., 4., 4., 5.]),\n",
       "       size=(6041, 3953), nnz=557171, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_data_coo = user_item_data.tocoo()\n",
    "\n",
    "values = user_item_data_coo.data\n",
    "indices = np.vstack((user_item_data_coo.row, user_item_data_coo.col))\n",
    "\n",
    "i = torch.LongTensor(indices)\n",
    "v = torch.FloatTensor(values)\n",
    "shape = user_item_data_coo.shape\n",
    "\n",
    "R = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f89510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLIM(nn.Module):\n",
    "    def __init__(self, R: torch.Tensor):\n",
    "        super().__init__()\n",
    "        \n",
    "        _, n = R.shape\n",
    "        self.R = R\n",
    "        # проинициализируем матрицу W нулями\n",
    "        self.W = torch.zeros(n, n)\n",
    "        # дадим знать pytorch, что для этой матрицы нужно посчитать градиент\n",
    "        self.W.requires_grad = True\n",
    "        # будем использовать маску, чтобы элементы по диагонали никак не участвовали в обучении\n",
    "        self.mask = 1 - torch.eye(n)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        W_masked = self.W * self.mask\n",
    "        return self.R @ W_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95f7650a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 epoch]\tLoss = 5440163.5, Hitrate@10 = 0.0\n",
      "[1 epoch]\tLoss = 6328567.0, Hitrate@10 = 0.01159324279562769\n",
      "[2 epoch]\tLoss = 4658681.5, Hitrate@10 = 0.13895329579330903\n",
      "[3 epoch]\tLoss = 4830916.5, Hitrate@10 = 0.14027823782709506\n",
      "[4 epoch]\tLoss = 5078073.0, Hitrate@10 = 0.14491553494534615\n",
      "[5 epoch]\tLoss = 4548290.0, Hitrate@10 = 0.1467373302418019\n",
      "[6 epoch]\tLoss = 3988636.75, Hitrate@10 = 0.15071215634316\n",
      "[7 epoch]\tLoss = 3921618.25, Hitrate@10 = 0.15336204041073204\n",
      "[8 epoch]\tLoss = 4114344.75, Hitrate@10 = 0.16098045710500167\n",
      "[9 epoch]\tLoss = 4077572.5, Hitrate@10 = 0.17025505134150382\n",
      "[10 epoch]\tLoss = 3775872.75, Hitrate@10 = 0.17737661477310368\n",
      "[11 epoch]\tLoss = 3508397.25, Hitrate@10 = 0.1825107651540245\n",
      "[12 epoch]\tLoss = 3465091.75, Hitrate@10 = 0.18648559125538258\n",
      "[13 epoch]\tLoss = 3545176.25, Hitrate@10 = 0.1878105332891686\n",
      "[14 epoch]\tLoss = 3537846.5, Hitrate@10 = 0.19261344816164294\n",
      "[15 epoch]\tLoss = 3392435.25, Hitrate@10 = 0.2007287181185823\n",
      "[16 epoch]\tLoss = 3228467.5, Hitrate@10 = 0.210997018880424\n",
      "[17 epoch]\tLoss = 3158218.25, Hitrate@10 = 0.21662802252401459\n",
      "[18 epoch]\tLoss = 3170076.5, Hitrate@10 = 0.226730705531633\n",
      "[19 epoch]\tLoss = 3168997.0, Hitrate@10 = 0.23269294468367008\n",
      "[20 epoch]\tLoss = 3098904.25, Hitrate@10 = 0.23318979794633984\n",
      "[21 epoch]\tLoss = 2995136.5, Hitrate@10 = 0.2330241801921166\n",
      "[22 epoch]\tLoss = 2925171.25, Hitrate@10 = 0.23434912222590262\n",
      "[23 epoch]\tLoss = 2907821.75, Hitrate@10 = 0.23070553163299107\n",
      "[24 epoch]\tLoss = 2902312.5, Hitrate@10 = 0.22855250082808878\n",
      "[25 epoch]\tLoss = 2866486.25, Hitrate@10 = 0.22474329248095395\n",
      "[26 epoch]\tLoss = 2804783.25, Hitrate@10 = 0.2220934084133819\n",
      "[27 epoch]\tLoss = 2751450.5, Hitrate@10 = 0.21994037760847962\n",
      "[28 epoch]\tLoss = 2723724.75, Hitrate@10 = 0.21911228883736336\n",
      "[29 epoch]\tLoss = 2707272.0, Hitrate@10 = 0.21878105332891687\n",
      "[30 epoch]\tLoss = 2681128.5, Hitrate@10 = 0.21844981782047035\n",
      "[31 epoch]\tLoss = 2642279.75, Hitrate@10 = 0.2204372308711494\n",
      "[32 epoch]\tLoss = 2603168.5, Hitrate@10 = 0.2217621729049354\n",
      "[33 epoch]\tLoss = 2574298.75, Hitrate@10 = 0.2220934084133819\n",
      "[34 epoch]\tLoss = 2554439.25, Hitrate@10 = 0.2239152037098377\n",
      "[35 epoch]\tLoss = 2534443.0, Hitrate@10 = 0.22374958595561445\n",
      "[36 epoch]\tLoss = 2508006.0, Hitrate@10 = 0.2257369990062935\n",
      "[37 epoch]\tLoss = 2478302.25, Hitrate@10 = 0.2257369990062935\n",
      "[38 epoch]\tLoss = 2453222.75, Hitrate@10 = 0.22540576349784697\n",
      "[39 epoch]\tLoss = 2434951.5, Hitrate@10 = 0.22524014574362372\n",
      "[40 epoch]\tLoss = 2417577.5, Hitrate@10 = 0.22308711493872144\n",
      "[41 epoch]\tLoss = 2395716.75, Hitrate@10 = 0.22225902616760518\n",
      "[42 epoch]\tLoss = 2371565.75, Hitrate@10 = 0.2217621729049354\n",
      "[43 epoch]\tLoss = 2350924.0, Hitrate@10 = 0.21994037760847962\n",
      "[44 epoch]\tLoss = 2334993.25, Hitrate@10 = 0.2172904935409076\n",
      "[45 epoch]\tLoss = 2319445.25, Hitrate@10 = 0.21530308049022856\n",
      "[46 epoch]\tLoss = 2300969.75, Hitrate@10 = 0.2144749917191123\n",
      "[47 epoch]\tLoss = 2281547.5, Hitrate@10 = 0.21430937396488903\n",
      "[48 epoch]\tLoss = 2264854.5, Hitrate@10 = 0.21563431599867505\n",
      "[49 epoch]\tLoss = 2250759.25, Hitrate@10 = 0.2157999337528983\n",
      "[50 epoch]\tLoss = 2236119.0, Hitrate@10 = 0.21679364027823783\n",
      "[51 epoch]\tLoss = 2219877.25, Hitrate@10 = 0.2172904935409076\n",
      "[52 epoch]\tLoss = 2204136.75, Hitrate@10 = 0.2182842000662471\n",
      "[53 epoch]\tLoss = 2190354.5, Hitrate@10 = 0.21911228883736336\n",
      "[54 epoch]\tLoss = 2177425.0, Hitrate@10 = 0.21977475985425637\n",
      "[55 epoch]\tLoss = 2163924.25, Hitrate@10 = 0.21911228883736336\n",
      "[56 epoch]\tLoss = 2150089.0, Hitrate@10 = 0.21878105332891687\n",
      "[57 epoch]\tLoss = 2136956.5, Hitrate@10 = 0.2172904935409076\n",
      "[58 epoch]\tLoss = 2124796.5, Hitrate@10 = 0.21712487578668432\n",
      "[59 epoch]\tLoss = 2112967.5, Hitrate@10 = 0.21629678701556806\n",
      "[60 epoch]\tLoss = 2100917.25, Hitrate@10 = 0.21613116926134482\n",
      "[61 epoch]\tLoss = 2088906.75, Hitrate@10 = 0.21497184498178204\n",
      "[62 epoch]\tLoss = 2077525.875, Hitrate@10 = 0.21397813845644253\n",
      "[63 epoch]\tLoss = 2066766.625, Hitrate@10 = 0.21348128519377277\n",
      "[64 epoch]\tLoss = 2056087.0, Hitrate@10 = 0.21281881417687976\n",
      "[65 epoch]\tLoss = 2045292.5, Hitrate@10 = 0.21364690294799601\n",
      "[66 epoch]\tLoss = 2034777.25, Hitrate@10 = 0.21281881417687976\n",
      "[67 epoch]\tLoss = 2024808.5, Hitrate@10 = 0.2119907254057635\n",
      "[68 epoch]\tLoss = 2015094.125, Hitrate@10 = 0.21182510765154025\n",
      "[69 epoch]\tLoss = 2005320.375, Hitrate@10 = 0.21182510765154025\n",
      "[70 epoch]\tLoss = 1995679.5, Hitrate@10 = 0.2098376946008612\n",
      "[71 epoch]\tLoss = 1986465.75, Hitrate@10 = 0.2101689301093077\n",
      "[72 epoch]\tLoss = 1977541.875, Hitrate@10 = 0.2095064590924147\n",
      "[73 epoch]\tLoss = 1968636.0, Hitrate@10 = 0.20934084133819145\n",
      "[74 epoch]\tLoss = 1959811.5, Hitrate@10 = 0.20867837032129843\n",
      "[75 epoch]\tLoss = 1951265.5, Hitrate@10 = 0.20834713481285194\n",
      "[76 epoch]\tLoss = 1942972.125, Hitrate@10 = 0.20785028155018218\n",
      "[77 epoch]\tLoss = 1934784.0, Hitrate@10 = 0.20718781053328916\n",
      "[78 epoch]\tLoss = 1926688.5, Hitrate@10 = 0.20685657502484267\n",
      "[79 epoch]\tLoss = 1918781.5, Hitrate@10 = 0.20768466379595893\n",
      "[80 epoch]\tLoss = 1911081.0, Hitrate@10 = 0.20801589930440542\n",
      "[81 epoch]\tLoss = 1903506.25, Hitrate@10 = 0.20751904604173568\n",
      "[82 epoch]\tLoss = 1896026.25, Hitrate@10 = 0.20751904604173568\n",
      "[83 epoch]\tLoss = 1888690.75, Hitrate@10 = 0.2073534282875124\n",
      "[84 epoch]\tLoss = 1881522.5, Hitrate@10 = 0.20652533951639615\n",
      "[85 epoch]\tLoss = 1874486.625, Hitrate@10 = 0.20586286849950314\n",
      "[86 epoch]\tLoss = 1867552.5, Hitrate@10 = 0.2053660152368334\n",
      "[87 epoch]\tLoss = 1860732.375, Hitrate@10 = 0.20619410400794966\n",
      "[88 epoch]\tLoss = 1854052.625, Hitrate@10 = 0.20652533951639615\n",
      "[89 epoch]\tLoss = 1847499.75, Hitrate@10 = 0.20619410400794966\n",
      "[90 epoch]\tLoss = 1841039.875, Hitrate@10 = 0.2060284862537264\n",
      "[91 epoch]\tLoss = 1834681.625, Hitrate@10 = 0.2060284862537264\n",
      "[92 epoch]\tLoss = 1828448.75, Hitrate@10 = 0.2060284862537264\n",
      "[93 epoch]\tLoss = 1822325.625, Hitrate@10 = 0.2053660152368334\n",
      "[94 epoch]\tLoss = 1816290.5, Hitrate@10 = 0.20503477972838688\n",
      "[95 epoch]\tLoss = 1810352.625, Hitrate@10 = 0.2047035442199404\n",
      "[96 epoch]\tLoss = 1804523.25, Hitrate@10 = 0.20387545544882413\n",
      "[97 epoch]\tLoss = 1798790.125, Hitrate@10 = 0.20321298443193112\n",
      "[98 epoch]\tLoss = 1793139.75, Hitrate@10 = 0.2028817489234846\n",
      "[99 epoch]\tLoss = 1787578.875, Hitrate@10 = 0.20172242464392182\n"
     ]
    }
   ],
   "source": [
    "beta = 5\n",
    "alpha = 1\n",
    "n_epochs = 100\n",
    "\n",
    "model = SLIM(R)\n",
    "# здесь явно укажем, что в качестве обучаемых параметров будет матрица W\n",
    "optimizer = torch.optim.Adam([model.W], lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(R)\n",
    "    # наша функция ошибки состоит из MSE, L2 и L1 регуляризации\n",
    "    loss = (\n",
    "        torch.sum((y_pred - R) ** 2) / 2\n",
    "        + beta / 2 * (model.W**2).sum()\n",
    "        + alpha * model.W.abs().sum()\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # с помощью функции topk выберем индексы top-k максимальных объектов на основе предсказанной матрицы рейтингов\n",
    "    recs = torch.topk(y_pred, TOP_K + median_seq_len)[1].numpy()\n",
    "\n",
    "    # оценим метрику качества самих рекомендаций\n",
    "    hitrate_list = []\n",
    "    for user_id, user_history, y_rel in grouped_df.select(\n",
    "        \"user_id\", \"train_item_ids\", \"test_item_ids\"\n",
    "    ).rows():\n",
    "        user_history = set(user_history)\n",
    "        y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "\n",
    "    mean_hitrate = np.mean(hitrate_list)\n",
    "\n",
    "    print(f\"[{epoch} epoch]\\tLoss = {loss.item()}, Hitrate@{TOP_K} = {mean_hitrate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1233447",
   "metadata": {},
   "source": [
    "После 22 эпохи моделька начала переобучаться, но тем не менее мы достигли результат SVD 🥳"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
